{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Guide to Polars for Pandas/PySpark Users\n",
    "\n",
    "This notebook provides a comprehensive introduction to Polars, covering everything from basics to advanced topics.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction & Setup](#1-introduction--setup)\n",
    "2. [Basic Data Structures](#2-basic-data-structures)\n",
    "3. [Creating DataFrames](#3-creating-dataframes)\n",
    "4. [Reading & Writing Data](#4-reading--writing-data)\n",
    "5. [Data Selection & Filtering](#5-data-selection--filtering)\n",
    "6. [Expressions - The Heart of Polars](#6-expressions---the-heart-of-polars)\n",
    "7. [Transformations & Column Operations](#7-transformations--column-operations)\n",
    "8. [Aggregations & GroupBy](#8-aggregations--groupby)\n",
    "9. [Joins & Concatenations](#9-joins--concatenations)\n",
    "10. [Lazy vs Eager Evaluation](#10-lazy-vs-eager-evaluation)\n",
    "11. [Time Series Operations](#11-time-series-operations)\n",
    "12. [String Operations](#12-string-operations)\n",
    "13. [Window Functions](#13-window-functions)\n",
    "14. [Performance Optimization](#14-performance-optimization)\n",
    "15. [Advanced Features](#15-advanced-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "\n",
    "### What is Polars?\n",
    "- **Fast**: Written in Rust, optimized for performance\n",
    "- **Efficient**: Uses Apache Arrow columnar format\n",
    "- **Expressive**: Rich expression API\n",
    "- **Lazy**: Built-in query optimization\n",
    "\n",
    "### Key Differences from Pandas/PySpark\n",
    "| Feature | Pandas | PySpark | Polars |\n",
    "|---------|--------|---------|--------|\n",
    "| Speed | Moderate | Fast (distributed) | Very Fast (single node) |\n",
    "| Memory | Copies data often | Distributed | Zero-copy views |\n",
    "| API Style | Method chaining | SQL-like | Expression-based |\n",
    "| Lazy Evaluation | No | Yes | Yes |\n",
    "| Parallelization | Limited | Distributed | Multi-threaded |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.34.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install Polars (run this if not already installed)\n",
    "# !pip install polars\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Check version\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "\n",
    "# Set display options\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Structures\n",
    "\n",
    "Polars has two main data structures:\n",
    "- **Series**: 1D array (like pandas Series)\n",
    "- **DataFrame**: 2D table (like pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "shape: (6,)\n",
      "Series: 'numbers' [i64]\n",
      "[\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "\t0\n",
      "]\n",
      "\n",
      "Dtype: Int64\n",
      "Length: 6\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series\n",
    "s = pl.Series(\"numbers\", [1, 2, 3, 4, 5, 0])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "print(f\"\\nDtype: {s.dtype}\")\n",
    "print(f\"Length: {len(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>numbers</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>5</td></tr><tr><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6,)\n",
       "Series: 'numbers' [i64]\n",
       "[\n",
       "\t1\n",
       "\t2\n",
       "\t3\n",
       "\t4\n",
       "\t5\n",
       "\t0\n",
       "]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>numbers</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'numbers' [i64]\n",
       "[\n",
       "\t1\n",
       "\t2\n",
       "\t3\n",
       "\t4\n",
       "\t5\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.filter(s > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int Series: [1, 2, 3]\n",
      "Float Series: [1.0, 2.5, 3.7]\n",
      "String Series: ['a', 'b', 'c']\n",
      "Boolean Series: [True, False, True]\n"
     ]
    }
   ],
   "source": [
    "# Series with different dtypes\n",
    "int_series = pl.Series(\"integers\", [1, 2, 3], dtype=pl.Int64)\n",
    "float_series = pl.Series(\"floats\", [1.0, 2.5, 3.7], dtype=pl.Float64)\n",
    "str_series = pl.Series(\"strings\", [\"a\", \"b\", \"c\"], dtype=pl.Utf8)\n",
    "bool_series = pl.Series(\"booleans\", [True, False, True], dtype=pl.Boolean)\n",
    "\n",
    "print(\"Int Series:\", int_series.to_list())\n",
    "print(\"Float Series:\", float_series.to_list())\n",
    "print(\"String Series:\", str_series.to_list())\n",
    "print(\"Boolean Series:\", bool_series.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating DataFrames\n",
    "\n",
    "Multiple ways to create DataFrames in Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from dictionary:\n",
      "shape: (5, 4)\n",
      "┌─────────┬─────┬──────────┬────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    │\n",
      "╞═════════╪═════╪══════════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  │\n",
      "└─────────┴─────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Method 1: From dictionary\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 28],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"salary\": [70000, 80000, 90000, 95000, 75000]\n",
    "})\n",
    "\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from list of dicts:\n",
      "shape: (3, 3)\n",
      "┌─────────┬──────────┬───────┐\n",
      "│ product ┆ quantity ┆ price │\n",
      "│ ---     ┆ ---      ┆ ---   │\n",
      "│ str     ┆ i64      ┆ i64   │\n",
      "╞═════════╪══════════╪═══════╡\n",
      "│ A       ┆ 10       ┆ 100   │\n",
      "│ B       ┆ 20       ┆ 200   │\n",
      "│ C       ┆ 15       ┆ 150   │\n",
      "└─────────┴──────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Method 2: From list of dictionaries (row-oriented)\n",
    "data = [\n",
    "    {\"product\": \"A\", \"quantity\": 10, \"price\": 100},\n",
    "    {\"product\": \"B\", \"quantity\": 20, \"price\": 200},\n",
    "    {\"product\": \"C\", \"quantity\": 15, \"price\": 150},\n",
    "]\n",
    "\n",
    "df2 = pl.DataFrame(data)\n",
    "print(\"DataFrame from list of dicts:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8\n",
      "Int16\n",
      "Int32\n",
      "Int64\n",
      "Int128\n",
      "UInt8\n",
      "UInt16\n",
      "UInt32\n",
      "UInt64\n",
      "UInt128\n",
      "Float32\n",
      "Float64\n",
      "Boolean\n",
      "String\n",
      "String\n",
      "Null\n",
      "Unknown\n"
     ]
    }
   ],
   "source": [
    "all_types = [\n",
    "    pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.Int128,\n",
    "    pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64, pl.UInt128,\n",
    "    pl.Float32, pl.Float64, \n",
    "    pl.Boolean,\n",
    "    pl.String, pl.Utf8,\n",
    "    pl.Null,\n",
    "    pl.Unknown\n",
    "]\n",
    "\n",
    "for dtype in all_types:\n",
    "    print(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from NumPy:\n",
      "shape: (5, 3)\n",
      "┌───────────┬───────────┬───────────┐\n",
      "│ col1      ┆ col2      ┆ col3      │\n",
      "│ ---       ┆ ---       ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ f64       │\n",
      "╞═══════════╪═══════════╪═══════════╡\n",
      "│ 0.68228   ┆ 0.513249  ┆ 0.317999  │\n",
      "│ 1.652426  ┆ 0.110475  ┆ 1.679442  │\n",
      "│ 0.250377  ┆ -1.387383 ┆ 0.028438  │\n",
      "│ 0.449553  ┆ -2.280736 ┆ -1.031757 │\n",
      "│ -1.406318 ┆ -1.727953 ┆ -1.208249 │\n",
      "└───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Method 3: From NumPy array\n",
    "arr = np.random.randn(5, 3)\n",
    "df3 = pl.DataFrame(arr, schema=[\"col1\", \"col2\", \"col3\"])\n",
    "print(\"DataFrame from NumPy:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5, 4)\n",
      "\n",
      "Column names: ['name', 'age', 'city', 'salary']\n",
      "\n",
      "Dtypes: [String, Int64, String, Int64]\n",
      "\n",
      "Schema:\n",
      "Schema({'name': String, 'age': Int64, 'city': String, 'salary': Int64})\n"
     ]
    }
   ],
   "source": [
    "# Basic DataFrame info (similar to pandas)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns)\n",
    "print(\"\\nDtypes:\", df.dtypes)\n",
    "print(\"\\nSchema:\")\n",
    "print(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe:\n",
      "shape: (9, 5)\n",
      "┌────────────┬───────┬─────────┬────────┬──────────────┐\n",
      "│ statistic  ┆ name  ┆ age     ┆ city   ┆ salary       │\n",
      "│ ---        ┆ ---   ┆ ---     ┆ ---    ┆ ---          │\n",
      "│ str        ┆ str   ┆ f64     ┆ str    ┆ f64          │\n",
      "╞════════════╪═══════╪═════════╪════════╪══════════════╡\n",
      "│ count      ┆ 5     ┆ 5.0     ┆ 5      ┆ 5.0          │\n",
      "│ null_count ┆ 0     ┆ 0.0     ┆ 0      ┆ 0.0          │\n",
      "│ mean       ┆ null  ┆ 31.6    ┆ null   ┆ 82000.0      │\n",
      "│ std        ┆ null  ┆ 5.94138 ┆ null   ┆ 10368.220677 │\n",
      "│ min        ┆ Alice ┆ 25.0    ┆ Berlin ┆ 70000.0      │\n",
      "│ 25%        ┆ null  ┆ 28.0    ┆ null   ┆ 75000.0      │\n",
      "│ 50%        ┆ null  ┆ 30.0    ┆ null   ┆ 80000.0      │\n",
      "│ 75%        ┆ null  ┆ 35.0    ┆ null   ┆ 90000.0      │\n",
      "│ max        ┆ Eve   ┆ 40.0    ┆ Tokyo  ┆ 95000.0      │\n",
      "└────────────┴───────┴─────────┴────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Quick statistics\n",
    "print(\"Describe:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reading & Writing Data\n",
    "\n",
    "Polars supports multiple file formats with excellent performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────┬────────┬───────┬────────────────────────────┐\n",
      "│ id  ┆ name   ┆ score ┆ timestamp                  │\n",
      "│ --- ┆ ---    ┆ ---   ┆ ---                        │\n",
      "│ i64 ┆ str    ┆ i64   ┆ datetime[μs]               │\n",
      "╞═════╪════════╪═══════╪════════════════════════════╡\n",
      "│ 1   ┆ User_1 ┆ 4     ┆ 2025-11-01 17:58:18.429212 │\n",
      "│ 2   ┆ User_2 ┆ 67    ┆ 2025-10-31 17:58:18.429218 │\n",
      "│ 3   ┆ User_3 ┆ 13    ┆ 2025-10-30 17:58:18.429219 │\n",
      "│ 4   ┆ User_4 ┆ 8     ┆ 2025-10-29 17:58:18.429220 │\n",
      "│ 5   ┆ User_5 ┆ 93    ┆ 2025-10-28 17:58:18.429220 │\n",
      "└─────┴────────┴───────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create sample data for I/O examples\n",
    "sample_df = pl.DataFrame({\n",
    "    \"id\": range(1, 1001),\n",
    "    \"name\": [f\"User_{i}\" for i in range(1, 1001)],\n",
    "    \"score\": np.random.randint(0, 100, 1000),\n",
    "    \"timestamp\": [datetime.now() - timedelta(days=i) for i in range(1000)]\n",
    "})\n",
    "\n",
    "print(sample_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to CSV\n",
      "\n",
      "Read from CSV:\n",
      "shape: (5, 4)\n",
      "┌─────┬────────┬───────┬────────────────────────────┐\n",
      "│ id  ┆ name   ┆ score ┆ timestamp                  │\n",
      "│ --- ┆ ---    ┆ ---   ┆ ---                        │\n",
      "│ i64 ┆ str    ┆ i64   ┆ str                        │\n",
      "╞═════╪════════╪═══════╪════════════════════════════╡\n",
      "│ 1   ┆ User_1 ┆ 4     ┆ 2025-11-01T17:58:18.429212 │\n",
      "│ 2   ┆ User_2 ┆ 67    ┆ 2025-10-31T17:58:18.429218 │\n",
      "│ 3   ┆ User_3 ┆ 13    ┆ 2025-10-30T17:58:18.429219 │\n",
      "│ 4   ┆ User_4 ┆ 8     ┆ 2025-10-29T17:58:18.429220 │\n",
      "│ 5   ┆ User_5 ┆ 93    ┆ 2025-10-28T17:58:18.429220 │\n",
      "└─────┴────────┴───────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Writing to CSV\n",
    "sample_df.write_csv(\"data.csv\")\n",
    "print(\"Written to CSV\")\n",
    "\n",
    "# Reading from CSV\n",
    "df_csv = pl.read_csv(\"data.csv\")\n",
    "print(\"\\nRead from CSV:\")\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from Parquet:\n",
      "shape: (5, 4)\n",
      "┌─────┬────────┬───────┬────────────────────────────┐\n",
      "│ id  ┆ name   ┆ score ┆ timestamp                  │\n",
      "│ --- ┆ ---    ┆ ---   ┆ ---                        │\n",
      "│ i64 ┆ str    ┆ i64   ┆ datetime[μs]               │\n",
      "╞═════╪════════╪═══════╪════════════════════════════╡\n",
      "│ 1   ┆ User_1 ┆ 4     ┆ 2025-11-01 17:58:18.429212 │\n",
      "│ 2   ┆ User_2 ┆ 67    ┆ 2025-10-31 17:58:18.429218 │\n",
      "│ 3   ┆ User_3 ┆ 13    ┆ 2025-10-30 17:58:18.429219 │\n",
      "│ 4   ┆ User_4 ┆ 8     ┆ 2025-10-29 17:58:18.429220 │\n",
      "│ 5   ┆ User_5 ┆ 93    ┆ 2025-10-28 17:58:18.429220 │\n",
      "└─────┴────────┴───────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Parquet (recommended for performance)\n",
    "sample_df.write_parquet(\"data.parquet\")\n",
    "df_parquet = pl.read_parquet(\"data.parquet\")\n",
    "print(\"Read from Parquet:\")\n",
    "print(df_parquet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from JSON:\n",
      "shape: (5, 4)\n",
      "┌─────┬────────┬───────┬────────────────────────────┐\n",
      "│ id  ┆ name   ┆ score ┆ timestamp                  │\n",
      "│ --- ┆ ---    ┆ ---   ┆ ---                        │\n",
      "│ i64 ┆ str    ┆ i64   ┆ str                        │\n",
      "╞═════╪════════╪═══════╪════════════════════════════╡\n",
      "│ 1   ┆ User_1 ┆ 4     ┆ 2025-11-01 17:58:18.429212 │\n",
      "│ 2   ┆ User_2 ┆ 67    ┆ 2025-10-31 17:58:18.429218 │\n",
      "│ 3   ┆ User_3 ┆ 13    ┆ 2025-10-30 17:58:18.429219 │\n",
      "│ 4   ┆ User_4 ┆ 8     ┆ 2025-10-29 17:58:18.429220 │\n",
      "│ 5   ┆ User_5 ┆ 93    ┆ 2025-10-28 17:58:18.429220 │\n",
      "└─────┴────────┴───────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# JSON\n",
    "sample_df.head(5).write_json(\"data.json\")\n",
    "df_json = pl.read_json(\"data.json\")\n",
    "print(\"Read from JSON:\")\n",
    "print(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy DataFrame (not yet loaded):\n",
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "Csv SCAN [data.csv]\n",
      "PROJECT */4 COLUMNS\n",
      "\n",
      "Collected result:\n",
      "shape: (3, 4)\n",
      "┌─────┬────────┬───────┬────────────────────────────┐\n",
      "│ id  ┆ name   ┆ score ┆ timestamp                  │\n",
      "│ --- ┆ ---    ┆ ---   ┆ ---                        │\n",
      "│ i64 ┆ str    ┆ i64   ┆ str                        │\n",
      "╞═════╪════════╪═══════╪════════════════════════════╡\n",
      "│ 1   ┆ User_1 ┆ 4     ┆ 2025-11-01T17:58:18.429212 │\n",
      "│ 2   ┆ User_2 ┆ 67    ┆ 2025-10-31T17:58:18.429218 │\n",
      "│ 3   ┆ User_3 ┆ 13    ┆ 2025-10-30T17:58:18.429219 │\n",
      "└─────┴────────┴───────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Lazy reading (for large files) - reads only when needed\n",
    "lazy_df = pl.scan_csv(\"data.csv\")\n",
    "print(\"Lazy DataFrame (not yet loaded):\")\n",
    "print(lazy_df)\n",
    "\n",
    "# Collect to execute\n",
    "result = lazy_df.head(3).collect()\n",
    "print(\"\\nCollected result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Selection & Filtering\n",
    "\n",
    "Polars uses expressions for powerful and efficient data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "shape: (6, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  ┆ HR         │\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\"],\n",
    "    \"age\": [25, 30, 35, 40, 28, 45],\n",
    "    \"city\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\", \"Sydney\"],\n",
    "    \"salary\": [70000, 80000, 90000, 95000, 75000, 100000],\n",
    "    \"department\": [\"IT\", \"HR\", \"IT\", \"Finance\", \"HR\", \"IT\"]\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select single column:\n",
      "shape: (6, 1)\n",
      "┌─────────┐\n",
      "│ name    │\n",
      "│ ---     │\n",
      "│ str     │\n",
      "╞═════════╡\n",
      "│ Alice   │\n",
      "│ Bob     │\n",
      "│ Charlie │\n",
      "│ David   │\n",
      "│ Eve     │\n",
      "│ Frank   │\n",
      "└─────────┘\n",
      "\n",
      "Select multiple columns:\n",
      "shape: (6, 3)\n",
      "┌─────────┬─────┬────────┐\n",
      "│ name    ┆ age ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---    │\n",
      "│ str     ┆ i64 ┆ i64    │\n",
      "╞═════════╪═════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ 70000  │\n",
      "│ Bob     ┆ 30  ┆ 80000  │\n",
      "│ Charlie ┆ 35  ┆ 90000  │\n",
      "│ David   ┆ 40  ┆ 95000  │\n",
      "│ Eve     ┆ 28  ┆ 75000  │\n",
      "│ Frank   ┆ 45  ┆ 100000 │\n",
      "└─────────┴─────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Select columns\n",
    "print(\"Select single column:\")\n",
    "print(df.select(\"name\"))\n",
    "\n",
    "print(\"\\nSelect multiple columns:\")\n",
    "print(df.select([\"name\", \"age\", \"salary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select with expressions:\n",
      "shape: (6, 3)\n",
      "┌─────────┬─────┬────────┐\n",
      "│ name    ┆ age ┆ salary │\n",
      "│ ---     ┆ --- ┆ ---    │\n",
      "│ str     ┆ i64 ┆ i64    │\n",
      "╞═════════╪═════╪════════╡\n",
      "│ Alice   ┆ 25  ┆ 70000  │\n",
      "│ Bob     ┆ 30  ┆ 80000  │\n",
      "│ Charlie ┆ 35  ┆ 90000  │\n",
      "│ David   ┆ 40  ┆ 95000  │\n",
      "│ Eve     ┆ 28  ┆ 75000  │\n",
      "│ Frank   ┆ 45  ┆ 100000 │\n",
      "└─────────┴─────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Select using expressions (pl.col)\n",
    "print(\"Select with expressions:\")\n",
    "print(df.select([\n",
    "    pl.col(\"name\"),\n",
    "    pl.col(\"age\"),\n",
    "    pl.col(\"salary\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select numeric columns:\n",
      "shape: (6, 2)\n",
      "┌─────┬────────┐\n",
      "│ age ┆ salary │\n",
      "│ --- ┆ ---    │\n",
      "│ i64 ┆ i64    │\n",
      "╞═════╪════════╡\n",
      "│ 25  ┆ 70000  │\n",
      "│ 30  ┆ 80000  │\n",
      "│ 35  ┆ 90000  │\n",
      "│ 40  ┆ 95000  │\n",
      "│ 28  ┆ 75000  │\n",
      "│ 45  ┆ 100000 │\n",
      "└─────┴────────┘\n",
      "\n",
      "Select string columns:\n",
      "shape: (6, 3)\n",
      "┌─────────┬──────────┬────────────┐\n",
      "│ name    ┆ city     ┆ department │\n",
      "│ ---     ┆ ---      ┆ ---        │\n",
      "│ str     ┆ str      ┆ str        │\n",
      "╞═════════╪══════════╪════════════╡\n",
      "│ Alice   ┆ New York ┆ IT         │\n",
      "│ Bob     ┆ London   ┆ HR         │\n",
      "│ Charlie ┆ Paris    ┆ IT         │\n",
      "│ David   ┆ Tokyo    ┆ Finance    │\n",
      "│ Eve     ┆ Berlin   ┆ HR         │\n",
      "│ Frank   ┆ Sydney   ┆ IT         │\n",
      "└─────────┴──────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Select by dtype\n",
    "print(\"Select numeric columns:\")\n",
    "print(df.select(pl.col(pl.Int64)))\n",
    "\n",
    "print(\"\\nSelect string columns:\")\n",
    "print(df.select(pl.col(pl.Utf8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter age > 30:\n",
      "shape: (3, 5)\n",
      "┌─────────┬─────┬────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city   ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---    ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str    ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪════════╪════════╪════════════╡\n",
      "│ Charlie ┆ 35  ┆ Paris  ┆ 90000  ┆ IT         │\n",
      "│ David   ┆ 40  ┆ Tokyo  ┆ 95000  ┆ Finance    │\n",
      "│ Frank   ┆ 45  ┆ Sydney ┆ 100000 ┆ IT         │\n",
      "└─────────┴─────┴────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Filter rows (similar to pandas query or SQL WHERE)\n",
    "print(\"Filter age > 30:\")\n",
    "print(df.filter(pl.col(\"age\") > 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter with multiple conditions (age > 30 AND salary > 80000):\n",
      "shape: (3, 5)\n",
      "┌─────────┬─────┬────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city   ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---    ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str    ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪════════╪════════╪════════════╡\n",
      "│ Charlie ┆ 35  ┆ Paris  ┆ 90000  ┆ IT         │\n",
      "│ David   ┆ 40  ┆ Tokyo  ┆ 95000  ┆ Finance    │\n",
      "│ Frank   ┆ 45  ┆ Sydney ┆ 100000 ┆ IT         │\n",
      "└─────────┴─────┴────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Multiple conditions with & (and) | (or)\n",
    "print(\"Filter with multiple conditions (age > 30 AND salary > 80000):\")\n",
    "print(df.filter(\n",
    "    (pl.col(\"age\") > 30) & (pl.col(\"salary\") > 80000)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter department == 'IT':\n",
      "shape: (3, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n",
      "\n",
      "Filter city contains 'o':\n",
      "shape: (3, 5)\n",
      "┌───────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name  ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---   ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str   ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═══════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Alice ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "│ Bob   ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ David ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    │\n",
      "└───────┴─────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# String filtering\n",
    "print(\"Filter department == 'IT':\")\n",
    "print(df.filter(pl.col(\"department\") == \"IT\"))\n",
    "\n",
    "print(\"\\nFilter city contains 'o':\")\n",
    "print(df.filter(pl.col(\"city\").str.contains(\"o\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter names in list:\n",
      "shape: (3, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# isin (similar to pandas)\n",
    "print(\"Filter names in list:\")\n",
    "print(df.filter(pl.col(\"name\").is_in([\"Alice\", \"Bob\", \"Charlie\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows:\n",
      "shape: (3, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n",
      "\n",
      "Last 2 rows:\n",
      "shape: (2, 5)\n",
      "┌───────┬─────┬────────┬────────┬────────────┐\n",
      "│ name  ┆ age ┆ city   ┆ salary ┆ department │\n",
      "│ ---   ┆ --- ┆ ---    ┆ ---    ┆ ---        │\n",
      "│ str   ┆ i64 ┆ str    ┆ i64    ┆ str        │\n",
      "╞═══════╪═════╪════════╪════════╪════════════╡\n",
      "│ Eve   ┆ 28  ┆ Berlin ┆ 75000  ┆ HR         │\n",
      "│ Frank ┆ 45  ┆ Sydney ┆ 100000 ┆ IT         │\n",
      "└───────┴─────┴────────┴────────┴────────────┘\n",
      "\n",
      "Random sample (2 rows):\n",
      "shape: (2, 5)\n",
      "┌──────┬─────┬────────┬────────┬────────────┐\n",
      "│ name ┆ age ┆ city   ┆ salary ┆ department │\n",
      "│ ---  ┆ --- ┆ ---    ┆ ---    ┆ ---        │\n",
      "│ str  ┆ i64 ┆ str    ┆ i64    ┆ str        │\n",
      "╞══════╪═════╪════════╪════════╪════════════╡\n",
      "│ Eve  ┆ 28  ┆ Berlin ┆ 75000  ┆ HR         │\n",
      "│ Bob  ┆ 30  ┆ London ┆ 80000  ┆ HR         │\n",
      "└──────┴─────┴────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# head, tail, sample\n",
    "print(\"First 3 rows:\")\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\nLast 2 rows:\")\n",
    "print(df.tail(2))\n",
    "\n",
    "print(\"\\nRandom sample (2 rows):\")\n",
    "print(df.sample(n=2, seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Expressions - The Heart of Polars\n",
    "\n",
    "Expressions are what make Polars powerful and fast. They are:\n",
    "- **Composable**: Can be chained together\n",
    "- **Parallelizable**: Automatically run in parallel\n",
    "- **Optimizable**: Query optimizer improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double the salary:\n",
      "shape: (6, 2)\n",
      "┌─────────┬────────────────┐\n",
      "│ name    ┆ doubled_salary │\n",
      "│ ---     ┆ ---            │\n",
      "│ str     ┆ i64            │\n",
      "╞═════════╪════════════════╡\n",
      "│ Alice   ┆ 140000         │\n",
      "│ Bob     ┆ 160000         │\n",
      "│ Charlie ┆ 180000         │\n",
      "│ David   ┆ 190000         │\n",
      "│ Eve     ┆ 150000         │\n",
      "│ Frank   ┆ 200000         │\n",
      "└─────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Basic expression\n",
    "print(\"Double the salary:\")\n",
    "print(df.select([\n",
    "    pl.col(\"name\"),\n",
    "    (pl.col(\"salary\") * 2).alias(\"doubled_salary\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple expressions:\n",
      "shape: (6, 4)\n",
      "┌─────────┬─────┬──────────┬───────────┐\n",
      "│ name    ┆ age ┆ salary_k ┆ is_senior │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---       │\n",
      "│ str     ┆ i64 ┆ f64      ┆ bool      │\n",
      "╞═════════╪═════╪══════════╪═══════════╡\n",
      "│ Alice   ┆ 25  ┆ 70.0     ┆ false     │\n",
      "│ Bob     ┆ 30  ┆ 80.0     ┆ false     │\n",
      "│ Charlie ┆ 35  ┆ 90.0     ┆ true      │\n",
      "│ David   ┆ 40  ┆ 95.0     ┆ true      │\n",
      "│ Eve     ┆ 28  ┆ 75.0     ┆ false     │\n",
      "│ Frank   ┆ 45  ┆ 100.0    ┆ true      │\n",
      "└─────────┴─────┴──────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Multiple operations in one select\n",
    "print(\"Multiple expressions:\")\n",
    "print(df.select([\n",
    "    pl.col(\"name\"),\n",
    "    pl.col(\"age\"),\n",
    "    (pl.col(\"salary\") / 1000).alias(\"salary_k\"),\n",
    "    (pl.col(\"age\") > 30).alias(\"is_senior\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add new columns:\n",
      "shape: (6, 7)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┬────────────────────┬───────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department ┆ salary_after_raise ┆ age_next_year │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        ┆ ---                ┆ ---           │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        ┆ f64                ┆ i64           │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╪════════════════════╪═══════════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         ┆ 77000.0            ┆ 26            │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         ┆ 88000.0            ┆ 31            │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         ┆ 99000.0            ┆ 36            │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    ┆ 104500.0           ┆ 41            │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  ┆ HR         ┆ 82500.0            ┆ 29            │\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         ┆ 110000.0           ┆ 46            │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┴────────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# with_columns (add/modify columns without selecting)\n",
    "print(\"Add new columns:\")\n",
    "result = df.with_columns([\n",
    "    (pl.col(\"salary\") * 1.1).alias(\"salary_after_raise\"),\n",
    "    (pl.col(\"age\") + 1).alias(\"age_next_year\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional column:\n",
      "shape: (6, 6)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┬───────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department ┆ age_group │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        ┆ ---       │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        ┆ str       │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╪═══════════╡\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         ┆ Young     │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         ┆ Middle    │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         ┆ Middle    │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    ┆ Senior    │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  ┆ HR         ┆ Young     │\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         ┆ Senior    │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Conditional expressions (when-then-otherwise)\n",
    "print(\"Conditional column:\")\n",
    "result = df.with_columns([\n",
    "    pl.when(pl.col(\"age\") < 30)\n",
    "      .then(pl.lit(\"Young\"))\n",
    "      .when(pl.col(\"age\") < 40)\n",
    "      .then(pl.lit(\"Middle\"))\n",
    "      .otherwise(pl.lit(\"Senior\"))\n",
    "      .alias(\"age_group\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chained expressions:\n",
      "shape: (6, 2)\n",
      "┌────────────┬────────────┐\n",
      "│ name_upper ┆ log_salary │\n",
      "│ ---        ┆ ---        │\n",
      "│ str        ┆ f64        │\n",
      "╞════════════╪════════════╡\n",
      "│ ALICE      ┆ 4.85       │\n",
      "│ BOB        ┆ 4.9        │\n",
      "│ CHARLIE    ┆ 4.95       │\n",
      "│ DAVID      ┆ 4.98       │\n",
      "│ EVE        ┆ 4.88       │\n",
      "│ FRANK      ┆ 5.0        │\n",
      "└────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Expression aliases and chaining\n",
    "print(\"Chained expressions:\")\n",
    "result = df.select([\n",
    "    pl.col(\"name\").str.to_uppercase().alias(\"name_upper\"),\n",
    "    pl.col(\"salary\").log10().round(2).alias(\"log_salary\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transformations & Column Operations\n",
    "\n",
    "Common data transformation operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by age (descending):\n",
      "shape: (6, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         │\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  ┆ HR         │\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n",
      "\n",
      "Sort by multiple columns:\n",
      "shape: (6, 5)\n",
      "┌─────────┬─────┬──────────┬────────┬────────────┐\n",
      "│ name    ┆ age ┆ city     ┆ salary ┆ department │\n",
      "│ ---     ┆ --- ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str     ┆ i64 ┆ str      ┆ i64    ┆ str        │\n",
      "╞═════════╪═════╪══════════╪════════╪════════════╡\n",
      "│ David   ┆ 40  ┆ Tokyo    ┆ 95000  ┆ Finance    │\n",
      "│ Bob     ┆ 30  ┆ London   ┆ 80000  ┆ HR         │\n",
      "│ Eve     ┆ 28  ┆ Berlin   ┆ 75000  ┆ HR         │\n",
      "│ Frank   ┆ 45  ┆ Sydney   ┆ 100000 ┆ IT         │\n",
      "│ Charlie ┆ 35  ┆ Paris    ┆ 90000  ┆ IT         │\n",
      "│ Alice   ┆ 25  ┆ New York ┆ 70000  ┆ IT         │\n",
      "└─────────┴─────┴──────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Sorting\n",
    "print(\"Sort by age (descending):\")\n",
    "print(df.sort(\"age\", descending=True))\n",
    "\n",
    "print(\"\\nSort by multiple columns:\")\n",
    "print(df.sort([\"department\", \"salary\"], descending=[False, True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename columns:\n",
      "['employee_name', 'age', 'city', 'annual_salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "print(\"Rename columns:\")\n",
    "renamed = df.rename({\"name\": \"employee_name\", \"salary\": \"annual_salary\"})\n",
    "print(renamed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop columns:\n",
      "['name', 'age', 'salary']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "print(\"Drop columns:\")\n",
    "print(df.drop([\"city\", \"department\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cast age to float:\n",
      "[String, Float64, String, Int64, String]\n"
     ]
    }
   ],
   "source": [
    "# Cast dtypes\n",
    "print(\"Cast age to float:\")\n",
    "result = df.with_columns(pl.col(\"age\").cast(pl.Float64))\n",
    "print(result.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>age</th><th>city</th><th>salary</th><th>department</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Alice&quot;</td><td>25.0</td><td>&quot;New York&quot;</td><td>70000</td><td>&quot;IT&quot;</td></tr><tr><td>&quot;Bob&quot;</td><td>30.0</td><td>&quot;London&quot;</td><td>80000</td><td>&quot;HR&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 5)\n",
       "┌───────┬──────┬──────────┬────────┬────────────┐\n",
       "│ name  ┆ age  ┆ city     ┆ salary ┆ department │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---    ┆ ---        │\n",
       "│ str   ┆ f64  ┆ str      ┆ i64    ┆ str        │\n",
       "╞═══════╪══════╪══════════╪════════╪════════════╡\n",
       "│ Alice ┆ 25.0 ┆ New York ┆ 70000  ┆ IT         │\n",
       "│ Bob   ┆ 30.0 ┆ London   ┆ 80000  ┆ HR         │\n",
       "└───────┴──────┴──────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with nulls:\n",
      "shape: (5, 2)\n",
      "┌──────┬──────┐\n",
      "│ a    ┆ b    │\n",
      "│ ---  ┆ ---  │\n",
      "│ i64  ┆ str  │\n",
      "╞══════╪══════╡\n",
      "│ 1    ┆ x    │\n",
      "│ 2    ┆ null │\n",
      "│ null ┆ y    │\n",
      "│ 4    ┆ z    │\n",
      "│ null ┆ null │\n",
      "└──────┴──────┘\n",
      "\n",
      "Fill nulls:\n",
      "shape: (5, 2)\n",
      "┌─────┬─────┐\n",
      "│ a   ┆ b   │\n",
      "│ --- ┆ --- │\n",
      "│ i64 ┆ str │\n",
      "╞═════╪═════╡\n",
      "│ 1   ┆ x   │\n",
      "│ 2   ┆ x   │\n",
      "│ 2   ┆ y   │\n",
      "│ 4   ┆ z   │\n",
      "│ 4   ┆ z   │\n",
      "└─────┴─────┘\n",
      "\n",
      "Fill with specific value:\n",
      "shape: (5, 2)\n",
      "┌─────┬──────┐\n",
      "│ a   ┆ b    │\n",
      "│ --- ┆ ---  │\n",
      "│ i64 ┆ str  │\n",
      "╞═════╪══════╡\n",
      "│ 1   ┆ x    │\n",
      "│ 2   ┆ null │\n",
      "│ 0   ┆ y    │\n",
      "│ 4   ┆ z    │\n",
      "│ 0   ┆ null │\n",
      "└─────┴──────┘\n",
      "\n",
      "Drop nulls:\n",
      "shape: (2, 2)\n",
      "┌─────┬─────┐\n",
      "│ a   ┆ b   │\n",
      "│ --- ┆ --- │\n",
      "│ i64 ┆ str │\n",
      "╞═════╪═════╡\n",
      "│ 1   ┆ x   │\n",
      "│ 4   ┆ z   │\n",
      "└─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# Null handling\n",
    "df_with_nulls = pl.DataFrame({\n",
    "    \"a\": [1, 2, None, 4, None],\n",
    "    \"b\": [\"x\", None, \"y\", \"z\", None]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with nulls:\")\n",
    "print(df_with_nulls)\n",
    "\n",
    "print(\"\\nFill nulls:\")\n",
    "print(df_with_nulls.fill_null(strategy=\"forward\"))\n",
    "\n",
    "print(\"\\nFill with specific value:\")\n",
    "print(df_with_nulls.fill_null(0))\n",
    "\n",
    "print(\"\\nDrop nulls:\")\n",
    "print(df_with_nulls.drop_nulls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in department:\n",
      "shape: (3, 1)\n",
      "┌────────────┐\n",
      "│ department │\n",
      "│ ---        │\n",
      "│ str        │\n",
      "╞════════════╡\n",
      "│ HR         │\n",
      "│ IT         │\n",
      "│ Finance    │\n",
      "└────────────┘\n",
      "\n",
      "Count unique values:\n",
      "shape: (1, 1)\n",
      "┌────────────┐\n",
      "│ department │\n",
      "│ ---        │\n",
      "│ u32        │\n",
      "╞════════════╡\n",
      "│ 3          │\n",
      "└────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Unique and duplicates\n",
    "print(\"Unique values in department:\")\n",
    "print(df.select(pl.col(\"department\").unique()))\n",
    "\n",
    "print(\"\\nCount unique values:\")\n",
    "print(df.select(pl.col(\"department\").n_unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Aggregations & GroupBy\n",
    "\n",
    "Powerful aggregation capabilities, similar to pandas groupby but more expressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean salary:\n",
      "shape: (1, 1)\n",
      "┌─────────┐\n",
      "│ salary  │\n",
      "│ ---     │\n",
      "│ f64     │\n",
      "╞═════════╡\n",
      "│ 85000.0 │\n",
      "└─────────┘\n",
      "\n",
      "Multiple aggregations:\n",
      "shape: (1, 5)\n",
      "┌─────────────┬───────────────┬──────────────┬─────────┬─────────┐\n",
      "│ mean_salary ┆ median_salary ┆ std_salary   ┆ min_age ┆ max_age │\n",
      "│ ---         ┆ ---           ┆ ---          ┆ ---     ┆ ---     │\n",
      "│ f64         ┆ f64           ┆ f64          ┆ i64     ┆ i64     │\n",
      "╞═════════════╪═══════════════╪══════════════╪═════════╪═════════╡\n",
      "│ 85000.0     ┆ 85000.0       ┆ 11832.159566 ┆ 25      ┆ 45      │\n",
      "└─────────────┴───────────────┴──────────────┴─────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Basic aggregations\n",
    "print(\"Mean salary:\")\n",
    "print(df.select(pl.col(\"salary\").mean()))\n",
    "\n",
    "print(\"\\nMultiple aggregations:\")\n",
    "print(df.select([\n",
    "    pl.col(\"salary\").mean().alias(\"mean_salary\"),\n",
    "    pl.col(\"salary\").median().alias(\"median_salary\"),\n",
    "    pl.col(\"salary\").std().alias(\"std_salary\"),\n",
    "    pl.col(\"age\").min().alias(\"min_age\"),\n",
    "    pl.col(\"age\").max().alias(\"max_age\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by department:\n",
      "shape: (3, 4)\n",
      "┌────────────┬──────────────┬─────────┬───────┐\n",
      "│ department ┆ avg_salary   ┆ avg_age ┆ count │\n",
      "│ ---        ┆ ---          ┆ ---     ┆ ---   │\n",
      "│ str        ┆ f64          ┆ f64     ┆ u32   │\n",
      "╞════════════╪══════════════╪═════════╪═══════╡\n",
      "│ Finance    ┆ 95000.0      ┆ 40.0    ┆ 1     │\n",
      "│ HR         ┆ 77500.0      ┆ 29.0    ┆ 2     │\n",
      "│ IT         ┆ 86666.666667 ┆ 35.0    ┆ 3     │\n",
      "└────────────┴──────────────┴─────────┴───────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14227/1569176789.py:6: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"count\")\n"
     ]
    }
   ],
   "source": [
    "# GroupBy - basic\n",
    "print(\"Group by department:\")\n",
    "print(df.group_by(\"department\").agg([\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"age\").mean().alias(\"avg_age\"),\n",
    "    pl.count().alias(\"count\")\n",
    "]).sort(\"department\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by department:\n",
      "shape: (3, 4)\n",
      "┌────────────┬──────────────┬─────────┬───────┐\n",
      "│ department ┆ avg_salary   ┆ avg_age ┆ count │\n",
      "│ ---        ┆ ---          ┆ ---     ┆ ---   │\n",
      "│ str        ┆ f64          ┆ f64     ┆ u32   │\n",
      "╞════════════╪══════════════╪═════════╪═══════╡\n",
      "│ Finance    ┆ 95000.0      ┆ 40.0    ┆ 1     │\n",
      "│ HR         ┆ 77500.0      ┆ 29.0    ┆ 2     │\n",
      "│ IT         ┆ 86666.666667 ┆ 35.0    ┆ 3     │\n",
      "└────────────┴──────────────┴─────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# GroupBy - basic\n",
    "print(\"Group by department:\")\n",
    "print(df.group_by(\"department\").agg([\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"age\").mean().alias(\"avg_age\"),\n",
    "    pl.len().alias(\"count\")\n",
    "]).sort(\"department\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple aggregations:\n",
      "shape: (3, 5)\n",
      "┌────────────┬────────────┬────────────┬──────────────┬────────────────┐\n",
      "│ department ┆ min_salary ┆ max_salary ┆ avg_salary   ┆ employee_count │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---          ┆ ---            │\n",
      "│ str        ┆ i64        ┆ i64        ┆ f64          ┆ u32            │\n",
      "╞════════════╪════════════╪════════════╪══════════════╪════════════════╡\n",
      "│ HR         ┆ 75000      ┆ 80000      ┆ 77500.0      ┆ 2              │\n",
      "│ Finance    ┆ 95000      ┆ 95000      ┆ 95000.0      ┆ 1              │\n",
      "│ IT         ┆ 70000      ┆ 100000     ┆ 86666.666667 ┆ 3              │\n",
      "└────────────┴────────────┴────────────┴──────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# GroupBy - multiple aggregations per column\n",
    "print(\"Multiple aggregations:\")\n",
    "print(df.group_by(\"department\").agg([\n",
    "    pl.col(\"salary\").min().alias(\"min_salary\"),\n",
    "    pl.col(\"salary\").max().alias(\"max_salary\"),\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"name\").count().alias(\"employee_count\")\n",
    "]).sort(\"max_salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by multiple columns:\n",
      "shape: (4, 4)\n",
      "┌────────────┬──────────────┬────────────┬───────┐\n",
      "│ department ┆ age_category ┆ avg_salary ┆ count │\n",
      "│ ---        ┆ ---          ┆ ---        ┆ ---   │\n",
      "│ str        ┆ str          ┆ f64        ┆ u32   │\n",
      "╞════════════╪══════════════╪════════════╪═══════╡\n",
      "│ Finance    ┆ Senior       ┆ 95000.0    ┆ 1     │\n",
      "│ HR         ┆ Young        ┆ 77500.0    ┆ 2     │\n",
      "│ IT         ┆ Senior       ┆ 95000.0    ┆ 2     │\n",
      "│ IT         ┆ Young        ┆ 70000.0    ┆ 1     │\n",
      "└────────────┴──────────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# GroupBy with multiple keys\n",
    "df_extended = df.with_columns(\n",
    "    pl.when(pl.col(\"age\") < 35)\n",
    "      .then(pl.lit(\"Young\"))\n",
    "      .otherwise(pl.lit(\"Senior\"))\n",
    "      .alias(\"age_category\")\n",
    ")\n",
    "\n",
    "print(\"Group by multiple columns:\")\n",
    "print(df_extended.group_by([\"department\", \"age_category\"]).agg([\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.len().alias(\"count\")\n",
    "]).sort([\"department\", \"age_category\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List aggregation (collect names per department):\n",
      "shape: (3, 3)\n",
      "┌────────────┬───────────────────────────────┬──────────────┐\n",
      "│ department ┆ employees                     ┆ total_salary │\n",
      "│ ---        ┆ ---                           ┆ ---          │\n",
      "│ str        ┆ list[str]                     ┆ i64          │\n",
      "╞════════════╪═══════════════════════════════╪══════════════╡\n",
      "│ Finance    ┆ [\"David\"]                     ┆ 95000        │\n",
      "│ HR         ┆ [\"Bob\", \"Eve\"]                ┆ 155000       │\n",
      "│ IT         ┆ [\"Alice\", \"Charlie\", \"Frank\"] ┆ 260000       │\n",
      "└────────────┴───────────────────────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Advanced aggregations\n",
    "print(\"List aggregation (collect names per department):\")\n",
    "print(df.group_by(\"department\").agg([\n",
    "    pl.col(\"name\").alias(\"employees\"),\n",
    "    pl.col(\"salary\").sum().alias(\"total_salary\")\n",
    "]).sort(\"department\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary percentiles:\n",
      "shape: (1, 4)\n",
      "┌─────────┬─────────┬─────────┬──────────┐\n",
      "│ p25     ┆ p50     ┆ p75     ┆ p90      │\n",
      "│ ---     ┆ ---     ┆ ---     ┆ ---      │\n",
      "│ f64     ┆ f64     ┆ f64     ┆ f64      │\n",
      "╞═════════╪═════════╪═════════╪══════════╡\n",
      "│ 75000.0 ┆ 90000.0 ┆ 95000.0 ┆ 100000.0 │\n",
      "└─────────┴─────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Quantiles and percentiles\n",
    "print(\"Salary percentiles:\")\n",
    "print(df.select([\n",
    "    pl.col(\"salary\").quantile(0.25).alias(\"p25\"),\n",
    "    pl.col(\"salary\").quantile(0.50).alias(\"p50\"),\n",
    "    pl.col(\"salary\").quantile(0.75).alias(\"p75\"),\n",
    "    pl.col(\"salary\").quantile(0.90).alias(\"p90\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Joins & Concatenations\n",
    "\n",
    "Combining DataFrames - similar to SQL joins and pandas merge/concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees:\n",
      "shape: (5, 3)\n",
      "┌────────┬─────────┬─────────┐\n",
      "│ emp_id ┆ name    ┆ dept_id │\n",
      "│ ---    ┆ ---     ┆ ---     │\n",
      "│ i64    ┆ str     ┆ i64     │\n",
      "╞════════╪═════════╪═════════╡\n",
      "│ 1      ┆ Alice   ┆ 10      │\n",
      "│ 2      ┆ Bob     ┆ 20      │\n",
      "│ 3      ┆ Charlie ┆ 10      │\n",
      "│ 4      ┆ David   ┆ 30      │\n",
      "│ 5      ┆ Eve     ┆ 20      │\n",
      "└────────┴─────────┴─────────┘\n",
      "\n",
      "Departments:\n",
      "shape: (4, 2)\n",
      "┌─────────┬───────────┐\n",
      "│ dept_id ┆ dept_name │\n",
      "│ ---     ┆ ---       │\n",
      "│ i64     ┆ str       │\n",
      "╞═════════╪═══════════╡\n",
      "│ 10      ┆ IT        │\n",
      "│ 20      ┆ HR        │\n",
      "│ 30      ┆ Finance   │\n",
      "│ 40      ┆ Marketing │\n",
      "└─────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create sample DataFrames for joining\n",
    "employees = pl.DataFrame({\n",
    "    \"emp_id\": [1, 2, 3, 4, 5],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"dept_id\": [10, 20, 10, 30, 20]\n",
    "})\n",
    "\n",
    "departments = pl.DataFrame({\n",
    "    \"dept_id\": [10, 20, 30, 40],\n",
    "    \"dept_name\": [\"IT\", \"HR\", \"Finance\", \"Marketing\"]\n",
    "})\n",
    "\n",
    "print(\"Employees:\")\n",
    "print(employees)\n",
    "print(\"\\nDepartments:\")\n",
    "print(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner join:\n",
      "shape: (5, 4)\n",
      "┌────────┬─────────┬─────────┬───────────┐\n",
      "│ emp_id ┆ name    ┆ dept_id ┆ dept_name │\n",
      "│ ---    ┆ ---     ┆ ---     ┆ ---       │\n",
      "│ i64    ┆ str     ┆ i64     ┆ str       │\n",
      "╞════════╪═════════╪═════════╪═══════════╡\n",
      "│ 1      ┆ Alice   ┆ 10      ┆ IT        │\n",
      "│ 2      ┆ Bob     ┆ 20      ┆ HR        │\n",
      "│ 3      ┆ Charlie ┆ 10      ┆ IT        │\n",
      "│ 4      ┆ David   ┆ 30      ┆ Finance   │\n",
      "│ 5      ┆ Eve     ┆ 20      ┆ HR        │\n",
      "└────────┴─────────┴─────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "print(\"Inner join:\")\n",
    "print(employees.join(departments, on=\"dept_id\", how=\"inner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left join:\n",
      "shape: (5, 4)\n",
      "┌────────┬─────────┬─────────┬───────────┐\n",
      "│ emp_id ┆ name    ┆ dept_id ┆ dept_name │\n",
      "│ ---    ┆ ---     ┆ ---     ┆ ---       │\n",
      "│ i64    ┆ str     ┆ i64     ┆ str       │\n",
      "╞════════╪═════════╪═════════╪═══════════╡\n",
      "│ 1      ┆ Alice   ┆ 10      ┆ IT        │\n",
      "│ 2      ┆ Bob     ┆ 20      ┆ HR        │\n",
      "│ 3      ┆ Charlie ┆ 10      ┆ IT        │\n",
      "│ 4      ┆ David   ┆ 30      ┆ Finance   │\n",
      "│ 5      ┆ Eve     ┆ 20      ┆ HR        │\n",
      "└────────┴─────────┴─────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Left join\n",
    "print(\"Left join:\")\n",
    "print(employees.join(departments, on=\"dept_id\", how=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer join:\n",
      "shape: (6, 5)\n",
      "┌────────┬─────────┬─────────┬───────────────┬───────────┐\n",
      "│ emp_id ┆ name    ┆ dept_id ┆ dept_id_right ┆ dept_name │\n",
      "│ ---    ┆ ---     ┆ ---     ┆ ---           ┆ ---       │\n",
      "│ i64    ┆ str     ┆ i64     ┆ i64           ┆ str       │\n",
      "╞════════╪═════════╪═════════╪═══════════════╪═══════════╡\n",
      "│ 1      ┆ Alice   ┆ 10      ┆ 10            ┆ IT        │\n",
      "│ 2      ┆ Bob     ┆ 20      ┆ 20            ┆ HR        │\n",
      "│ 3      ┆ Charlie ┆ 10      ┆ 10            ┆ IT        │\n",
      "│ 4      ┆ David   ┆ 30      ┆ 30            ┆ Finance   │\n",
      "│ 5      ┆ Eve     ┆ 20      ┆ 20            ┆ HR        │\n",
      "│ null   ┆ null    ┆ null    ┆ 40            ┆ Marketing │\n",
      "└────────┴─────────┴─────────┴───────────────┴───────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14227/4010517553.py:3: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  print(employees.join(departments, on=\"dept_id\", how=\"outer\"))\n"
     ]
    }
   ],
   "source": [
    "# Outer join\n",
    "print(\"Outer join:\")\n",
    "print(employees.join(departments, on=\"dept_id\", how=\"outer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join on different column names:\n",
      "shape: (5, 4)\n",
      "┌────────┬─────────┬─────────┬────────┐\n",
      "│ emp_id ┆ name    ┆ dept_id ┆ salary │\n",
      "│ ---    ┆ ---     ┆ ---     ┆ ---    │\n",
      "│ i64    ┆ str     ┆ i64     ┆ i64    │\n",
      "╞════════╪═════════╪═════════╪════════╡\n",
      "│ 1      ┆ Alice   ┆ 10      ┆ 70000  │\n",
      "│ 2      ┆ Bob     ┆ 20      ┆ 80000  │\n",
      "│ 3      ┆ Charlie ┆ 10      ┆ 90000  │\n",
      "│ 4      ┆ David   ┆ 30      ┆ 95000  │\n",
      "│ 5      ┆ Eve     ┆ 20      ┆ 75000  │\n",
      "└────────┴─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Join with different column names\n",
    "salaries = pl.DataFrame({\n",
    "    \"employee_id\": [1, 2, 3, 4, 5],\n",
    "    \"salary\": [70000, 80000, 90000, 95000, 75000]\n",
    "})\n",
    "\n",
    "print(\"Join on different column names:\")\n",
    "print(employees.join(salaries, left_on=\"emp_id\", right_on=\"employee_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical concatenation:\n",
      "shape: (4, 2)\n",
      "┌─────┬─────┐\n",
      "│ a   ┆ b   │\n",
      "│ --- ┆ --- │\n",
      "│ i64 ┆ i64 │\n",
      "╞═════╪═════╡\n",
      "│ 1   ┆ 3   │\n",
      "│ 2   ┆ 4   │\n",
      "│ 5   ┆ 7   │\n",
      "│ 6   ┆ 8   │\n",
      "└─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# Concatenation - vertical (like SQL UNION or pandas concat axis=0)\n",
    "df1 = pl.DataFrame({\"a\": [1, 2], \"b\": [3, 4]})\n",
    "df2 = pl.DataFrame({\"a\": [5, 6], \"b\": [7, 8]})\n",
    "\n",
    "print(\"Vertical concatenation:\")\n",
    "print(pl.concat([df1, df2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>a</th><th>b</th></tr><tr><td>u32</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>3</td></tr><tr><td>1</td><td>2</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────┬─────┬─────┐\n",
       "│ idx ┆ a   ┆ b   │\n",
       "│ --- ┆ --- ┆ --- │\n",
       "│ u32 ┆ i64 ┆ i64 │\n",
       "╞═════╪═════╪═════╡\n",
       "│ 0   ┆ 1   ┆ 3   │\n",
       "│ 1   ┆ 2   ┆ 4   │\n",
       "└─────┴─────┴─────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.with_row_index(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal concatenation:\n",
      "shape: (2, 3)\n",
      "┌─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   │\n",
      "│ --- ┆ --- ┆ --- │\n",
      "│ i64 ┆ i64 ┆ i64 │\n",
      "╞═════╪═════╪═════╡\n",
      "│ 1   ┆ 3   ┆ 9   │\n",
      "│ 2   ┆ 4   ┆ 10  │\n",
      "└─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# Concatenation - horizontal (like pandas concat axis=1)\n",
    "df3 = pl.DataFrame({\"c\": [9, 10]})\n",
    "\n",
    "print(\"Horizontal concatenation:\")\n",
    "print(pl.concat([df1, df3], how=\"horizontal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Lazy vs Eager Evaluation\n",
    "\n",
    "One of Polars' most powerful features - lazy evaluation allows query optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution:\n",
      "shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ name    ┆ salary │\n",
      "│ ---     ┆ ---    │\n",
      "│ str     ┆ i64    │\n",
      "╞═════════╪════════╡\n",
      "│ Frank   ┆ 100000 │\n",
      "│ David   ┆ 95000  │\n",
      "│ Charlie ┆ 90000  │\n",
      "└─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Eager execution (default)\n",
    "print(\"Eager execution:\")\n",
    "result_eager = (\n",
    "    df.filter(pl.col(\"age\") > 30)\n",
    "      .select([\"name\", \"salary\"])\n",
    "      .sort(\"salary\", descending=True)\n",
    ")\n",
    "print(result_eager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy execution (not yet computed):\n",
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "SORT BY [descending: [true]] [col(\"salary\")]\n",
      "  SELECT [col(\"name\"), col(\"salary\")]\n",
      "    FILTER [(col(\"age\")) > (30)]\n",
      "    FROM\n",
      "      DF [\"name\", \"age\", \"city\", \"salary\", ...]; PROJECT */5 COLUMNS\n",
      "\n",
      "Query plan:\n",
      "SORT BY [descending: [true]] [col(\"salary\")]\n",
      "  simple π 2/2 [\"name\", \"salary\"]\n",
      "    FILTER [(col(\"age\")) > (30)]\n",
      "    FROM\n",
      "      DF [\"name\", \"age\", \"city\", \"salary\", ...]; PROJECT[\"name\", \"salary\", \"age\"] 3/5 COLUMNS\n"
     ]
    }
   ],
   "source": [
    "# Lazy execution - convert to lazy\n",
    "print(\"Lazy execution (not yet computed):\")\n",
    "lazy_query = (\n",
    "    df.lazy()\n",
    "      .filter(pl.col(\"age\") > 30)\n",
    "      .select([\"name\", \"salary\"])\n",
    "      .sort(\"salary\", descending=True)\n",
    ")\n",
    "print(lazy_query)\n",
    "print(\"\\nQuery plan:\")\n",
    "print(lazy_query.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected result:\n",
      "shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ name    ┆ salary │\n",
      "│ ---     ┆ ---    │\n",
      "│ str     ┆ i64    │\n",
      "╞═════════╪════════╡\n",
      "│ Frank   ┆ 100000 │\n",
      "│ David   ┆ 95000  │\n",
      "│ Charlie ┆ 90000  │\n",
      "└─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Execute lazy query with collect()\n",
    "print(\"Collected result:\")\n",
    "result_lazy = lazy_query.collect()\n",
    "print(result_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized query plan:\n",
      "SLICE[offset: 0, len: 10]\n",
      "  Csv SCAN [data.csv]\n",
      "  PROJECT 2/4 COLUMNS\n",
      "  SELECTION: [(col(\"score\")) > (50)]\n",
      "\n",
      "Result:\n",
      "shape: (10, 2)\n",
      "┌─────────┬───────┐\n",
      "│ name    ┆ score │\n",
      "│ ---     ┆ ---   │\n",
      "│ str     ┆ i64   │\n",
      "╞═════════╪═══════╡\n",
      "│ User_2  ┆ 67    │\n",
      "│ User_5  ┆ 93    │\n",
      "│ User_8  ┆ 53    │\n",
      "│ User_12 ┆ 74    │\n",
      "│ User_13 ┆ 82    │\n",
      "│ User_14 ┆ 91    │\n",
      "│ User_17 ┆ 59    │\n",
      "│ User_19 ┆ 97    │\n",
      "│ User_20 ┆ 82    │\n",
      "│ User_23 ┆ 70    │\n",
      "└─────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Example showing optimization benefits\n",
    "# Polars will optimize this to only read necessary columns\n",
    "lazy_optimized = (\n",
    "    pl.scan_csv(\"data.csv\")\n",
    "      .select([\"name\", \"score\"])  # Only these columns will be read from CSV\n",
    "      .filter(pl.col(\"score\") > 50)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "print(\"Optimized query plan:\")\n",
    "print(lazy_optimized.explain())\n",
    "\n",
    "# Execute\n",
    "print(\"\\nResult:\")\n",
    "print(lazy_optimized.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Time Series Operations\n",
    "\n",
    "Working with dates and times in Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series data:\n",
      "shape: (10, 2)\n",
      "┌────────────┬───────────┐\n",
      "│ date       ┆ value     │\n",
      "│ ---        ┆ ---       │\n",
      "│ date       ┆ f64       │\n",
      "╞════════════╪═══════════╡\n",
      "│ 2024-01-01 ┆ -0.699253 │\n",
      "│ 2024-01-02 ┆ -1.789907 │\n",
      "│ 2024-01-03 ┆ -2.940818 │\n",
      "│ 2024-01-04 ┆ -4.756508 │\n",
      "│ 2024-01-05 ┆ -5.301946 │\n",
      "│ 2024-01-06 ┆ -5.64176  │\n",
      "│ 2024-01-07 ┆ -5.26977  │\n",
      "│ 2024-01-08 ┆ -6.63814  │\n",
      "│ 2024-01-09 ┆ -6.554948 │\n",
      "│ 2024-01-10 ┆ -7.978885 │\n",
      "└────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create time series data\n",
    "from datetime import date\n",
    "\n",
    "ts_df = pl.DataFrame({\n",
    "    \"date\": pl.date_range(\n",
    "        date(2024, 1, 1),\n",
    "        date(2024, 12, 31),\n",
    "        interval=\"1d\",\n",
    "        eager=True\n",
    "    ),\n",
    "    \"value\": np.random.randn(366).cumsum()\n",
    "})\n",
    "\n",
    "print(\"Time series data:\")\n",
    "print(ts_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract date components:\n",
      "shape: (10, 7)\n",
      "┌────────────┬───────────┬──────┬───────┬─────┬─────────┬─────────┐\n",
      "│ date       ┆ value     ┆ year ┆ month ┆ day ┆ weekday ┆ quarter │\n",
      "│ ---        ┆ ---       ┆ ---  ┆ ---   ┆ --- ┆ ---     ┆ ---     │\n",
      "│ date       ┆ f64       ┆ i32  ┆ i8    ┆ i8  ┆ i8      ┆ i8      │\n",
      "╞════════════╪═══════════╪══════╪═══════╪═════╪═════════╪═════════╡\n",
      "│ 2024-01-01 ┆ -0.699253 ┆ 2024 ┆ 1     ┆ 1   ┆ 1       ┆ 1       │\n",
      "│ 2024-01-02 ┆ -1.789907 ┆ 2024 ┆ 1     ┆ 2   ┆ 2       ┆ 1       │\n",
      "│ 2024-01-03 ┆ -2.940818 ┆ 2024 ┆ 1     ┆ 3   ┆ 3       ┆ 1       │\n",
      "│ 2024-01-04 ┆ -4.756508 ┆ 2024 ┆ 1     ┆ 4   ┆ 4       ┆ 1       │\n",
      "│ 2024-01-05 ┆ -5.301946 ┆ 2024 ┆ 1     ┆ 5   ┆ 5       ┆ 1       │\n",
      "│ 2024-01-06 ┆ -5.64176  ┆ 2024 ┆ 1     ┆ 6   ┆ 6       ┆ 1       │\n",
      "│ 2024-01-07 ┆ -5.26977  ┆ 2024 ┆ 1     ┆ 7   ┆ 7       ┆ 1       │\n",
      "│ 2024-01-08 ┆ -6.63814  ┆ 2024 ┆ 1     ┆ 8   ┆ 1       ┆ 1       │\n",
      "│ 2024-01-09 ┆ -6.554948 ┆ 2024 ┆ 1     ┆ 9   ┆ 2       ┆ 1       │\n",
      "│ 2024-01-10 ┆ -7.978885 ┆ 2024 ┆ 1     ┆ 10  ┆ 3       ┆ 1       │\n",
      "└────────────┴───────────┴──────┴───────┴─────┴─────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Extract date components\n",
    "print(\"Extract date components:\")\n",
    "result = ts_df.with_columns([\n",
    "    pl.col(\"date\").dt.year().alias(\"year\"),\n",
    "    pl.col(\"date\").dt.month().alias(\"month\"),\n",
    "    pl.col(\"date\").dt.day().alias(\"day\"),\n",
    "    pl.col(\"date\").dt.weekday().alias(\"weekday\"),\n",
    "    pl.col(\"date\").dt.quarter().alias(\"quarter\")\n",
    "]).head(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add days to date:\n",
      "shape: (5, 3)\n",
      "┌────────────┬───────────┬────────────────┐\n",
      "│ date       ┆ value     ┆ date_plus_week │\n",
      "│ ---        ┆ ---       ┆ ---            │\n",
      "│ date       ┆ f64       ┆ date           │\n",
      "╞════════════╪═══════════╪════════════════╡\n",
      "│ 2024-01-01 ┆ -0.699253 ┆ 2024-01-08     │\n",
      "│ 2024-01-02 ┆ -1.789907 ┆ 2024-01-09     │\n",
      "│ 2024-01-03 ┆ -2.940818 ┆ 2024-01-10     │\n",
      "│ 2024-01-04 ┆ -4.756508 ┆ 2024-01-11     │\n",
      "│ 2024-01-05 ┆ -5.301946 ┆ 2024-01-12     │\n",
      "└────────────┴───────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Datetime arithmetic\n",
    "print(\"Add days to date:\")\n",
    "result = ts_df.with_columns(\n",
    "    (pl.col(\"date\") + pl.duration(days=7)).alias(\"date_plus_week\")\n",
    ").head(5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly aggregation:\n",
      "shape: (12, 4)\n",
      "┌────────────┬────────────┬────────────┬────────────┐\n",
      "│ date       ┆ avg_value  ┆ min_value  ┆ max_value  │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│ date       ┆ f64        ┆ f64        ┆ f64        │\n",
      "╞════════════╪════════════╪════════════╪════════════╡\n",
      "│ 2024-01-01 ┆ -6.350379  ┆ -10.022018 ┆ -0.699253  │\n",
      "│ 2024-02-01 ┆ -1.11954   ┆ -5.24      ┆ 2.215408   │\n",
      "│ 2024-03-01 ┆ -2.040125  ┆ -6.737816  ┆ 2.438064   │\n",
      "│ 2024-04-01 ┆ -4.735409  ┆ -9.777551  ┆ -1.911747  │\n",
      "│ 2024-05-01 ┆ -2.500507  ┆ -4.727688  ┆ -0.857876  │\n",
      "│ …          ┆ …          ┆ …          ┆ …          │\n",
      "│ 2024-08-01 ┆ -21.442485 ┆ -24.797178 ┆ -16.060661 │\n",
      "│ 2024-09-01 ┆ -26.900073 ┆ -32.66983  ┆ -19.268094 │\n",
      "│ 2024-10-01 ┆ -35.113639 ┆ -38.371231 ┆ -30.392645 │\n",
      "│ 2024-11-01 ┆ -32.572655 ┆ -39.252343 ┆ -29.949984 │\n",
      "│ 2024-12-01 ┆ -30.502186 ┆ -33.390259 ┆ -26.927342 │\n",
      "└────────────┴────────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Resample and aggregate (like pandas resample)\n",
    "print(\"Monthly aggregation:\")\n",
    "monthly = (\n",
    "    ts_df.group_by_dynamic(\"date\", every=\"1mo\")\n",
    "         .agg([\n",
    "             pl.col(\"value\").mean().alias(\"avg_value\"),\n",
    "             pl.col(\"value\").min().alias(\"min_value\"),\n",
    "             pl.col(\"value\").max().alias(\"max_value\")\n",
    "         ])\n",
    ")\n",
    "print(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-day rolling average:\n",
      "shape: (20, 3)\n",
      "┌────────────┬───────────┬────────────────┐\n",
      "│ date       ┆ value     ┆ rolling_avg_7d │\n",
      "│ ---        ┆ ---       ┆ ---            │\n",
      "│ date       ┆ f64       ┆ f64            │\n",
      "╞════════════╪═══════════╪════════════════╡\n",
      "│ 2024-01-01 ┆ -0.699253 ┆ null           │\n",
      "│ 2024-01-02 ┆ -1.789907 ┆ null           │\n",
      "│ 2024-01-03 ┆ -2.940818 ┆ null           │\n",
      "│ 2024-01-04 ┆ -4.756508 ┆ null           │\n",
      "│ 2024-01-05 ┆ -5.301946 ┆ null           │\n",
      "│ …          ┆ …         ┆ …              │\n",
      "│ 2024-01-16 ┆ -8.814478 ┆ -9.354376      │\n",
      "│ 2024-01-17 ┆ -7.908645 ┆ -9.344342      │\n",
      "│ 2024-01-18 ┆ -8.074913 ┆ -9.081206      │\n",
      "│ 2024-01-19 ┆ -7.392987 ┆ -8.736533      │\n",
      "│ 2024-01-20 ┆ -8.291755 ┆ -8.533982      │\n",
      "└────────────┴───────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Rolling window operations\n",
    "print(\"7-day rolling average:\")\n",
    "result = ts_df.with_columns(\n",
    "    pl.col(\"value\").rolling_mean(window_size=7).alias(\"rolling_avg_7d\")\n",
    ").head(20)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. String Operations\n",
    "\n",
    "String manipulation in Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String data:\n",
      "shape: (5, 1)\n",
      "┌───────────────────┐\n",
      "│ text              │\n",
      "│ ---               │\n",
      "│ str               │\n",
      "╞═══════════════════╡\n",
      "│ hello world       │\n",
      "│ POLARS is FAST    │\n",
      "│   pandas          │\n",
      "│ data-science-2024 │\n",
      "│ user@example.com  │\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create string data\n",
    "str_df = pl.DataFrame({\n",
    "    \"text\": [\n",
    "        \"hello world\",\n",
    "        \"POLARS is FAST\",\n",
    "        \"  pandas  \",\n",
    "        \"data-science-2024\",\n",
    "        \"user@example.com\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"String data:\")\n",
    "print(str_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String transformations:\n",
      "shape: (5, 5)\n",
      "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬────────┐\n",
      "│ text              ┆ upper             ┆ lower             ┆ stripped          ┆ length │\n",
      "│ ---               ┆ ---               ┆ ---               ┆ ---               ┆ ---    │\n",
      "│ str               ┆ str               ┆ str               ┆ str               ┆ u32    │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪════════╡\n",
      "│ hello world       ┆ HELLO WORLD       ┆ hello world       ┆ hello world       ┆ 11     │\n",
      "│ POLARS is FAST    ┆ POLARS IS FAST    ┆ polars is fast    ┆ POLARS is FAST    ┆ 14     │\n",
      "│   pandas          ┆   PANDAS          ┆   pandas          ┆ pandas            ┆ 10     │\n",
      "│ data-science-2024 ┆ DATA-SCIENCE-2024 ┆ data-science-2024 ┆ data-science-2024 ┆ 17     │\n",
      "│ user@example.com  ┆ USER@EXAMPLE.COM  ┆ user@example.com  ┆ user@example.com  ┆ 16     │\n",
      "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# String methods\n",
    "print(\"String transformations:\")\n",
    "result = str_df.with_columns([\n",
    "    pl.col(\"text\").str.to_uppercase().alias(\"upper\"),\n",
    "    pl.col(\"text\").str.to_lowercase().alias(\"lower\"),\n",
    "    pl.col(\"text\").str.strip_chars().alias(\"stripped\"),\n",
    "    pl.col(\"text\").str.len_chars().alias(\"length\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String matching:\n",
      "shape: (5, 4)\n",
      "┌───────────────────┬────────────┬──────────┬────────┐\n",
      "│ text              ┆ contains_a ┆ starts_h ┆ ends_m │\n",
      "│ ---               ┆ ---        ┆ ---      ┆ ---    │\n",
      "│ str               ┆ bool       ┆ bool     ┆ bool   │\n",
      "╞═══════════════════╪════════════╪══════════╪════════╡\n",
      "│ hello world       ┆ false      ┆ true     ┆ false  │\n",
      "│ POLARS is FAST    ┆ false      ┆ false    ┆ false  │\n",
      "│   pandas          ┆ true       ┆ false    ┆ false  │\n",
      "│ data-science-2024 ┆ true       ┆ false    ┆ false  │\n",
      "│ user@example.com  ┆ true       ┆ false    ┆ true   │\n",
      "└───────────────────┴────────────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# String contains, starts_with, ends_with\n",
    "print(\"String matching:\")\n",
    "result = str_df.with_columns([\n",
    "    pl.col(\"text\").str.contains(\"a\").alias(\"contains_a\"),\n",
    "    pl.col(\"text\").str.starts_with(\"h\").alias(\"starts_h\"),\n",
    "    pl.col(\"text\").str.ends_with(\"m\").alias(\"ends_m\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace:\n",
      "shape: (5, 2)\n",
      "┌───────────────────┬───────────────────┐\n",
      "│ text              ┆ replaced          │\n",
      "│ ---               ┆ ---               │\n",
      "│ str               ┆ str               │\n",
      "╞═══════════════════╪═══════════════════╡\n",
      "│ hello world       ┆ hello world       │\n",
      "│ POLARS is FAST    ┆ POLARS is FAST    │\n",
      "│   pandas          ┆   pandas          │\n",
      "│ data-science-2024 ┆ data_science-2024 │\n",
      "│ user@example.com  ┆ user@example.com  │\n",
      "└───────────────────┴───────────────────┘\n",
      "\n",
      "Split:\n",
      "shape: (5, 2)\n",
      "┌───────────────────┬─────────────────────────────┐\n",
      "│ text              ┆ split                       │\n",
      "│ ---               ┆ ---                         │\n",
      "│ str               ┆ list[str]                   │\n",
      "╞═══════════════════╪═════════════════════════════╡\n",
      "│ hello world       ┆ [\"hello world\"]             │\n",
      "│ POLARS is FAST    ┆ [\"POLARS is FAST\"]          │\n",
      "│   pandas          ┆ [\"  pandas  \"]              │\n",
      "│ data-science-2024 ┆ [\"data\", \"science\", \"2024\"] │\n",
      "│ user@example.com  ┆ [\"user@example.com\"]        │\n",
      "└───────────────────┴─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# String replace and split\n",
    "print(\"Replace:\")\n",
    "print(str_df.with_columns(\n",
    "    pl.col(\"text\").str.replace(\"-\", \"_\").alias(\"replaced\")\n",
    "))\n",
    "\n",
    "print(\"\\nSplit:\")\n",
    "print(str_df.with_columns(\n",
    "    pl.col(\"text\").str.split(\"-\").alias(\"split\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract email domain:\n",
      "shape: (2, 2)\n",
      "┌──────────────────┬─────────────┐\n",
      "│ email            ┆ domain      │\n",
      "│ ---              ┆ ---         │\n",
      "│ str              ┆ str         │\n",
      "╞══════════════════╪═════════════╡\n",
      "│ user@example.com ┆ example.com │\n",
      "│ test@domain.org  ┆ domain.org  │\n",
      "└──────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Extract with regex\n",
    "print(\"Extract email domain:\")\n",
    "email_df = pl.DataFrame({\"email\": [\"user@example.com\", \"test@domain.org\"]})\n",
    "result = email_df.with_columns(\n",
    "    pl.col(\"email\").str.extract(r\"@(.+)\", group_index=1).alias(\"domain\")\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Window Functions\n",
    "\n",
    "Powerful window operations (like SQL window functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales data:\n",
      "shape: (10, 3)\n",
      "┌────────────┬─────────┬───────┐\n",
      "│ date       ┆ product ┆ sales │\n",
      "│ ---        ┆ ---     ┆ ---   │\n",
      "│ date       ┆ str     ┆ i64   │\n",
      "╞════════════╪═════════╪═══════╡\n",
      "│ 2024-01-01 ┆ A       ┆ 100   │\n",
      "│ 2024-01-02 ┆ B       ┆ 150   │\n",
      "│ 2024-01-03 ┆ A       ┆ 120   │\n",
      "│ 2024-01-04 ┆ B       ┆ 160   │\n",
      "│ 2024-01-05 ┆ A       ┆ 110   │\n",
      "│ 2024-01-06 ┆ B       ┆ 140   │\n",
      "│ 2024-01-07 ┆ A       ┆ 130   │\n",
      "│ 2024-01-08 ┆ B       ┆ 170   │\n",
      "│ 2024-01-09 ┆ A       ┆ 115   │\n",
      "│ 2024-01-10 ┆ B       ┆ 155   │\n",
      "└────────────┴─────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Sample data for window functions\n",
    "sales_df = pl.DataFrame({\n",
    "    \"date\": pl.date_range(date(2024, 1, 1), date(2024, 1, 10), interval=\"1d\", eager=True),\n",
    "    \"product\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n",
    "    \"sales\": [100, 150, 120, 160, 110, 140, 130, 170, 115, 155]\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sales per product (window function):\n",
      "shape: (10, 5)\n",
      "┌────────────┬─────────┬───────┬───────────────────────┬─────────────────────────┐\n",
      "│ date       ┆ product ┆ sales ┆ avg_sales_per_product ┆ total_sales_per_product │\n",
      "│ ---        ┆ ---     ┆ ---   ┆ ---                   ┆ ---                     │\n",
      "│ date       ┆ str     ┆ i64   ┆ f64                   ┆ i64                     │\n",
      "╞════════════╪═════════╪═══════╪═══════════════════════╪═════════════════════════╡\n",
      "│ 2024-01-01 ┆ A       ┆ 100   ┆ 115.0                 ┆ 575                     │\n",
      "│ 2024-01-02 ┆ B       ┆ 150   ┆ 155.0                 ┆ 775                     │\n",
      "│ 2024-01-03 ┆ A       ┆ 120   ┆ 115.0                 ┆ 575                     │\n",
      "│ 2024-01-04 ┆ B       ┆ 160   ┆ 155.0                 ┆ 775                     │\n",
      "│ 2024-01-05 ┆ A       ┆ 110   ┆ 115.0                 ┆ 575                     │\n",
      "│ 2024-01-06 ┆ B       ┆ 140   ┆ 155.0                 ┆ 775                     │\n",
      "│ 2024-01-07 ┆ A       ┆ 130   ┆ 115.0                 ┆ 575                     │\n",
      "│ 2024-01-08 ┆ B       ┆ 170   ┆ 155.0                 ┆ 775                     │\n",
      "│ 2024-01-09 ┆ A       ┆ 115   ┆ 115.0                 ┆ 575                     │\n",
      "│ 2024-01-10 ┆ B       ┆ 155   ┆ 155.0                 ┆ 775                     │\n",
      "└────────────┴─────────┴───────┴───────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Window aggregation with over()\n",
    "print(\"Average sales per product (window function):\")\n",
    "result = sales_df.with_columns([\n",
    "    pl.col(\"sales\").mean().over(\"product\").alias(\"avg_sales_per_product\"),\n",
    "    pl.col(\"sales\").sum().over(\"product\").alias(\"total_sales_per_product\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank sales within each product:\n",
      "shape: (10, 4)\n",
      "┌────────────┬─────────┬───────┬──────┐\n",
      "│ date       ┆ product ┆ sales ┆ rank │\n",
      "│ ---        ┆ ---     ┆ ---   ┆ ---  │\n",
      "│ date       ┆ str     ┆ i64   ┆ u32  │\n",
      "╞════════════╪═════════╪═══════╪══════╡\n",
      "│ 2024-01-01 ┆ A       ┆ 100   ┆ 1    │\n",
      "│ 2024-01-05 ┆ A       ┆ 110   ┆ 2    │\n",
      "│ 2024-01-09 ┆ A       ┆ 115   ┆ 3    │\n",
      "│ 2024-01-03 ┆ A       ┆ 120   ┆ 4    │\n",
      "│ 2024-01-07 ┆ A       ┆ 130   ┆ 5    │\n",
      "│ 2024-01-06 ┆ B       ┆ 140   ┆ 1    │\n",
      "│ 2024-01-02 ┆ B       ┆ 150   ┆ 2    │\n",
      "│ 2024-01-10 ┆ B       ┆ 155   ┆ 3    │\n",
      "│ 2024-01-04 ┆ B       ┆ 160   ┆ 4    │\n",
      "│ 2024-01-08 ┆ B       ┆ 170   ┆ 5    │\n",
      "└────────────┴─────────┴───────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "# Ranking within groups\n",
    "print(\"Rank sales within each product:\")\n",
    "result = sales_df.with_columns([\n",
    "    pl.col(\"sales\").rank(method=\"ordinal\").over(\"product\").alias(\"rank\")\n",
    "]).sort([\"product\", \"rank\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum within groups\n",
    "print(\"Cumulative sales per product:\")\n",
    "result = sales_df.with_columns(\n",
    "    pl.col(\"sales\").cum_sum().over(\"product\").alias(\"cumulative_sales\")\n",
    ").sort([\"product\", \"date\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift/lag operations\n",
    "print(\"Previous day sales (lag):\")\n",
    "result = sales_df.with_columns([\n",
    "    pl.col(\"sales\").shift(1).over(\"product\").alias(\"prev_sales\"),\n",
    "    (pl.col(\"sales\") - pl.col(\"sales\").shift(1).over(\"product\")).alias(\"sales_change\")\n",
    "]).sort([\"product\", \"date\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Performance Optimization\n",
    "\n",
    "Tips and tricks for maximizing Polars performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use lazy evaluation for large datasets\n",
    "print(\"Use scan_* methods for lazy reading:\")\n",
    "lazy_query = (\n",
    "    pl.scan_csv(\"data.csv\")\n",
    "      .filter(pl.col(\"score\") > 50)\n",
    "      .select([\"name\", \"score\"])\n",
    "      .head(5)\n",
    ")\n",
    "print(lazy_query.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use appropriate data types (smaller = faster)\n",
    "print(\"Downcast to smaller dtypes when possible:\")\n",
    "df_optimized = pl.DataFrame({\n",
    "    \"id\": pl.Series([1, 2, 3], dtype=pl.UInt32),  # Instead of Int64\n",
    "    \"value\": pl.Series([1.0, 2.0, 3.0], dtype=pl.Float32)  # Instead of Float64\n",
    "})\n",
    "print(df_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prefer Parquet over CSV for I/O\n",
    "import time\n",
    "\n",
    "# Write\n",
    "start = time.time()\n",
    "sample_df.write_parquet(\"test.parquet\")\n",
    "parquet_write_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "sample_df.write_csv(\"test.csv\")\n",
    "csv_write_time = time.time() - start\n",
    "\n",
    "print(f\"Parquet write time: {parquet_write_time:.4f}s\")\n",
    "print(f\"CSV write time: {csv_write_time:.4f}s\")\n",
    "\n",
    "# Read\n",
    "start = time.time()\n",
    "_ = pl.read_parquet(\"test.parquet\")\n",
    "parquet_read_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = pl.read_csv(\"test.csv\")\n",
    "csv_read_time = time.time() - start\n",
    "\n",
    "print(f\"Parquet read time: {parquet_read_time:.4f}s\")\n",
    "print(f\"CSV read time: {csv_read_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Use expression chaining instead of multiple operations\n",
    "print(\"Chain operations efficiently:\")\n",
    "\n",
    "# Less efficient: multiple passes\n",
    "result1 = df.with_columns((pl.col(\"salary\") * 1.1).alias(\"new_salary\"))\n",
    "result1 = result1.with_columns((pl.col(\"age\") + 1).alias(\"new_age\"))\n",
    "\n",
    "# More efficient: single pass\n",
    "result2 = df.with_columns([\n",
    "    (pl.col(\"salary\") * 1.1).alias(\"new_salary\"),\n",
    "    (pl.col(\"age\") + 1).alias(\"new_age\")\n",
    "])\n",
    "\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use streaming for very large datasets\n",
    "print(\"Streaming execution for large data:\")\n",
    "lazy_query = (\n",
    "    pl.scan_csv(\"data.csv\")\n",
    "      .filter(pl.col(\"score\") > 50)\n",
    "      .group_by(\"name\")\n",
    "      .agg(pl.col(\"score\").mean())\n",
    ")\n",
    "\n",
    "# Collect with streaming (processes data in chunks)\n",
    "result = lazy_query.collect(streaming=True)\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Advanced Features\n",
    "\n",
    "Advanced Polars capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Explode (unnest lists)\n",
    "df_lists = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\"],\n",
    "    \"scores\": [[85, 90, 88], [92, 87, 95]]\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df_lists)\n",
    "\n",
    "print(\"\\nExploded:\")\n",
    "print(df_lists.explode(\"scores\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pivot (wide format)\n",
    "pivot_df = pl.DataFrame({\n",
    "    \"date\": [\"2024-01-01\", \"2024-01-01\", \"2024-01-02\", \"2024-01-02\"],\n",
    "    \"product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"sales\": [100, 150, 120, 160]\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(pivot_df)\n",
    "\n",
    "print(\"\\nPivoted:\")\n",
    "print(pivot_df.pivot(values=\"sales\", index=\"date\", columns=\"product\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Melt (long format)\n",
    "wide_df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\"],\n",
    "    \"math\": [85, 90],\n",
    "    \"science\": [88, 92],\n",
    "    \"english\": [90, 87]\n",
    "})\n",
    "\n",
    "print(\"Wide format:\")\n",
    "print(wide_df)\n",
    "\n",
    "print(\"\\nMelted (long format):\")\n",
    "print(wide_df.melt(id_vars=\"name\", variable_name=\"subject\", value_name=\"score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Apply custom functions with map_elements (use sparingly - slower than expressions)\n",
    "def custom_function(x):\n",
    "    return x * 2 + 10\n",
    "\n",
    "print(\"Apply custom function:\")\n",
    "result = df.select([\n",
    "    pl.col(\"name\"),\n",
    "    pl.col(\"age\").map_elements(custom_function, return_dtype=pl.Int64).alias(\"custom\")\n",
    "])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SQL interface\n",
    "# Register DataFrame in SQL context\n",
    "ctx = pl.SQLContext()\n",
    "ctx.register(\"employees\", df)\n",
    "\n",
    "print(\"Query with SQL:\")\n",
    "result = ctx.execute(\"\"\"\n",
    "    SELECT name, salary, department\n",
    "    FROM employees\n",
    "    WHERE salary > 80000\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").collect()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Categorical data for memory efficiency\n",
    "cat_df = pl.DataFrame({\n",
    "    \"category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\", \"C\"] * 1000\n",
    "})\n",
    "\n",
    "print(\"String dtype memory:\")\n",
    "print(f\"{cat_df.estimated_size('mb'):.4f} MB\")\n",
    "\n",
    "# Convert to categorical\n",
    "cat_df_opt = cat_df.with_columns(\n",
    "    pl.col(\"category\").cast(pl.Categorical)\n",
    ")\n",
    "\n",
    "print(\"\\nCategorical dtype memory:\")\n",
    "print(f\"{cat_df_opt.estimated_size('mb'):.4f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Struct columns (nested data)\n",
    "struct_df = pl.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"address\": [\n",
    "        {\"city\": \"NYC\", \"zip\": \"10001\"},\n",
    "        {\"city\": \"LA\", \"zip\": \"90001\"},\n",
    "        {\"city\": \"SF\", \"zip\": \"94101\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Struct column:\")\n",
    "print(struct_df)\n",
    "\n",
    "print(\"\\nAccess struct fields:\")\n",
    "print(struct_df.with_columns([\n",
    "    pl.col(\"address\").struct.field(\"city\").alias(\"city\"),\n",
    "    pl.col(\"address\").struct.field(\"zip\").alias(\"zip\")\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Takeaways\n",
    "\n",
    "### When to Use Polars vs Pandas/PySpark:\n",
    "\n",
    "**Use Polars when:**\n",
    "- You need maximum performance on a single machine\n",
    "- Your data fits in memory (or can be streamed)\n",
    "- You want better memory efficiency\n",
    "- You need lazy evaluation and query optimization\n",
    "\n",
    "**Use Pandas when:**\n",
    "- You need maximum ecosystem compatibility\n",
    "- Your data is small and performance isn't critical\n",
    "- You're working with legacy code\n",
    "\n",
    "**Use PySpark when:**\n",
    "- Your data is too large for a single machine\n",
    "- You need distributed computing\n",
    "- You already have a Spark cluster\n",
    "\n",
    "### Key Polars Concepts:\n",
    "1. **Expressions**: The core abstraction for data manipulation\n",
    "2. **Lazy Evaluation**: Use `.lazy()` and `scan_*` for query optimization\n",
    "3. **Arrow Backend**: Zero-copy operations for speed\n",
    "4. **Parallelization**: Automatic multi-threading\n",
    "5. **Type System**: Strong typing helps catch errors early\n",
    "\n",
    "### Performance Tips:\n",
    "- Use Parquet for storage\n",
    "- Chain operations in a single expression\n",
    "- Use lazy evaluation for large datasets\n",
    "- Prefer expressions over custom functions\n",
    "- Use appropriate dtypes (smaller when possible)\n",
    "- Use streaming for very large data\n",
    "\n",
    "### Migration from Pandas:\n",
    "- `df[df['col'] > 5]` → `df.filter(pl.col('col') > 5)`\n",
    "- `df['new'] = df['old'] * 2` → `df.with_columns((pl.col('old') * 2).alias('new'))`\n",
    "- `df.groupby('col').agg({'x': 'mean'})` → `df.group_by('col').agg(pl.col('x').mean())`\n",
    "- `df.merge(other)` → `df.join(other)`\n",
    "\n",
    "Happy data wrangling with Polars!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:\n",
    "\n",
    "1. Load the data.csv file and find all records where score > 75\n",
    "2. Calculate the average score per day of the week\n",
    "3. Create a new column that categorizes scores: Low (0-33), Medium (34-66), High (67-100)\n",
    "4. Find the top 10 users by score using window functions\n",
    "5. Write a lazy query that filters, groups, and aggregates the data, then optimize it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
