{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Lazy Evaluation & Query Optimization\n",
    "\n",
    "This notebook covers LazyFrames, query optimization, and when to use lazy vs eager evaluation.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Eager**: Operations execute immediately (like pandas)\n",
    "- **Lazy**: Operations are planned first, optimized, then executed\n",
    "- **Query Plan**: Visual representation of planned operations\n",
    "- **Optimizations**: Automatic improvements Polars makes to your queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Eager vs Lazy Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "df = pl.DataFrame({\n",
    "    'customer_id': range(1, 11),\n",
    "    'name': [f'Customer_{i}' for i in range(1, 11)],\n",
    "    'age': [25, 34, 28, 42, 31, 55, 23, 38, 45, 29],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'NYC', 'Boston', 'LA', 'Chicago', 'NYC', 'Boston', 'LA'],\n",
    "    'purchases': [5, 12, 3, 18, 7, 22, 4, 15, 9, 11],\n",
    "    'total_spent': [250.5, 680.2, 120.0, 950.8, 340.5, 1100.0, 180.3, 720.5, 450.0, 520.8]\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution (default DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each operation executes immediately\n",
    "print(\"EAGER EXECUTION:\")\n",
    "print(\"Step 1: Filter...\")\n",
    "filtered = df.filter(pl.col('age') > 30)  # Executes NOW\n",
    "print(f\"Rows after filter: {len(filtered)}\")\n",
    "\n",
    "print(\"\\nStep 2: Select columns...\")\n",
    "selected = filtered.select(['name', 'city', 'total_spent'])  # Executes NOW\n",
    "print(f\"Columns: {selected.columns}\")\n",
    "\n",
    "print(\"\\nStep 3: Sort...\")\n",
    "result = selected.sort('total_spent', descending=True)  # Executes NOW\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Execution (LazyFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LazyFrame\n",
    "lazy_df = df.lazy()  # or pl.scan_csv(), pl.scan_parquet(), etc.\n",
    "\n",
    "print(\"LAZY EXECUTION:\")\n",
    "print(\"Building query plan (nothing executes yet)...\\n\")\n",
    "\n",
    "# Chain operations - nothing executes yet!\n",
    "lazy_query = (\n",
    "    lazy_df\n",
    "    .filter(pl.col('age') > 30)\n",
    "    .select(['name', 'city', 'total_spent'])\n",
    "    .sort('total_spent', descending=True)\n",
    ")\n",
    "\n",
    "print(f\"Type: {type(lazy_query)}\")\n",
    "print(\"Query has been planned but NOT executed yet!\")\n",
    "print(\"\\nTo execute, call .collect():\")\n",
    "\n",
    "# Execute the optimized query\n",
    "result = lazy_query.collect()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Query Plans - Understanding What Polars Does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the naive (unoptimized) query plan\n",
    "print(\"NAIVE QUERY PLAN (before optimization):\")\n",
    "print(lazy_query.explain(optimized=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the optimized query plan\n",
    "print(\"OPTIMIZED QUERY PLAN:\")\n",
    "print(lazy_query.explain(optimized=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Automatic Optimizations\n",
    "\n",
    "Polars automatically applies several optimizations:\n",
    "1. **Projection Pushdown**: Select only needed columns as early as possible\n",
    "2. **Predicate Pushdown**: Apply filters as early as possible\n",
    "3. **Slice Pushdown**: Apply limits/slices early\n",
    "4. **Common Subexpression Elimination**: Avoid redundant calculations\n",
    "5. **Simplification**: Simplify complex expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 1: Projection Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger dataset to see optimization impact\n",
    "large_df = pl.DataFrame({\n",
    "    'id': range(100000),\n",
    "    'col1': np.random.randn(100000),\n",
    "    'col2': np.random.randn(100000),\n",
    "    'col3': np.random.randn(100000),\n",
    "    'col4': np.random.randn(100000),\n",
    "    'col5': np.random.randn(100000),\n",
    "    'col6': np.random.randn(100000),\n",
    "    'col7': np.random.randn(100000),\n",
    "    'col8': np.random.randn(100000),\n",
    "    'col9': np.random.randn(100000),\n",
    "    'col10': np.random.randn(100000),\n",
    "})\n",
    "\n",
    "# Lazy query that only needs 2 columns\n",
    "query = (\n",
    "    large_df.lazy()\n",
    "    .filter(pl.col('col1') > 0)\n",
    "    .select(['id', 'col1'])  # Only need 2 columns\n",
    ")\n",
    "\n",
    "print(\"Query Plan - Notice how 'select' happens BEFORE filter:\")\n",
    "print(query.explain())\n",
    "print(\"\\nProjection pushdown: Polars reads only 'id' and 'col1', ignoring other 8 columns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 2: Predicate Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter is applied as early as possible\n",
    "query = (\n",
    "    large_df.lazy()\n",
    "    .select(['id', 'col1', 'col2'])\n",
    "    .with_columns((pl.col('col1') * 2).alias('col1_doubled'))\n",
    "    .filter(pl.col('id') < 1000)  # Filter at the end\n",
    ")\n",
    "\n",
    "print(\"Query Plan - Notice filter moves to the top:\")\n",
    "print(query.explain())\n",
    "print(\"\\nPredicate pushdown: Filter applied early, reducing data processed in later steps!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 3: Slice Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using .head() or .limit(), Polars optimizes to read only needed rows\n",
    "query = (\n",
    "    large_df.lazy()\n",
    "    .select(['id', 'col1'])\n",
    "    .sort('col1')\n",
    "    .head(10)  # Only need 10 rows\n",
    ")\n",
    "\n",
    "print(\"Query Plan with head(10):\")\n",
    "print(query.explain())\n",
    "print(\"\\nSlice pushdown: Polars knows to stop processing after finding top 10!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 4: Common Subexpression Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use the same expression multiple times, Polars calculates it once\n",
    "query = (\n",
    "    df.lazy()\n",
    "    .with_columns([\n",
    "        (pl.col('total_spent') / pl.col('purchases')).alias('avg_per_purchase'),\n",
    "        ((pl.col('total_spent') / pl.col('purchases')) * 1.1).alias('avg_with_tax'),\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(\"Query with repeated expression (total_spent / purchases):\")\n",
    "print(query.explain())\n",
    "print(\"\\nPolars calculates 'total_spent / purchases' once and reuses it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create large dataset\n",
    "n_rows = 1_000_000\n",
    "large_data = pl.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "    'value1': np.random.randn(n_rows),\n",
    "    'value2': np.random.randn(n_rows),\n",
    "    'value3': np.random.randn(n_rows),\n",
    "    'value4': np.random.randn(n_rows),\n",
    "    'value5': np.random.randn(n_rows),\n",
    "})\n",
    "\n",
    "print(f\"Dataset: {n_rows:,} rows, {len(large_data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query - Eager execution\n",
    "start = time.time()\n",
    "eager_result = (\n",
    "    large_data\n",
    "    .filter(pl.col('category').is_in(['A', 'B']))\n",
    "    .filter(pl.col('value1') > 0)\n",
    "    .select(['id', 'category', 'value1', 'value2'])\n",
    "    .with_columns((pl.col('value1') * pl.col('value2')).alias('product'))\n",
    "    .group_by('category')\n",
    "    .agg([\n",
    "        pl.col('product').mean().alias('avg_product'),\n",
    "        pl.col('product').std().alias('std_product'),\n",
    "    ])\n",
    ")\n",
    "eager_time = time.time() - start\n",
    "\n",
    "print(f\"Eager execution: {eager_time:.4f} seconds\")\n",
    "print(eager_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same query - Lazy execution\n",
    "start = time.time()\n",
    "lazy_result = (\n",
    "    large_data.lazy()\n",
    "    .filter(pl.col('category').is_in(['A', 'B']))\n",
    "    .filter(pl.col('value1') > 0)\n",
    "    .select(['id', 'category', 'value1', 'value2'])\n",
    "    .with_columns((pl.col('value1') * pl.col('value2')).alias('product'))\n",
    "    .group_by('category')\n",
    "    .agg([\n",
    "        pl.col('product').mean().alias('avg_product'),\n",
    "        pl.col('product').std().alias('std_product'),\n",
    "    ])\n",
    "    .collect()\n",
    ")\n",
    "lazy_time = time.time() - start\n",
    "\n",
    "print(f\"Lazy execution: {lazy_time:.4f} seconds\")\n",
    "print(lazy_result)\n",
    "print(f\"\\nSpeedup: {eager_time/lazy_time:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Streaming Mode (for datasets larger than RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming processes data in chunks - can handle datasets larger than RAM\n",
    "query = (\n",
    "    large_data.lazy()\n",
    "    .filter(pl.col('category') == 'A')\n",
    "    .select(['value1', 'value2'])\n",
    "    .group_by(pl.col('value1').cast(pl.Int32))\n",
    "    .agg(pl.col('value2').mean())\n",
    ")\n",
    "\n",
    "print(\"Regular collect():\")\n",
    "start = time.time()\n",
    "result1 = query.collect()\n",
    "time1 = time.time() - start\n",
    "print(f\"Time: {time1:.4f}s\")\n",
    "\n",
    "print(\"\\nStreaming collect():\")\n",
    "start = time.time()\n",
    "result2 = query.collect(streaming=True)\n",
    "time2 = time.time() - start\n",
    "print(f\"Time: {time2:.4f}s\")\n",
    "\n",
    "print(f\"\\nStreaming uses less memory (processes in chunks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: LazyFrame Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect() - Execute and return DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_query = df.lazy().filter(pl.col('age') > 30)\n",
    "\n",
    "# Execute and get DataFrame\n",
    "result = lazy_query.collect()\n",
    "print(f\"Type after collect(): {type(result)}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fetch() - Execute on first N rows (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query on first 5 rows before running on full dataset\n",
    "sample_result = lazy_query.fetch(5)\n",
    "print(\"fetch(5) - Quick test on first 5 rows:\")\n",
    "print(sample_result)\n",
    "print(\"\\nUse fetch() to debug/test queries on large datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe_plan() and describe_optimized_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    df.lazy()\n",
    "    .filter(pl.col('age') > 30)\n",
    "    .select(['name', 'total_spent'])\n",
    "    .sort('total_spent', descending=True)\n",
    ")\n",
    "\n",
    "print(\"Naive plan:\")\n",
    "print(query.describe_plan())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Optimized plan:\")\n",
    "print(query.describe_optimized_plan())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sink_parquet() and sink_csv() - Write without loading into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and write directly to file without loading full result in memory\n",
    "query = (\n",
    "    large_data.lazy()\n",
    "    .filter(pl.col('category') == 'A')\n",
    "    .select(['id', 'value1', 'value2'])\n",
    ")\n",
    "\n",
    "# Write directly to parquet (efficient for large results)\n",
    "query.sink_parquet('/tmp/output.parquet')\n",
    "print(\"Written to /tmp/output.parquet without loading in memory!\")\n",
    "\n",
    "# Verify\n",
    "result = pl.read_parquet('/tmp/output.parquet')\n",
    "print(f\"\\nRows written: {len(result)}\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Scan Functions (Lazy from Start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some data first\n",
    "df.write_csv('/tmp/customers.csv')\n",
    "df.write_parquet('/tmp/customers.parquet')\n",
    "\n",
    "print(\"Files created for scanning demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scan_csv() vs read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv - Eager (loads entire file)\n",
    "eager_df = pl.read_csv('/tmp/customers.csv')\n",
    "print(f\"read_csv type: {type(eager_df)}\")\n",
    "\n",
    "# scan_csv - Lazy (doesn't load until .collect())\n",
    "lazy_df = pl.scan_csv('/tmp/customers.csv')\n",
    "print(f\"scan_csv type: {type(lazy_df)}\")\n",
    "\n",
    "# Advantage: Can filter/select before loading\n",
    "result = (\n",
    "    pl.scan_csv('/tmp/customers.csv')\n",
    "    .select(['name', 'city'])  # Only read these columns!\n",
    "    .filter(pl.col('city') == 'NYC')  # Only load filtered rows!\n",
    "    .collect()\n",
    ")\n",
    "print(\"\\nFiltered result (only read needed columns/rows):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scan_parquet() - Even Better Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet is columnar - can skip columns at file level\n",
    "result = (\n",
    "    pl.scan_parquet('/tmp/customers.parquet')\n",
    "    .select(['name', 'total_spent'])\n",
    "    .filter(pl.col('total_spent') > 500)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"Parquet scan with projection pushdown:\")\n",
    "print(result)\n",
    "print(\"\\nParquet format allows reading only needed columns from disk!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Lazy Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 1: Lazy Join Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_large = pl.DataFrame({\n",
    "    'customer_id': range(10000),\n",
    "    'name': [f'Customer_{i}' for i in range(10000)],\n",
    "    'segment': np.random.choice(['A', 'B', 'C'], 10000)\n",
    "})\n",
    "\n",
    "orders_large = pl.DataFrame({\n",
    "    'order_id': range(50000),\n",
    "    'customer_id': np.random.randint(0, 10000, 50000),\n",
    "    'amount': np.random.uniform(10, 1000, 50000)\n",
    "})\n",
    "\n",
    "# Lazy join with filters - optimized automatically\n",
    "query = (\n",
    "    customers_large.lazy()\n",
    "    .join(orders_large.lazy(), on='customer_id')\n",
    "    .filter(pl.col('segment') == 'A')  # Filter pushed before join!\n",
    "    .select(['customer_id', 'name', 'amount'])\n",
    "    .group_by('customer_id')\n",
    "    .agg(pl.col('amount').sum().alias('total_spent'))\n",
    ")\n",
    "\n",
    "print(\"Optimized join query plan:\")\n",
    "print(query.explain())\n",
    "print(\"\\nNotice: Filter on 'segment' happens BEFORE join (reduces join size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Lazy Union/Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple datasets lazily\n",
    "df1 = pl.DataFrame({'id': [1, 2], 'value': [10, 20]})\n",
    "df2 = pl.DataFrame({'id': [3, 4], 'value': [30, 40]})\n",
    "df3 = pl.DataFrame({'id': [5, 6], 'value': [50, 60]})\n",
    "\n",
    "# Lazy union\n",
    "result = (\n",
    "    pl.concat([df1.lazy(), df2.lazy(), df3.lazy()])\n",
    "    .filter(pl.col('value') > 25)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"Lazy union with filter:\")\n",
    "print(result)\n",
    "print(\"\\nFilter applied to each DataFrame before combining!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Multiple Queries from Same LazyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base lazy query\n",
    "base_query = (\n",
    "    large_data.lazy()\n",
    "    .filter(pl.col('category').is_in(['A', 'B']))\n",
    "    .select(['category', 'value1', 'value2'])\n",
    ")\n",
    "\n",
    "# Branch 1: Summary stats\n",
    "summary = (\n",
    "    base_query\n",
    "    .group_by('category')\n",
    "    .agg([\n",
    "        pl.col('value1').mean().alias('avg_value1'),\n",
    "        pl.col('value2').mean().alias('avg_value2'),\n",
    "    ])\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# Branch 2: Top records\n",
    "top_records = (\n",
    "    base_query\n",
    "    .sort('value1', descending=True)\n",
    "    .head(10)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n",
    "print(\"\\nTop 10:\")\n",
    "print(top_records)\n",
    "print(\"\\nBoth queries optimize the shared base_query independently!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: When to Use Eager vs Lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use EAGER when:\n",
    "- Exploring data interactively\n",
    "- Working with small datasets (< 100MB)\n",
    "- Debugging and need immediate feedback\n",
    "- Simple, one-off operations\n",
    "\n",
    "### Use LAZY when:\n",
    "- Complex queries with multiple steps\n",
    "- Large datasets (> 100MB)\n",
    "- Production pipelines\n",
    "- Reading from files (use scan_*)\n",
    "- Need maximum performance\n",
    "- Working with data larger than RAM (use streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Common Gotchas and Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha 1: Lazy operations don't execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does NOTHING (forgot .collect())\n",
    "result = df.lazy().filter(pl.col('age') > 30)  # No execution!\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(\"This is still a LazyFrame, not executed!\")\n",
    "\n",
    "# Remember to collect()\n",
    "result = df.lazy().filter(pl.col('age') > 30).collect()\n",
    "print(f\"\\nAfter collect() - Type: {type(result)}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip 1: Use fetch() for query development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop query on small sample first\n",
    "query = (\n",
    "    large_data.lazy()\n",
    "    .filter(pl.col('category') == 'A')\n",
    "    .select(['value1', 'value2'])\n",
    "    .with_columns((pl.col('value1') * pl.col('value2')).alias('product'))\n",
    ")\n",
    "\n",
    "# Test on 100 rows\n",
    "print(\"Testing query with fetch(100):\")\n",
    "test_result = query.fetch(100)\n",
    "print(test_result.head())\n",
    "\n",
    "# Once confirmed working, run on full dataset\n",
    "# full_result = query.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip 2: Profile your queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use explain() to understand optimizations\n",
    "query = (\n",
    "    df.lazy()\n",
    "    .filter(pl.col('purchases') > 10)\n",
    "    .select(['name', 'city', 'total_spent'])\n",
    ")\n",
    "\n",
    "# Check if query is optimized as expected\n",
    "print(query.explain())\n",
    "print(\"\\nLook for: projection pushdown, predicate pushdown, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip 3: Chain operations for better optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD: Chain everything\n",
    "good_query = (\n",
    "    df.lazy()\n",
    "    .filter(pl.col('age') > 30)\n",
    "    .select(['name', 'total_spent'])\n",
    "    .sort('total_spent')\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# LESS GOOD: Multiple collects\n",
    "temp1 = df.lazy().filter(pl.col('age') > 30).collect()  # Collect #1\n",
    "temp2 = temp1.select(['name', 'total_spent'])  # Now eager\n",
    "bad_query = temp2.sort('total_spent')  # Each step executes separately\n",
    "\n",
    "print(\"Chain operations for maximum optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Lazy evaluation** delays execution until `.collect()` is called\n",
    "2. **Optimizations** happen automatically (projection/predicate/slice pushdown)\n",
    "3. **Query plans** show how Polars will execute your query\n",
    "4. **Streaming mode** processes data in chunks for huge datasets\n",
    "5. **scan_* functions** enable lazy reading from files\n",
    "6. Use **fetch()** to test queries on large datasets\n",
    "7. Use **explain()** to understand optimizations\n",
    "\n",
    "### Best Practices:\n",
    "- Start with `.lazy()` for complex pipelines\n",
    "- Use `scan_csv/parquet` instead of `read_csv/parquet` when possible\n",
    "- Chain operations instead of multiple `.collect()` calls\n",
    "- Use `.explain()` to verify optimizations\n",
    "- Use `.fetch()` for testing on large datasets\n",
    "- Use `streaming=True` for data larger than RAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
