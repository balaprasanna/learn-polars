{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Stock Market Analysis with yfinance and Polars\n",
    "\n",
    "This notebook demonstrates extensive multi-timeframe analysis of stock market data using:\n",
    "- **yfinance**: For fetching real-time and historical stock data\n",
    "- **Polars**: For high-performance data manipulation and analysis\n",
    "\n",
    "## Timeframes Covered:\n",
    "- 10-minute intervals\n",
    "- 15-minute intervals\n",
    "- 30-minute intervals\n",
    "- 1-hour intervals\n",
    "- 4-hour intervals\n",
    "- Daily intervals\n",
    "\n",
    "## Analysis Includes:\n",
    "- Price action analysis\n",
    "- Volume analysis\n",
    "- Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands)\n",
    "- Volatility metrics\n",
    "- Support/Resistance levels\n",
    "- Cross-timeframe analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import polars as pl\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure Polars display\n",
    "pl.Config.set_tbl_rows(20)\n",
    "pl.Config.set_tbl_cols(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition from yfinance\n",
    "\n",
    "We'll fetch stock data for multiple tickers across different timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock tickers to analyze\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "PRIMARY_TICKER = 'AAPL'  # Primary ticker for detailed analysis\n",
    "\n",
    "# Define timeframe configurations\n",
    "TIMEFRAMES = {\n",
    "    '10min': {'interval': '10m', 'period': '5d'},\n",
    "    '15min': {'interval': '15m', 'period': '5d'},\n",
    "    '30min': {'interval': '30m', 'period': '1mo'},\n",
    "    '1hour': {'interval': '1h', 'period': '3mo'},\n",
    "    '4hour': {'interval': '1h', 'period': '1y'},  # We'll resample 1h to 4h\n",
    "    '1day': {'interval': '1d', 'period': '2y'}\n",
    "}\n",
    "\n",
    "print(\"Timeframes configured for analysis:\")\n",
    "for tf, config in TIMEFRAMES.items():\n",
    "    print(f\"  {tf}: interval={config['interval']}, period={config['period']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker: str, interval: str, period: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch stock data from yfinance and convert to Polars DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        ticker: Stock ticker symbol\n",
    "        interval: Data interval (1m, 5m, 15m, 30m, 1h, 1d, etc.)\n",
    "        period: Data period (1d, 5d, 1mo, 3mo, 1y, 2y, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Polars DataFrame with stock data\n",
    "    \"\"\"\n",
    "    print(f\"Fetching {ticker} data: interval={interval}, period={period}\")\n",
    "    \n",
    "    # Download data from yfinance\n",
    "    stock = yf.Ticker(ticker)\n",
    "    df_pandas = stock.history(period=period, interval=interval)\n",
    "    \n",
    "    if df_pandas.empty:\n",
    "        print(f\"Warning: No data returned for {ticker}\")\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    # Reset index to make datetime a column\n",
    "    df_pandas = df_pandas.reset_index()\n",
    "    \n",
    "    # Convert to Polars\n",
    "    df = pl.from_pandas(df_pandas)\n",
    "    \n",
    "    # Rename columns to lowercase for consistency\n",
    "    df = df.rename({\n",
    "        col: col.lower().replace(' ', '_') \n",
    "        for col in df.columns\n",
    "    })\n",
    "    \n",
    "    # Ensure datetime column is properly named\n",
    "    if 'date' in df.columns:\n",
    "        df = df.rename({'date': 'datetime'})\n",
    "    elif 'datetime' not in df.columns and len(df.columns) > 0:\n",
    "        # First column is usually the datetime\n",
    "        first_col = df.columns[0]\n",
    "        if df[first_col].dtype in [pl.Datetime, pl.Date]:\n",
    "            df = df.rename({first_col: 'datetime'})\n",
    "    \n",
    "    # Add ticker column\n",
    "    df = df.with_columns(pl.lit(ticker).alias('ticker'))\n",
    "    \n",
    "    print(f\"  Retrieved {len(df)} rows\")\n",
    "    return df\n",
    "\n",
    "# Test fetch for primary ticker\n",
    "test_df = fetch_stock_data(PRIMARY_TICKER, '1d', '5d')\n",
    "print(\"\\nSample data:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Data for All Timeframes\n",
    "\n",
    "Download stock data for all configured timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store dataframes for each timeframe\n",
    "timeframe_data = {}\n",
    "\n",
    "print(\"Fetching data for all timeframes...\\n\")\n",
    "\n",
    "for tf_name, config in TIMEFRAMES.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fetching {tf_name} data\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    df = fetch_stock_data(\n",
    "        PRIMARY_TICKER,\n",
    "        config['interval'],\n",
    "        config['period']\n",
    "    )\n",
    "    \n",
    "    # Handle 4-hour timeframe by resampling 1-hour data\n",
    "    if tf_name == '4hour' and not df.is_empty():\n",
    "        print(\"Resampling 1-hour data to 4-hour intervals...\")\n",
    "        df = df.sort('datetime')\n",
    "        df = df.with_columns(\n",
    "            pl.col('datetime').dt.truncate('4h').alias('datetime_4h')\n",
    "        ).group_by('datetime_4h', 'ticker').agg([\n",
    "            pl.col('open').first().alias('open'),\n",
    "            pl.col('high').max().alias('high'),\n",
    "            pl.col('low').min().alias('low'),\n",
    "            pl.col('close').last().alias('close'),\n",
    "            pl.col('volume').sum().alias('volume')\n",
    "        ]).rename({'datetime_4h': 'datetime'}).sort('datetime')\n",
    "    \n",
    "    timeframe_data[tf_name] = df\n",
    "    print(f\"Stored {len(df)} rows for {tf_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data fetch complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Technical Indicators Functions\n",
    "\n",
    "Define functions to calculate various technical indicators using Polars expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_averages(df: pl.DataFrame, periods: list = [5, 10, 20, 50, 200]) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add Simple Moving Averages (SMA) and Exponential Moving Averages (EMA).\n",
    "    \"\"\"\n",
    "    for period in periods:\n",
    "        if len(df) >= period:\n",
    "            df = df.with_columns([\n",
    "                pl.col('close').rolling_mean(window_size=period).alias(f'sma_{period}'),\n",
    "                pl.col('close').ewm_mean(span=period).alias(f'ema_{period}')\n",
    "            ])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rsi(df: pl.DataFrame, period: int = 14) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Relative Strength Index (RSI).\n",
    "    \"\"\"\n",
    "    if len(df) < period + 1:\n",
    "        return df.with_columns(pl.lit(None).alias('rsi'))\n",
    "    \n",
    "    # Calculate price changes\n",
    "    df = df.with_columns(\n",
    "        (pl.col('close') - pl.col('close').shift(1)).alias('price_change')\n",
    "    )\n",
    "    \n",
    "    # Separate gains and losses\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col('price_change') > 0)\n",
    "          .then(pl.col('price_change'))\n",
    "          .otherwise(0)\n",
    "          .alias('gain'),\n",
    "        pl.when(pl.col('price_change') < 0)\n",
    "          .then(pl.col('price_change').abs())\n",
    "          .otherwise(0)\n",
    "          .alias('loss')\n",
    "    ])\n",
    "    \n",
    "    # Calculate average gain and loss\n",
    "    df = df.with_columns([\n",
    "        pl.col('gain').ewm_mean(span=period).alias('avg_gain'),\n",
    "        pl.col('loss').ewm_mean(span=period).alias('avg_loss')\n",
    "    ])\n",
    "    \n",
    "    # Calculate RSI\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('avg_loss') == 0)\n",
    "          .then(100)\n",
    "          .otherwise(\n",
    "              100 - (100 / (1 + pl.col('avg_gain') / pl.col('avg_loss')))\n",
    "          )\n",
    "          .alias('rsi')\n",
    "    )\n",
    "    \n",
    "    # Clean up intermediate columns\n",
    "    return df.drop(['price_change', 'gain', 'loss', 'avg_gain', 'avg_loss'])\n",
    "\n",
    "\n",
    "def add_macd(df: pl.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate MACD (Moving Average Convergence Divergence).\n",
    "    \"\"\"\n",
    "    if len(df) < slow:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('macd'),\n",
    "            pl.lit(None).alias('macd_signal'),\n",
    "            pl.lit(None).alias('macd_histogram')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('close').ewm_mean(span=fast).alias('ema_fast'),\n",
    "        pl.col('close').ewm_mean(span=slow).alias('ema_slow')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('ema_fast') - pl.col('ema_slow')).alias('macd')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col('macd').ewm_mean(span=signal).alias('macd_signal')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('macd') - pl.col('macd_signal')).alias('macd_histogram')\n",
    "    )\n",
    "    \n",
    "    return df.drop(['ema_fast', 'ema_slow'])\n",
    "\n",
    "\n",
    "def add_bollinger_bands(df: pl.DataFrame, period: int = 20, std_dev: float = 2.0) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands.\n",
    "    \"\"\"\n",
    "    if len(df) < period:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('bb_middle'),\n",
    "            pl.lit(None).alias('bb_upper'),\n",
    "            pl.lit(None).alias('bb_lower'),\n",
    "            pl.lit(None).alias('bb_width')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('close').rolling_mean(window_size=period).alias('bb_middle'),\n",
    "        pl.col('close').rolling_std(window_size=period).alias('bb_std')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        (pl.col('bb_middle') + std_dev * pl.col('bb_std')).alias('bb_upper'),\n",
    "        (pl.col('bb_middle') - std_dev * pl.col('bb_std')).alias('bb_lower')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('bb_upper') - pl.col('bb_lower')).alias('bb_width')\n",
    "    )\n",
    "    \n",
    "    return df.drop('bb_std')\n",
    "\n",
    "\n",
    "def add_volatility_metrics(df: pl.DataFrame, period: int = 14) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate volatility metrics including ATR (Average True Range).\n",
    "    \"\"\"\n",
    "    if len(df) < 2:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('atr'),\n",
    "            pl.lit(None).alias('volatility')\n",
    "        ])\n",
    "    \n",
    "    # Calculate True Range\n",
    "    df = df.with_columns([\n",
    "        (pl.col('high') - pl.col('low')).alias('hl'),\n",
    "        (pl.col('high') - pl.col('close').shift(1)).abs().alias('hc'),\n",
    "        (pl.col('low') - pl.col('close').shift(1)).abs().alias('lc')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.max_horizontal('hl', 'hc', 'lc').alias('true_range')\n",
    "    )\n",
    "    \n",
    "    # Calculate ATR\n",
    "    if len(df) >= period:\n",
    "        df = df.with_columns(\n",
    "            pl.col('true_range').rolling_mean(window_size=period).alias('atr')\n",
    "        )\n",
    "    \n",
    "    # Calculate price volatility (standard deviation of returns)\n",
    "    df = df.with_columns(\n",
    "        (pl.col('close') / pl.col('close').shift(1) - 1).alias('returns')\n",
    "    )\n",
    "    \n",
    "    if len(df) >= period:\n",
    "        df = df.with_columns(\n",
    "            pl.col('returns').rolling_std(window_size=period).alias('volatility')\n",
    "        )\n",
    "    \n",
    "    return df.drop(['hl', 'hc', 'lc', 'true_range', 'returns'])\n",
    "\n",
    "\n",
    "def add_volume_indicators(df: pl.DataFrame, period: int = 20) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate volume-based indicators.\n",
    "    \"\"\"\n",
    "    if len(df) < period:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('volume_sma'),\n",
    "            pl.lit(None).alias('volume_ratio')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col('volume').rolling_mean(window_size=period).alias('volume_sma')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('volume') / pl.col('volume_sma')).alias('volume_ratio')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_price_action_signals(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add price action signals and patterns.\n",
    "    \"\"\"\n",
    "    if len(df) < 2:\n",
    "        return df\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        # Daily price change\n",
    "        (pl.col('close') - pl.col('open')).alias('candle_body'),\n",
    "        (pl.col('high') - pl.col('low')).alias('candle_range'),\n",
    "        \n",
    "        # Price change percentage\n",
    "        ((pl.col('close') - pl.col('close').shift(1)) / pl.col('close').shift(1) * 100).alias('pct_change'),\n",
    "        \n",
    "        # Higher highs and lower lows\n",
    "        (pl.col('high') > pl.col('high').shift(1)).alias('higher_high'),\n",
    "        (pl.col('low') < pl.col('low').shift(1)).alias('lower_low'),\n",
    "        \n",
    "        # Bullish/Bearish candle\n",
    "        (pl.col('close') > pl.col('open')).alias('bullish_candle'),\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Technical indicator functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Technical Indicators to All Timeframes\n",
    "\n",
    "Calculate comprehensive technical indicators for each timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_indicators(df: pl.DataFrame, timeframe: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply all technical indicators to a dataframe.\n",
    "    \"\"\"\n",
    "    if df.is_empty():\n",
    "        return df\n",
    "    \n",
    "    print(f\"Calculating indicators for {timeframe}...\")\n",
    "    \n",
    "    # Determine appropriate periods based on timeframe\n",
    "    if timeframe in ['10min', '15min', '30min']:\n",
    "        ma_periods = [5, 10, 20, 50]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 14\n",
    "    elif timeframe in ['1hour', '4hour']:\n",
    "        ma_periods = [5, 10, 20, 50, 100]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 14\n",
    "    else:  # 1day\n",
    "        ma_periods = [5, 10, 20, 50, 200]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 20\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df = df.sort('datetime')\n",
    "    \n",
    "    # Apply indicators\n",
    "    df = add_moving_averages(df, ma_periods)\n",
    "    df = add_rsi(df, rsi_period)\n",
    "    df = add_macd(df)\n",
    "    df = add_bollinger_bands(df, bb_period)\n",
    "    df = add_volatility_metrics(df, vol_period)\n",
    "    df = add_volume_indicators(df, vol_period)\n",
    "    df = add_price_action_signals(df)\n",
    "    \n",
    "    # Add timeframe identifier\n",
    "    df = df.with_columns(pl.lit(timeframe).alias('timeframe'))\n",
    "    \n",
    "    print(f\"  ‚úì Completed {timeframe}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "# Enrich all timeframes with indicators\n",
    "enriched_data = {}\n",
    "\n",
    "print(\"Enriching all timeframes with technical indicators...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for tf_name, df in timeframe_data.items():\n",
    "    enriched_data[tf_name] = enrich_with_indicators(df, tf_name)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\nIndicator calculation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Timeframe-Specific Analysis\n",
    "\n",
    "### 5.1 - 10 Minute Analysis (Scalping Timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10min = enriched_data['10min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"10-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_10min)}\")\n",
    "print(f\"Date range: {df_10min['datetime'].min()} to {df_10min['datetime'].max()}\")\n",
    "\n",
    "# Recent price action\n",
    "print(\"\\nüìä Latest 10 bars:\")\n",
    "print(df_10min.select([\n",
    "    'datetime', 'open', 'high', 'low', 'close', 'volume',\n",
    "    'sma_5', 'sma_10', 'rsi', 'pct_change'\n",
    "]).tail(10))\n",
    "\n",
    "# Key statistics\n",
    "if not df_10min.is_empty():\n",
    "    stats_10min = df_10min.select([\n",
    "        pl.col('close').mean().alias('avg_price'),\n",
    "        pl.col('close').std().alias('price_std'),\n",
    "        pl.col('volume').mean().alias('avg_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi'),\n",
    "        pl.col('atr').mean().alias('avg_atr'),\n",
    "        pl.col('pct_change').mean().alias('avg_pct_change'),\n",
    "        pl.col('pct_change').std().alias('volatility')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìà 10-Minute Statistics:\")\n",
    "    print(stats_10min)\n",
    "\n",
    "# Identify high volatility periods\n",
    "if 'volatility' in df_10min.columns:\n",
    "    high_vol = df_10min.filter(\n",
    "        pl.col('volatility') > pl.col('volatility').quantile(0.75)\n",
    "    ).select(['datetime', 'close', 'volume', 'volatility', 'pct_change'])\n",
    "    \n",
    "    print(f\"\\n‚ö° High Volatility Periods (Top 25%): {len(high_vol)} bars\")\n",
    "    print(high_vol.head(5))\n",
    "\n",
    "# RSI extremes (oversold/overbought)\n",
    "if 'rsi' in df_10min.columns:\n",
    "    oversold = df_10min.filter(pl.col('rsi') < 30).select(\n",
    "        ['datetime', 'close', 'rsi', 'volume']\n",
    "    )\n",
    "    overbought = df_10min.filter(pl.col('rsi') > 70).select(\n",
    "        ['datetime', 'close', 'rsi', 'volume']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüî¥ Oversold signals (RSI < 30): {len(oversold)}\")\n",
    "    if len(oversold) > 0:\n",
    "        print(oversold.tail(3))\n",
    "    \n",
    "    print(f\"\\nüü¢ Overbought signals (RSI > 70): {len(overbought)}\")\n",
    "    if len(overbought) > 0:\n",
    "        print(overbought.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - 15 Minute Analysis (Intraday Trading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15min = enriched_data['15min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"15-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_15min)}\")\n",
    "print(f\"Date range: {df_15min['datetime'].min()} to {df_15min['datetime'].max()}\")\n",
    "\n",
    "# Moving average crossovers\n",
    "if 'sma_5' in df_15min.columns and 'sma_20' in df_15min.columns:\n",
    "    df_15min_signals = df_15min.with_columns([\n",
    "        (pl.col('sma_5') > pl.col('sma_20')).alias('bullish_ma_cross'),\n",
    "        (pl.col('sma_5') < pl.col('sma_20')).alias('bearish_ma_cross')\n",
    "    ])\n",
    "    \n",
    "    # Detect crossover points\n",
    "    df_15min_signals = df_15min_signals.with_columns([\n",
    "        (pl.col('bullish_ma_cross') & ~pl.col('bullish_ma_cross').shift(1)).alias('bullish_cross_signal'),\n",
    "        (pl.col('bearish_ma_cross') & ~pl.col('bearish_ma_cross').shift(1)).alias('bearish_cross_signal')\n",
    "    ])\n",
    "    \n",
    "    bullish_crosses = df_15min_signals.filter(pl.col('bullish_cross_signal'))\n",
    "    bearish_crosses = df_15min_signals.filter(pl.col('bearish_cross_signal'))\n",
    "    \n",
    "    print(f\"\\nüîµ Bullish MA crossovers (5 > 20): {len(bullish_crosses)}\")\n",
    "    if len(bullish_crosses) > 0:\n",
    "        print(bullish_crosses.select(['datetime', 'close', 'sma_5', 'sma_20', 'rsi']).tail(3))\n",
    "    \n",
    "    print(f\"\\nüî¥ Bearish MA crossovers (5 < 20): {len(bearish_crosses)}\")\n",
    "    if len(bearish_crosses) > 0:\n",
    "        print(bearish_crosses.select(['datetime', 'close', 'sma_5', 'sma_20', 'rsi']).tail(3))\n",
    "\n",
    "# Volume analysis\n",
    "if 'volume_ratio' in df_15min.columns:\n",
    "    high_volume = df_15min.filter(\n",
    "        pl.col('volume_ratio') > 1.5\n",
    "    ).select(['datetime', 'close', 'volume', 'volume_ratio', 'pct_change'])\n",
    "    \n",
    "    print(f\"\\nüìä High Volume Bars (>1.5x average): {len(high_volume)}\")\n",
    "    if len(high_volume) > 0:\n",
    "        print(high_volume.tail(5))\n",
    "\n",
    "# MACD signals\n",
    "if 'macd' in df_15min.columns and 'macd_signal' in df_15min.columns:\n",
    "    df_15min_macd = df_15min.with_columns([\n",
    "        (pl.col('macd') > pl.col('macd_signal')).alias('macd_bullish'),\n",
    "        (pl.col('macd') < pl.col('macd_signal')).alias('macd_bearish')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìà MACD Analysis:\")\n",
    "    print(df_15min_macd.select([\n",
    "        'datetime', 'close', 'macd', 'macd_signal', 'macd_histogram'\n",
    "    ]).tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - 30 Minute Analysis (Short-term Trading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30min = enriched_data['30min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"30-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_30min)}\")\n",
    "print(f\"Date range: {df_30min['datetime'].min()} to {df_30min['datetime'].max()}\")\n",
    "\n",
    "# Bollinger Band analysis\n",
    "if all(col in df_30min.columns for col in ['bb_upper', 'bb_lower', 'close']):\n",
    "    df_30min_bb = df_30min.with_columns([\n",
    "        (pl.col('close') > pl.col('bb_upper')).alias('above_bb_upper'),\n",
    "        (pl.col('close') < pl.col('bb_lower')).alias('below_bb_lower'),\n",
    "        ((pl.col('close') - pl.col('bb_lower')) / (pl.col('bb_upper') - pl.col('bb_lower'))).alias('bb_position')\n",
    "    ])\n",
    "    \n",
    "    upper_touches = df_30min_bb.filter(pl.col('above_bb_upper'))\n",
    "    lower_touches = df_30min_bb.filter(pl.col('below_bb_lower'))\n",
    "    \n",
    "    print(f\"\\nüìä Bollinger Band Analysis:\")\n",
    "    print(f\"  Price above upper band: {len(upper_touches)} times\")\n",
    "    print(f\"  Price below lower band: {len(lower_touches)} times\")\n",
    "    \n",
    "    print(\"\\n Latest BB positions:\")\n",
    "    print(df_30min_bb.select([\n",
    "        'datetime', 'close', 'bb_upper', 'bb_middle', 'bb_lower', 'bb_position'\n",
    "    ]).tail(10))\n",
    "\n",
    "# Trend analysis using multiple moving averages\n",
    "if all(col in df_30min.columns for col in ['sma_5', 'sma_10', 'sma_20']):\n",
    "    df_30min_trend = df_30min.with_columns(\n",
    "        pl.when(\n",
    "            (pl.col('sma_5') > pl.col('sma_10')) & (pl.col('sma_10') > pl.col('sma_20'))\n",
    "        ).then(pl.lit('strong_uptrend'))\n",
    "        .when(\n",
    "            (pl.col('sma_5') < pl.col('sma_10')) & (pl.col('sma_10') < pl.col('sma_20'))\n",
    "        ).then(pl.lit('strong_downtrend'))\n",
    "        .when(\n",
    "            pl.col('sma_5') > pl.col('sma_20')\n",
    "        ).then(pl.lit('uptrend'))\n",
    "        .when(\n",
    "            pl.col('sma_5') < pl.col('sma_20')\n",
    "        ).then(pl.lit('downtrend'))\n",
    "        .otherwise(pl.lit('sideways'))\n",
    "        .alias('trend')\n",
    "    )\n",
    "    \n",
    "    trend_dist = df_30min_trend.group_by('trend').agg(\n",
    "        pl.count().alias('count')\n",
    "    ).sort('count', descending=True)\n",
    "    \n",
    "    print(\"\\nüìà Trend Distribution:\")\n",
    "    print(trend_dist)\n",
    "    \n",
    "    print(\"\\n Current trend:\")\n",
    "    print(df_30min_trend.select(['datetime', 'close', 'trend', 'rsi', 'atr']).tail(5))\n",
    "\n",
    "# Support and resistance levels (using rolling highs/lows)\n",
    "if len(df_30min) > 20:\n",
    "    df_30min_sr = df_30min.with_columns([\n",
    "        pl.col('high').rolling_max(window_size=20).alias('resistance_20'),\n",
    "        pl.col('low').rolling_min(window_size=20).alias('support_20')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüéØ Support & Resistance Levels (20-period):\")\n",
    "    print(df_30min_sr.select([\n",
    "        'datetime', 'close', 'support_20', 'resistance_20'\n",
    "    ]).tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 - 1 Hour Analysis (Swing Trading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1hour = enriched_data['1hour']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1-HOUR TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_1hour)}\")\n",
    "print(f\"Date range: {df_1hour['datetime'].min()} to {df_1hour['datetime'].max()}\")\n",
    "\n",
    "# Multi-timeframe momentum\n",
    "if all(col in df_1hour.columns for col in ['sma_10', 'sma_20', 'sma_50']):\n",
    "    df_1hour_momentum = df_1hour.with_columns([\n",
    "        ((pl.col('close') - pl.col('sma_10')) / pl.col('sma_10') * 100).alias('distance_from_sma10'),\n",
    "        ((pl.col('close') - pl.col('sma_20')) / pl.col('sma_20') * 100).alias('distance_from_sma20'),\n",
    "        ((pl.col('close') - pl.col('sma_50')) / pl.col('sma_50') * 100).alias('distance_from_sma50')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìä Distance from Moving Averages:\")\n",
    "    print(df_1hour_momentum.select([\n",
    "        'datetime', 'close', 'distance_from_sma10', 'distance_from_sma20', 'distance_from_sma50'\n",
    "    ]).tail(10))\n",
    "\n",
    "# ATR-based stop loss levels\n",
    "if 'atr' in df_1hour.columns:\n",
    "    df_1hour_stops = df_1hour.with_columns([\n",
    "        (pl.col('close') - 2 * pl.col('atr')).alias('stop_loss_2atr'),\n",
    "        (pl.col('close') + 2 * pl.col('atr')).alias('take_profit_2atr'),\n",
    "        (pl.col('close') - 3 * pl.col('atr')).alias('stop_loss_3atr'),\n",
    "        (pl.col('close') + 3 * pl.col('atr')).alias('take_profit_3atr')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüéØ ATR-Based Trading Levels:\")\n",
    "    print(df_1hour_stops.select([\n",
    "        'datetime', 'close', 'atr', 'stop_loss_2atr', 'take_profit_2atr'\n",
    "    ]).tail(5))\n",
    "\n",
    "# Divergence analysis (price vs RSI)\n",
    "if 'rsi' in df_1hour.columns and len(df_1hour) > 5:\n",
    "    df_1hour_div = df_1hour.with_columns([\n",
    "        (pl.col('close') > pl.col('close').shift(5)).alias('price_higher'),\n",
    "        (pl.col('rsi') > pl.col('rsi').shift(5)).alias('rsi_higher')\n",
    "    ])\n",
    "    \n",
    "    # Bearish divergence: price makes higher high, RSI makes lower high\n",
    "    bearish_div = df_1hour_div.filter(\n",
    "        pl.col('price_higher') & ~pl.col('rsi_higher')\n",
    "    )\n",
    "    \n",
    "    # Bullish divergence: price makes lower low, RSI makes higher low\n",
    "    bullish_div = df_1hour_div.filter(\n",
    "        ~pl.col('price_higher') & pl.col('rsi_higher')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Divergence Signals:\")\n",
    "    print(f\"  Bearish divergences: {len(bearish_div)}\")\n",
    "    print(f\"  Bullish divergences: {len(bullish_div)}\")\n",
    "\n",
    "# Consolidation vs breakout identification\n",
    "if 'atr' in df_1hour.columns:\n",
    "    df_1hour_volatility = df_1hour.with_columns(\n",
    "        (pl.col('atr') < pl.col('atr').rolling_mean(window_size=20)).alias('consolidation')\n",
    "    )\n",
    "    \n",
    "    consolidating = df_1hour_volatility.filter(pl.col('consolidation'))\n",
    "    \n",
    "    print(f\"\\nüìâ Market State:\")\n",
    "    print(f\"  Consolidation periods: {len(consolidating)}\")\n",
    "    print(f\"  Trending periods: {len(df_1hour) - len(consolidating)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 - 4 Hour Analysis (Position Trading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4hour = enriched_data['4hour']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4-HOUR TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_4hour)}\")\n",
    "print(f\"Date range: {df_4hour['datetime'].min()} to {df_4hour['datetime'].max()}\")\n",
    "\n",
    "# Longer-term trend analysis\n",
    "if all(col in df_4hour.columns for col in ['sma_20', 'sma_50']):\n",
    "    current_price = df_4hour.select(pl.col('close').last()).item()\n",
    "    sma_20 = df_4hour.select(pl.col('sma_20').last()).item()\n",
    "    sma_50 = df_4hour.select(pl.col('sma_50').last()).item()\n",
    "    \n",
    "    print(f\"\\nüìä Current Technical Position:\")\n",
    "    print(f\"  Current Price: ${current_price:.2f}\")\n",
    "    print(f\"  20-period SMA: ${sma_20:.2f}\")\n",
    "    print(f\"  50-period SMA: ${sma_50:.2f}\")\n",
    "    \n",
    "    if current_price > sma_20 > sma_50:\n",
    "        print(\"  Trend: STRONG BULLISH üü¢\")\n",
    "    elif current_price < sma_20 < sma_50:\n",
    "        print(\"  Trend: STRONG BEARISH üî¥\")\n",
    "    elif current_price > sma_50:\n",
    "        print(\"  Trend: BULLISH üü¢\")\n",
    "    else:\n",
    "        print(\"  Trend: BEARISH üî¥\")\n",
    "\n",
    "# Price swings (for swing trading)\n",
    "if len(df_4hour) > 10:\n",
    "    df_4hour_swings = df_4hour.with_columns([\n",
    "        pl.col('high').rolling_max(window_size=5).shift(1).alias('swing_high'),\n",
    "        pl.col('low').rolling_min(window_size=5).shift(1).alias('swing_low')\n",
    "    ])\n",
    "    \n",
    "    # Breakouts above swing highs\n",
    "    breakouts = df_4hour_swings.filter(\n",
    "        pl.col('close') > pl.col('swing_high')\n",
    "    )\n",
    "    \n",
    "    # Breakdowns below swing lows\n",
    "    breakdowns = df_4hour_swings.filter(\n",
    "        pl.col('close') < pl.col('swing_low')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüöÄ Swing Analysis:\")\n",
    "    print(f\"  Breakouts (above swing high): {len(breakouts)}\")\n",
    "    print(f\"  Breakdowns (below swing low): {len(breakdowns)}\")\n",
    "    \n",
    "    if len(breakouts) > 0:\n",
    "        print(\"\\n  Recent breakouts:\")\n",
    "        print(breakouts.select(['datetime', 'close', 'swing_high', 'volume']).tail(3))\n",
    "\n",
    "# Weekly statistics\n",
    "if len(df_4hour) > 0:\n",
    "    weekly_stats = df_4hour.select([\n",
    "        pl.col('pct_change').mean().alias('avg_4h_change'),\n",
    "        pl.col('pct_change').std().alias('volatility'),\n",
    "        pl.col('volume').mean().alias('avg_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìà 4-Hour Statistics:\")\n",
    "    print(weekly_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 - Daily Analysis (Investment/Long-term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1day = enriched_data['1day']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DAILY TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_1day)}\")\n",
    "print(f\"Date range: {df_1day['datetime'].min()} to {df_1day['datetime'].max()}\")\n",
    "\n",
    "# Major moving average analysis\n",
    "if all(col in df_1day.columns for col in ['sma_50', 'sma_200']):\n",
    "    current_price = df_1day.select(pl.col('close').last()).item()\n",
    "    sma_50 = df_1day.select(pl.col('sma_50').last()).item()\n",
    "    sma_200 = df_1day.select(pl.col('sma_200').last()).item()\n",
    "    \n",
    "    print(f\"\\nüìä Major Moving Averages:\")\n",
    "    print(f\"  Current Price: ${current_price:.2f}\")\n",
    "    print(f\"  50-day SMA: ${sma_50:.2f}\")\n",
    "    print(f\"  200-day SMA: ${sma_200:.2f}\")\n",
    "    \n",
    "    if sma_50 > sma_200:\n",
    "        print(\"  Golden Cross: YES ‚úÖ (Bullish)\")\n",
    "    else:\n",
    "        print(\"  Death Cross: YES ‚ùå (Bearish)\")\n",
    "    \n",
    "    # Detect recent crossovers\n",
    "    df_1day_crosses = df_1day.with_columns([\n",
    "        (pl.col('sma_50') > pl.col('sma_200')).alias('golden_cross_active'),\n",
    "    ])\n",
    "    \n",
    "    df_1day_crosses = df_1day_crosses.with_columns(\n",
    "        (pl.col('golden_cross_active') != pl.col('golden_cross_active').shift(1)).alias('cross_occurred')\n",
    "    )\n",
    "    \n",
    "    recent_crosses = df_1day_crosses.filter(pl.col('cross_occurred')).tail(5)\n",
    "    if len(recent_crosses) > 0:\n",
    "        print(\"\\n  Recent MA Crosses:\")\n",
    "        print(recent_crosses.select(['datetime', 'close', 'sma_50', 'sma_200']))\n",
    "\n",
    "# Year-to-date performance\n",
    "if len(df_1day) > 0:\n",
    "    latest = df_1day.select('datetime', 'close').sort('datetime').tail(1)\n",
    "    latest_date = latest['datetime'].item()\n",
    "    latest_price = latest['close'].item()\n",
    "    \n",
    "    # Find first price of the year\n",
    "    year_start = df_1day.filter(\n",
    "        pl.col('datetime').dt.year() == latest_date.year\n",
    "    ).sort('datetime').head(1)\n",
    "    \n",
    "    if len(year_start) > 0:\n",
    "        year_start_price = year_start['close'].item()\n",
    "        ytd_return = ((latest_price - year_start_price) / year_start_price) * 100\n",
    "        \n",
    "        print(f\"\\nüìà Year-to-Date Performance:\")\n",
    "        print(f\"  Start of year price: ${year_start_price:.2f}\")\n",
    "        print(f\"  Current price: ${latest_price:.2f}\")\n",
    "        print(f\"  YTD Return: {ytd_return:+.2f}%\")\n",
    "\n",
    "# Monthly returns analysis\n",
    "monthly_returns = df_1day.with_columns(\n",
    "    pl.col('datetime').dt.strftime('%Y-%m').alias('month')\n",
    ").group_by('month').agg([\n",
    "    pl.col('close').first().alias('month_open'),\n",
    "    pl.col('close').last().alias('month_close'),\n",
    "    pl.col('high').max().alias('month_high'),\n",
    "    pl.col('low').min().alias('month_low'),\n",
    "    pl.col('volume').sum().alias('month_volume')\n",
    "]).with_columns(\n",
    "    ((pl.col('month_close') - pl.col('month_open')) / pl.col('month_open') * 100).alias('monthly_return')\n",
    ").sort('month')\n",
    "\n",
    "print(\"\\nüìÖ Monthly Returns (Last 12 months):\")\n",
    "print(monthly_returns.tail(12))\n",
    "\n",
    "# Statistical summary\n",
    "if len(df_1day) > 0:\n",
    "    daily_stats = df_1day.select([\n",
    "        pl.col('close').max().alias('all_time_high'),\n",
    "        pl.col('close').min().alias('all_time_low'),\n",
    "        pl.col('pct_change').mean().alias('avg_daily_change'),\n",
    "        pl.col('pct_change').std().alias('daily_volatility'),\n",
    "        pl.col('volume').mean().alias('avg_daily_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìä Daily Statistics Summary:\")\n",
    "    print(daily_stats)\n",
    "\n",
    "# Drawdown analysis\n",
    "if len(df_1day) > 0:\n",
    "    df_1day_dd = df_1day.with_columns(\n",
    "        pl.col('close').cum_max().alias('running_max')\n",
    "    ).with_columns(\n",
    "        ((pl.col('close') - pl.col('running_max')) / pl.col('running_max') * 100).alias('drawdown_pct')\n",
    "    )\n",
    "    \n",
    "    max_drawdown = df_1day_dd.select(pl.col('drawdown_pct').min()).item()\n",
    "    max_dd_row = df_1day_dd.filter(pl.col('drawdown_pct') == max_drawdown)\n",
    "    \n",
    "    print(f\"\\nüìâ Drawdown Analysis:\")\n",
    "    print(f\"  Maximum Drawdown: {max_drawdown:.2f}%\")\n",
    "    if len(max_dd_row) > 0:\n",
    "        print(f\"  Occurred on: {max_dd_row['datetime'].item()}\")\n",
    "        print(f\"  Price at max DD: ${max_dd_row['close'].item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Timeframe Analysis\n",
    "\n",
    "Compare signals and trends across multiple timeframes for comprehensive market view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROSS-TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get latest values from each timeframe\n",
    "def get_latest_metrics(df: pl.DataFrame, timeframe: str) -> dict:\n",
    "    \"\"\"Extract latest metrics from a timeframe.\"\"\"\n",
    "    if df.is_empty():\n",
    "        return None\n",
    "    \n",
    "    latest = df.sort('datetime').tail(1)\n",
    "    \n",
    "    metrics = {\n",
    "        'timeframe': timeframe,\n",
    "        'datetime': latest['datetime'].item(),\n",
    "        'close': latest['close'].item(),\n",
    "    }\n",
    "    \n",
    "    # Add available indicators\n",
    "    for col in ['rsi', 'macd', 'macd_signal', 'atr', 'bb_width', 'volume_ratio']:\n",
    "        if col in latest.columns:\n",
    "            metrics[col] = latest[col].item()\n",
    "    \n",
    "    # Trend determination\n",
    "    if 'sma_5' in latest.columns and 'sma_20' in latest.columns:\n",
    "        sma_5 = latest['sma_5'].item()\n",
    "        sma_20 = latest['sma_20'].item()\n",
    "        close = latest['close'].item()\n",
    "        \n",
    "        if close > sma_5 > sma_20:\n",
    "            metrics['trend'] = 'bullish'\n",
    "        elif close < sma_5 < sma_20:\n",
    "            metrics['trend'] = 'bearish'\n",
    "        else:\n",
    "            metrics['trend'] = 'mixed'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Collect metrics from all timeframes\n",
    "timeframe_comparison = []\n",
    "for tf_name, df in enriched_data.items():\n",
    "    metrics = get_latest_metrics(df, tf_name)\n",
    "    if metrics:\n",
    "        timeframe_comparison.append(metrics)\n",
    "\n",
    "# Create comparison dataframe\n",
    "if timeframe_comparison:\n",
    "    df_comparison = pl.DataFrame(timeframe_comparison)\n",
    "    \n",
    "    print(\"\\nüìä Latest Metrics Across All Timeframes:\")\n",
    "    print(df_comparison)\n",
    "    \n",
    "    # Trend alignment\n",
    "    if 'trend' in df_comparison.columns:\n",
    "        trend_summary = df_comparison.group_by('trend').agg(\n",
    "            pl.col('timeframe').count().alias('count')\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüéØ Trend Alignment:\")\n",
    "        print(trend_summary)\n",
    "        \n",
    "        bullish_count = trend_summary.filter(pl.col('trend') == 'bullish')['count'].sum()\n",
    "        bearish_count = trend_summary.filter(pl.col('trend') == 'bearish')['count'].sum()\n",
    "        \n",
    "        print(f\"\\n  Overall Market Bias:\")\n",
    "        if bullish_count > bearish_count:\n",
    "            print(f\"  BULLISH ({bullish_count}/{len(timeframe_comparison)} timeframes) üü¢\")\n",
    "        elif bearish_count > bullish_count:\n",
    "            print(f\"  BEARISH ({bearish_count}/{len(timeframe_comparison)} timeframes) üî¥\")\n",
    "        else:\n",
    "            print(f\"  NEUTRAL (Mixed signals) ‚ö™\")\n",
    "    \n",
    "    # RSI comparison\n",
    "    if 'rsi' in df_comparison.columns:\n",
    "        print(\"\\nüìä RSI Across Timeframes:\")\n",
    "        rsi_data = df_comparison.select(['timeframe', 'rsi']).sort('timeframe')\n",
    "        print(rsi_data)\n",
    "        \n",
    "        avg_rsi = df_comparison['rsi'].mean()\n",
    "        print(f\"\\n  Average RSI across all timeframes: {avg_rsi:.2f}\")\n",
    "        \n",
    "        if avg_rsi < 30:\n",
    "            print(\"  ‚ö†Ô∏è Overall OVERSOLD condition\")\n",
    "        elif avg_rsi > 70:\n",
    "            print(\"  ‚ö†Ô∏è Overall OVERBOUGHT condition\")\n",
    "        else:\n",
    "            print(\"  ‚úÖ Neutral RSI conditions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading Signals Summary\n",
    "\n",
    "Consolidated view of trading signals across all timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trading_signals(df: pl.DataFrame, timeframe: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on multiple indicators.\n",
    "    \"\"\"\n",
    "    if df.is_empty() or len(df) < 5:\n",
    "        return None\n",
    "    \n",
    "    latest = df.sort('datetime').tail(1)\n",
    "    \n",
    "    signals = {\n",
    "        'timeframe': timeframe,\n",
    "        'datetime': latest['datetime'].item(),\n",
    "        'price': latest['close'].item()\n",
    "    }\n",
    "    \n",
    "    bullish_signals = 0\n",
    "    bearish_signals = 0\n",
    "    signal_details = []\n",
    "    \n",
    "    # RSI signals\n",
    "    if 'rsi' in latest.columns:\n",
    "        rsi = latest['rsi'].item()\n",
    "        if rsi is not None:\n",
    "            if rsi < 30:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(f\"RSI oversold ({rsi:.1f})\")\n",
    "            elif rsi > 70:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(f\"RSI overbought ({rsi:.1f})\")\n",
    "    \n",
    "    # MACD signals\n",
    "    if 'macd' in latest.columns and 'macd_signal' in latest.columns:\n",
    "        macd = latest['macd'].item()\n",
    "        macd_signal = latest['macd_signal'].item()\n",
    "        if macd is not None and macd_signal is not None:\n",
    "            if macd > macd_signal:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"MACD bullish\")\n",
    "            else:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"MACD bearish\")\n",
    "    \n",
    "    # Moving average signals\n",
    "    if 'sma_5' in latest.columns and 'sma_20' in latest.columns:\n",
    "        close = latest['close'].item()\n",
    "        sma_5 = latest['sma_5'].item()\n",
    "        sma_20 = latest['sma_20'].item()\n",
    "        \n",
    "        if sma_5 is not None and sma_20 is not None:\n",
    "            if close > sma_5 > sma_20:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"MA alignment bullish\")\n",
    "            elif close < sma_5 < sma_20:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"MA alignment bearish\")\n",
    "    \n",
    "    # Bollinger Band signals\n",
    "    if all(col in latest.columns for col in ['close', 'bb_upper', 'bb_lower']):\n",
    "        close = latest['close'].item()\n",
    "        bb_upper = latest['bb_upper'].item()\n",
    "        bb_lower = latest['bb_lower'].item()\n",
    "        \n",
    "        if all(v is not None for v in [close, bb_upper, bb_lower]):\n",
    "            if close < bb_lower:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"Below BB lower band\")\n",
    "            elif close > bb_upper:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"Above BB upper band\")\n",
    "    \n",
    "    # Determine overall signal\n",
    "    total_signals = bullish_signals + bearish_signals\n",
    "    if total_signals > 0:\n",
    "        if bullish_signals > bearish_signals:\n",
    "            signals['signal'] = 'BUY'\n",
    "            signals['strength'] = f\"{bullish_signals}/{total_signals}\"\n",
    "        elif bearish_signals > bullish_signals:\n",
    "            signals['signal'] = 'SELL'\n",
    "            signals['strength'] = f\"{bearish_signals}/{total_signals}\"\n",
    "        else:\n",
    "            signals['signal'] = 'HOLD'\n",
    "            signals['strength'] = f\"{max(bullish_signals, bearish_signals)}/{total_signals}\"\n",
    "    else:\n",
    "        signals['signal'] = 'HOLD'\n",
    "        signals['strength'] = '0/0'\n",
    "    \n",
    "    signals['details'] = ', '.join(signal_details) if signal_details else 'No clear signals'\n",
    "    \n",
    "    return signals\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRADING SIGNALS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate signals for all timeframes\n",
    "all_signals = []\n",
    "for tf_name, df in enriched_data.items():\n",
    "    signals = generate_trading_signals(df, tf_name)\n",
    "    if signals:\n",
    "        all_signals.append(signals)\n",
    "\n",
    "if all_signals:\n",
    "    df_signals = pl.DataFrame(all_signals)\n",
    "    \n",
    "    print(\"\\nüéØ Trading Signals Across All Timeframes:\")\n",
    "    print(df_signals.select(['timeframe', 'signal', 'strength', 'details']))\n",
    "    \n",
    "    # Signal consensus\n",
    "    signal_counts = df_signals.group_by('signal').agg(\n",
    "        pl.col('timeframe').count().alias('count')\n",
    "    ).sort('count', descending=True)\n",
    "    \n",
    "    print(\"\\nüìä Signal Consensus:\")\n",
    "    print(signal_counts)\n",
    "    \n",
    "    # Overall recommendation\n",
    "    buy_count = signal_counts.filter(pl.col('signal') == 'BUY')['count'].sum()\n",
    "    sell_count = signal_counts.filter(pl.col('signal') == 'SELL')['count'].sum()\n",
    "    hold_count = signal_counts.filter(pl.col('signal') == 'HOLD')['count'].sum()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OVERALL RECOMMENDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if buy_count > sell_count and buy_count > hold_count:\n",
    "        print(f\"\\nüü¢ BULLISH BIAS: {buy_count}/{len(all_signals)} timeframes suggest BUY\")\n",
    "    elif sell_count > buy_count and sell_count > hold_count:\n",
    "        print(f\"\\nüî¥ BEARISH BIAS: {sell_count}/{len(all_signals)} timeframes suggest SELL\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö™ NEUTRAL: Mixed signals across timeframes (Hold recommended)\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è Disclaimer: This is for educational purposes only.\")\n",
    "    print(\"   Not financial advice. Always do your own research.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Data for Further Analysis\n",
    "\n",
    "Save processed data to CSV files for external analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export data\n",
    "\n",
    "# for tf_name, df in enriched_data.items():\n",
    "#     if not df.is_empty():\n",
    "#         filename = f\"{PRIMARY_TICKER}_{tf_name}_analysis.csv\"\n",
    "#         df.write_csv(filename)\n",
    "#         print(f\"Exported {filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis Complete!\")\n",
    "print(\"\\nTo export data, uncomment the code block above and run the cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Acquisition**: Fetching multi-timeframe stock data using yfinance\n",
    "2. **Polars Integration**: Converting and processing data with Polars for high performance\n",
    "3. **Technical Indicators**: Implementing various indicators (MA, RSI, MACD, BB, ATR, etc.)\n",
    "4. **Multi-Timeframe Analysis**: Analyzing 10min, 15min, 30min, 1hr, 4hr, and daily timeframes\n",
    "5. **Cross-Timeframe Comparison**: Identifying trends and signals across different timeframes\n",
    "6. **Trading Signals**: Generating actionable signals based on multiple indicators\n",
    "7. **Polars Features**: Leveraging expressions, lazy evaluation, window functions, and aggregations\n",
    "\n",
    "### Key Polars Operations Used:\n",
    "- DataFrame transformations with `with_columns`\n",
    "- Window functions with `rolling_mean`, `rolling_std`, `rolling_max`, `rolling_min`\n",
    "- Conditional expressions with `when`, `then`, `otherwise`\n",
    "- Aggregations with `group_by` and `agg`\n",
    "- Filtering and sorting\n",
    "- DateTime operations\n",
    "- Expression chaining for complex calculations\n",
    "\n",
    "This approach provides a comprehensive framework for stock market analysis using modern data tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
