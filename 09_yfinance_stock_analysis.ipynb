{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Stock Market Analysis with yfinance and Polars\n",
    "\n",
    "This notebook demonstrates extensive multi-timeframe analysis of stock market data using:\n",
    "- **yfinance**: For fetching real-time and historical stock data\n",
    "- **Polars**: For high-performance data manipulation and analysis\n",
    "\n",
    "## Timeframes Covered:\n",
    "- 10-minute intervals\n",
    "- 15-minute intervals\n",
    "- 30-minute intervals\n",
    "- 1-hour intervals\n",
    "- 4-hour intervals\n",
    "- Daily intervals\n",
    "\n",
    "## Analysis Includes:\n",
    "- Price action analysis\n",
    "- Volume analysis\n",
    "- Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands)\n",
    "- Volatility metrics\n",
    "- Support/Resistance levels\n",
    "- Cross-timeframe analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport polars as pl\nimport yfinance as yf\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom matplotlib.gridspec import GridSpec\nimport numpy as np\n\n# Configure Polars display\npl.Config.set_tbl_rows(20)\npl.Config.set_tbl_cols(15)\n\n# Configure matplotlib\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (14, 8)\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.grid'] = True\nplt.rcParams['grid.alpha'] = 0.3\n\nprint(\"✓ Libraries imported and configured successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition from yfinance\n",
    "\n",
    "We'll fetch stock data for multiple tickers across different timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock tickers to analyze\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "PRIMARY_TICKER = 'AAPL'  # Primary ticker for detailed analysis\n",
    "\n",
    "# Define timeframe configurations\n",
    "TIMEFRAMES = {\n",
    "    '10min': {'interval': '10m', 'period': '5d'},\n",
    "    '15min': {'interval': '15m', 'period': '5d'},\n",
    "    '30min': {'interval': '30m', 'period': '1mo'},\n",
    "    '1hour': {'interval': '1h', 'period': '3mo'},\n",
    "    '4hour': {'interval': '1h', 'period': '1y'},  # We'll resample 1h to 4h\n",
    "    '1day': {'interval': '1d', 'period': '2y'}\n",
    "}\n",
    "\n",
    "print(\"Timeframes configured for analysis:\")\n",
    "for tf, config in TIMEFRAMES.items():\n",
    "    print(f\"  {tf}: interval={config['interval']}, period={config['period']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker: str, interval: str, period: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch stock data from yfinance and convert to Polars DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        ticker: Stock ticker symbol\n",
    "        interval: Data interval (1m, 5m, 15m, 30m, 1h, 1d, etc.)\n",
    "        period: Data period (1d, 5d, 1mo, 3mo, 1y, 2y, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Polars DataFrame with stock data\n",
    "    \"\"\"\n",
    "    print(f\"Fetching {ticker} data: interval={interval}, period={period}\")\n",
    "    \n",
    "    # Download data from yfinance\n",
    "    stock = yf.Ticker(ticker)\n",
    "    df_pandas = stock.history(period=period, interval=interval)\n",
    "    \n",
    "    if df_pandas.empty:\n",
    "        print(f\"Warning: No data returned for {ticker}\")\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    # Reset index to make datetime a column\n",
    "    df_pandas = df_pandas.reset_index()\n",
    "    \n",
    "    # Convert to Polars\n",
    "    df = pl.from_pandas(df_pandas)\n",
    "    \n",
    "    # Rename columns to lowercase for consistency\n",
    "    df = df.rename({\n",
    "        col: col.lower().replace(' ', '_') \n",
    "        for col in df.columns\n",
    "    })\n",
    "    \n",
    "    # Ensure datetime column is properly named\n",
    "    if 'date' in df.columns:\n",
    "        df = df.rename({'date': 'datetime'})\n",
    "    elif 'datetime' not in df.columns and len(df.columns) > 0:\n",
    "        # First column is usually the datetime\n",
    "        first_col = df.columns[0]\n",
    "        if df[first_col].dtype in [pl.Datetime, pl.Date]:\n",
    "            df = df.rename({first_col: 'datetime'})\n",
    "    \n",
    "    # Add ticker column\n",
    "    df = df.with_columns(pl.lit(ticker).alias('ticker'))\n",
    "    \n",
    "    print(f\"  Retrieved {len(df)} rows\")\n",
    "    return df\n",
    "\n",
    "# Test fetch for primary ticker\n",
    "test_df = fetch_stock_data(PRIMARY_TICKER, '1d', '5d')\n",
    "print(\"\\nSample data:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Data for All Timeframes\n",
    "\n",
    "Download stock data for all configured timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store dataframes for each timeframe\n",
    "timeframe_data = {}\n",
    "\n",
    "print(\"Fetching data for all timeframes...\\n\")\n",
    "\n",
    "for tf_name, config in TIMEFRAMES.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fetching {tf_name} data\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    df = fetch_stock_data(\n",
    "        PRIMARY_TICKER,\n",
    "        config['interval'],\n",
    "        config['period']\n",
    "    )\n",
    "    \n",
    "    # Handle 4-hour timeframe by resampling 1-hour data\n",
    "    if tf_name == '4hour' and not df.is_empty():\n",
    "        print(\"Resampling 1-hour data to 4-hour intervals...\")\n",
    "        df = df.sort('datetime')\n",
    "        df = df.with_columns(\n",
    "            pl.col('datetime').dt.truncate('4h').alias('datetime_4h')\n",
    "        ).group_by('datetime_4h', 'ticker').agg([\n",
    "            pl.col('open').first().alias('open'),\n",
    "            pl.col('high').max().alias('high'),\n",
    "            pl.col('low').min().alias('low'),\n",
    "            pl.col('close').last().alias('close'),\n",
    "            pl.col('volume').sum().alias('volume')\n",
    "        ]).rename({'datetime_4h': 'datetime'}).sort('datetime')\n",
    "    \n",
    "    timeframe_data[tf_name] = df\n",
    "    print(f\"Stored {len(df)} rows for {tf_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data fetch complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Technical Indicators Functions\n",
    "\n",
    "Define functions to calculate various technical indicators using Polars expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_averages(df: pl.DataFrame, periods: list = [5, 10, 20, 50, 200]) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add Simple Moving Averages (SMA) and Exponential Moving Averages (EMA).\n",
    "    \"\"\"\n",
    "    for period in periods:\n",
    "        if len(df) >= period:\n",
    "            df = df.with_columns([\n",
    "                pl.col('close').rolling_mean(window_size=period).alias(f'sma_{period}'),\n",
    "                pl.col('close').ewm_mean(span=period).alias(f'ema_{period}')\n",
    "            ])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rsi(df: pl.DataFrame, period: int = 14) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Relative Strength Index (RSI).\n",
    "    \"\"\"\n",
    "    if len(df) < period + 1:\n",
    "        return df.with_columns(pl.lit(None).alias('rsi'))\n",
    "    \n",
    "    # Calculate price changes\n",
    "    df = df.with_columns(\n",
    "        (pl.col('close') - pl.col('close').shift(1)).alias('price_change')\n",
    "    )\n",
    "    \n",
    "    # Separate gains and losses\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col('price_change') > 0)\n",
    "          .then(pl.col('price_change'))\n",
    "          .otherwise(0)\n",
    "          .alias('gain'),\n",
    "        pl.when(pl.col('price_change') < 0)\n",
    "          .then(pl.col('price_change').abs())\n",
    "          .otherwise(0)\n",
    "          .alias('loss')\n",
    "    ])\n",
    "    \n",
    "    # Calculate average gain and loss\n",
    "    df = df.with_columns([\n",
    "        pl.col('gain').ewm_mean(span=period).alias('avg_gain'),\n",
    "        pl.col('loss').ewm_mean(span=period).alias('avg_loss')\n",
    "    ])\n",
    "    \n",
    "    # Calculate RSI\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('avg_loss') == 0)\n",
    "          .then(100)\n",
    "          .otherwise(\n",
    "              100 - (100 / (1 + pl.col('avg_gain') / pl.col('avg_loss')))\n",
    "          )\n",
    "          .alias('rsi')\n",
    "    )\n",
    "    \n",
    "    # Clean up intermediate columns\n",
    "    return df.drop(['price_change', 'gain', 'loss', 'avg_gain', 'avg_loss'])\n",
    "\n",
    "\n",
    "def add_macd(df: pl.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate MACD (Moving Average Convergence Divergence).\n",
    "    \"\"\"\n",
    "    if len(df) < slow:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('macd'),\n",
    "            pl.lit(None).alias('macd_signal'),\n",
    "            pl.lit(None).alias('macd_histogram')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('close').ewm_mean(span=fast).alias('ema_fast'),\n",
    "        pl.col('close').ewm_mean(span=slow).alias('ema_slow')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('ema_fast') - pl.col('ema_slow')).alias('macd')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col('macd').ewm_mean(span=signal).alias('macd_signal')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('macd') - pl.col('macd_signal')).alias('macd_histogram')\n",
    "    )\n",
    "    \n",
    "    return df.drop(['ema_fast', 'ema_slow'])\n",
    "\n",
    "\n",
    "def add_bollinger_bands(df: pl.DataFrame, period: int = 20, std_dev: float = 2.0) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands.\n",
    "    \"\"\"\n",
    "    if len(df) < period:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('bb_middle'),\n",
    "            pl.lit(None).alias('bb_upper'),\n",
    "            pl.lit(None).alias('bb_lower'),\n",
    "            pl.lit(None).alias('bb_width')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('close').rolling_mean(window_size=period).alias('bb_middle'),\n",
    "        pl.col('close').rolling_std(window_size=period).alias('bb_std')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        (pl.col('bb_middle') + std_dev * pl.col('bb_std')).alias('bb_upper'),\n",
    "        (pl.col('bb_middle') - std_dev * pl.col('bb_std')).alias('bb_lower')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('bb_upper') - pl.col('bb_lower')).alias('bb_width')\n",
    "    )\n",
    "    \n",
    "    return df.drop('bb_std')\n",
    "\n",
    "\n",
    "def add_volatility_metrics(df: pl.DataFrame, period: int = 14) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate volatility metrics including ATR (Average True Range).\n",
    "    \"\"\"\n",
    "    if len(df) < 2:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('atr'),\n",
    "            pl.lit(None).alias('volatility')\n",
    "        ])\n",
    "    \n",
    "    # Calculate True Range\n",
    "    df = df.with_columns([\n",
    "        (pl.col('high') - pl.col('low')).alias('hl'),\n",
    "        (pl.col('high') - pl.col('close').shift(1)).abs().alias('hc'),\n",
    "        (pl.col('low') - pl.col('close').shift(1)).abs().alias('lc')\n",
    "    ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.max_horizontal('hl', 'hc', 'lc').alias('true_range')\n",
    "    )\n",
    "    \n",
    "    # Calculate ATR\n",
    "    if len(df) >= period:\n",
    "        df = df.with_columns(\n",
    "            pl.col('true_range').rolling_mean(window_size=period).alias('atr')\n",
    "        )\n",
    "    \n",
    "    # Calculate price volatility (standard deviation of returns)\n",
    "    df = df.with_columns(\n",
    "        (pl.col('close') / pl.col('close').shift(1) - 1).alias('returns')\n",
    "    )\n",
    "    \n",
    "    if len(df) >= period:\n",
    "        df = df.with_columns(\n",
    "            pl.col('returns').rolling_std(window_size=period).alias('volatility')\n",
    "        )\n",
    "    \n",
    "    return df.drop(['hl', 'hc', 'lc', 'true_range', 'returns'])\n",
    "\n",
    "\n",
    "def add_volume_indicators(df: pl.DataFrame, period: int = 20) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate volume-based indicators.\n",
    "    \"\"\"\n",
    "    if len(df) < period:\n",
    "        return df.with_columns([\n",
    "            pl.lit(None).alias('volume_sma'),\n",
    "            pl.lit(None).alias('volume_ratio')\n",
    "        ])\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col('volume').rolling_mean(window_size=period).alias('volume_sma')\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col('volume') / pl.col('volume_sma')).alias('volume_ratio')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_price_action_signals(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add price action signals and patterns.\n",
    "    \"\"\"\n",
    "    if len(df) < 2:\n",
    "        return df\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        # Daily price change\n",
    "        (pl.col('close') - pl.col('open')).alias('candle_body'),\n",
    "        (pl.col('high') - pl.col('low')).alias('candle_range'),\n",
    "        \n",
    "        # Price change percentage\n",
    "        ((pl.col('close') - pl.col('close').shift(1)) / pl.col('close').shift(1) * 100).alias('pct_change'),\n",
    "        \n",
    "        # Higher highs and lower lows\n",
    "        (pl.col('high') > pl.col('high').shift(1)).alias('higher_high'),\n",
    "        (pl.col('low') < pl.col('low').shift(1)).alias('lower_low'),\n",
    "        \n",
    "        # Bullish/Bearish candle\n",
    "        (pl.col('close') > pl.col('open')).alias('bullish_candle'),\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Technical indicator functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "def plot_price_with_ma(df: pl.DataFrame, timeframe: str, ticker: str, ma_periods=[5, 20, 50]):\n    \"\"\"\n    Plot price chart with moving averages.\n    \"\"\"\n    if df.is_empty():\n        print(f\"No data to plot for {timeframe}\")\n        return\n    \n    # Convert to pandas for plotting\n    df_pd = df.to_pandas()\n    \n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), height_ratios=[3, 1])\n    \n    # Price and MA plot\n    ax1.plot(df_pd['datetime'], df_pd['close'], label='Close', linewidth=2, color='black')\n    \n    colors = ['blue', 'orange', 'green', 'red', 'purple']\n    for i, period in enumerate(ma_periods):\n        col_name = f'sma_{period}'\n        if col_name in df_pd.columns:\n            ax1.plot(df_pd['datetime'], df_pd[col_name], \n                    label=f'SMA {period}', alpha=0.7, linewidth=1.5, \n                    color=colors[i % len(colors)])\n    \n    ax1.set_title(f'{ticker} - {timeframe.upper()} Price Chart with Moving Averages', \n                  fontsize=14, fontweight='bold')\n    ax1.set_ylabel('Price ($)', fontsize=12)\n    ax1.legend(loc='best')\n    ax1.grid(True, alpha=0.3)\n    \n    # Volume plot\n    colors_vol = ['green' if row['close'] >= row['open'] else 'red' \n                  for _, row in df_pd.iterrows()]\n    ax2.bar(df_pd['datetime'], df_pd['volume'], color=colors_vol, alpha=0.5)\n    ax2.set_ylabel('Volume', fontsize=12)\n    ax2.set_xlabel('Date', fontsize=12)\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_rsi(df: pl.DataFrame, timeframe: str, ticker: str):\n    \"\"\"\n    Plot RSI indicator with overbought/oversold levels.\n    \"\"\"\n    if df.is_empty() or 'rsi' not in df.columns:\n        print(f\"No RSI data to plot for {timeframe}\")\n        return\n    \n    df_pd = df.to_pandas()\n    \n    fig, ax = plt.subplots(figsize=(14, 4))\n    \n    ax.plot(df_pd['datetime'], df_pd['rsi'], label='RSI', linewidth=2, color='purple')\n    ax.axhline(y=70, color='r', linestyle='--', label='Overbought (70)', alpha=0.7)\n    ax.axhline(y=30, color='g', linestyle='--', label='Oversold (30)', alpha=0.7)\n    ax.axhline(y=50, color='gray', linestyle=':', alpha=0.5)\n    ax.fill_between(df_pd['datetime'], 30, 70, alpha=0.1, color='gray')\n    \n    ax.set_title(f'{ticker} - {timeframe.upper()} RSI (14)', fontsize=14, fontweight='bold')\n    ax.set_ylabel('RSI', fontsize=12)\n    ax.set_xlabel('Date', fontsize=12)\n    ax.set_ylim(0, 100)\n    ax.legend(loc='best')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_macd(df: pl.DataFrame, timeframe: str, ticker: str):\n    \"\"\"\n    Plot MACD indicator.\n    \"\"\"\n    if df.is_empty() or 'macd' not in df.columns:\n        print(f\"No MACD data to plot for {timeframe}\")\n        return\n    \n    df_pd = df.to_pandas()\n    \n    fig, ax = plt.subplots(figsize=(14, 4))\n    \n    ax.plot(df_pd['datetime'], df_pd['macd'], label='MACD', linewidth=2, color='blue')\n    ax.plot(df_pd['datetime'], df_pd['macd_signal'], label='Signal', linewidth=2, color='red')\n    \n    # Histogram\n    colors = ['green' if val >= 0 else 'red' for val in df_pd['macd_histogram']]\n    ax.bar(df_pd['datetime'], df_pd['macd_histogram'], label='Histogram', \n           color=colors, alpha=0.3)\n    \n    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n    ax.set_title(f'{ticker} - {timeframe.upper()} MACD', fontsize=14, fontweight='bold')\n    ax.set_ylabel('MACD', fontsize=12)\n    ax.set_xlabel('Date', fontsize=12)\n    ax.legend(loc='best')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_bollinger_bands(df: pl.DataFrame, timeframe: str, ticker: str):\n    \"\"\"\n    Plot price with Bollinger Bands.\n    \"\"\"\n    if df.is_empty() or 'bb_upper' not in df.columns:\n        print(f\"No Bollinger Bands data to plot for {timeframe}\")\n        return\n    \n    df_pd = df.to_pandas()\n    \n    fig, ax = plt.subplots(figsize=(14, 6))\n    \n    ax.plot(df_pd['datetime'], df_pd['close'], label='Close', linewidth=2, color='black')\n    ax.plot(df_pd['datetime'], df_pd['bb_upper'], label='Upper Band', \n            linewidth=1, color='red', linestyle='--', alpha=0.7)\n    ax.plot(df_pd['datetime'], df_pd['bb_middle'], label='Middle Band (SMA 20)', \n            linewidth=1, color='blue', alpha=0.7)\n    ax.plot(df_pd['datetime'], df_pd['bb_lower'], label='Lower Band', \n            linewidth=1, color='green', linestyle='--', alpha=0.7)\n    \n    ax.fill_between(df_pd['datetime'], df_pd['bb_lower'], df_pd['bb_upper'], \n                     alpha=0.1, color='gray')\n    \n    ax.set_title(f'{ticker} - {timeframe.upper()} Bollinger Bands', \n                 fontsize=14, fontweight='bold')\n    ax.set_ylabel('Price ($)', fontsize=12)\n    ax.set_xlabel('Date', fontsize=12)\n    ax.legend(loc='best')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_comprehensive_chart(df: pl.DataFrame, timeframe: str, ticker: str):\n    \"\"\"\n    Create a comprehensive chart with price, volume, RSI, and MACD.\n    \"\"\"\n    if df.is_empty():\n        print(f\"No data to plot for {timeframe}\")\n        return\n    \n    df_pd = df.to_pandas()\n    \n    # Create subplots\n    fig = plt.figure(figsize=(16, 12))\n    gs = GridSpec(4, 1, height_ratios=[3, 1, 1, 1], hspace=0.3)\n    \n    # Price and Bollinger Bands\n    ax1 = fig.add_subplot(gs[0])\n    ax1.plot(df_pd['datetime'], df_pd['close'], label='Close', linewidth=2, color='black')\n    \n    if 'bb_upper' in df_pd.columns:\n        ax1.plot(df_pd['datetime'], df_pd['bb_upper'], 'r--', alpha=0.5, linewidth=1)\n        ax1.plot(df_pd['datetime'], df_pd['bb_middle'], 'b-', alpha=0.5, linewidth=1)\n        ax1.plot(df_pd['datetime'], df_pd['bb_lower'], 'g--', alpha=0.5, linewidth=1)\n        ax1.fill_between(df_pd['datetime'], df_pd['bb_lower'], df_pd['bb_upper'], \n                         alpha=0.1, color='gray')\n    \n    # Add SMAs\n    for period, color in [(5, 'orange'), (20, 'blue'), (50, 'green')]:\n        col_name = f'sma_{period}'\n        if col_name in df_pd.columns:\n            ax1.plot(df_pd['datetime'], df_pd[col_name], \n                    label=f'SMA {period}', alpha=0.7, linewidth=1.5, color=color)\n    \n    ax1.set_title(f'{ticker} - {timeframe.upper()} Comprehensive Technical Analysis', \n                  fontsize=16, fontweight='bold')\n    ax1.set_ylabel('Price ($)', fontsize=12)\n    ax1.legend(loc='best', fontsize=9)\n    ax1.grid(True, alpha=0.3)\n    \n    # Volume\n    ax2 = fig.add_subplot(gs[1], sharex=ax1)\n    colors_vol = ['green' if row['close'] >= row['open'] else 'red' \n                  for _, row in df_pd.iterrows()]\n    ax2.bar(df_pd['datetime'], df_pd['volume'], color=colors_vol, alpha=0.5)\n    ax2.set_ylabel('Volume', fontsize=12)\n    ax2.grid(True, alpha=0.3)\n    \n    # RSI\n    if 'rsi' in df_pd.columns:\n        ax3 = fig.add_subplot(gs[2], sharex=ax1)\n        ax3.plot(df_pd['datetime'], df_pd['rsi'], linewidth=2, color='purple')\n        ax3.axhline(y=70, color='r', linestyle='--', alpha=0.5, linewidth=1)\n        ax3.axhline(y=30, color='g', linestyle='--', alpha=0.5, linewidth=1)\n        ax3.fill_between(df_pd['datetime'], 30, 70, alpha=0.1, color='gray')\n        ax3.set_ylabel('RSI', fontsize=12)\n        ax3.set_ylim(0, 100)\n        ax3.grid(True, alpha=0.3)\n    \n    # MACD\n    if 'macd' in df_pd.columns:\n        ax4 = fig.add_subplot(gs[3], sharex=ax1)\n        ax4.plot(df_pd['datetime'], df_pd['macd'], linewidth=2, color='blue', label='MACD')\n        ax4.plot(df_pd['datetime'], df_pd['macd_signal'], linewidth=2, color='red', label='Signal')\n        colors_hist = ['green' if val >= 0 else 'red' for val in df_pd['macd_histogram']]\n        ax4.bar(df_pd['datetime'], df_pd['macd_histogram'], color=colors_hist, alpha=0.3)\n        ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n        ax4.set_ylabel('MACD', fontsize=12)\n        ax4.set_xlabel('Date', fontsize=12)\n        ax4.legend(loc='best', fontsize=9)\n        ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_candlestick(df: pl.DataFrame, timeframe: str, ticker: str, num_candles=50):\n    \"\"\"\n    Plot candlestick chart with volume.\n    \"\"\"\n    if df.is_empty():\n        print(f\"No data to plot for {timeframe}\")\n        return\n    \n    # Get last N candles\n    df_plot = df.tail(num_candles)\n    df_pd = df_plot.to_pandas()\n    \n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), height_ratios=[3, 1])\n    \n    # Candlestick plot\n    for idx, row in df_pd.iterrows():\n        color = 'green' if row['close'] >= row['open'] else 'red'\n        \n        # Draw the candle body\n        body_height = abs(row['close'] - row['open'])\n        body_bottom = min(row['open'], row['close'])\n        ax1.add_patch(plt.Rectangle((idx, body_bottom), 0.6, body_height, \n                                     facecolor=color, edgecolor='black', linewidth=0.5))\n        \n        # Draw the wick\n        ax1.plot([idx + 0.3, idx + 0.3], [row['low'], row['high']], \n                color='black', linewidth=1)\n    \n    # Add moving averages\n    for period, color, style in [(5, 'orange', '-'), (20, 'blue', '-'), (50, 'green', '--')]:\n        col_name = f'sma_{period}'\n        if col_name in df_pd.columns:\n            ax1.plot(range(len(df_pd)), df_pd[col_name], \n                    label=f'SMA {period}', color=color, linestyle=style, alpha=0.7, linewidth=1.5)\n    \n    ax1.set_title(f'{ticker} - {timeframe.upper()} Candlestick Chart (Last {num_candles} bars)', \n                  fontsize=14, fontweight='bold')\n    ax1.set_ylabel('Price ($)', fontsize=12)\n    ax1.legend(loc='best')\n    ax1.grid(True, alpha=0.3, axis='y')\n    ax1.set_xticks([])\n    \n    # Volume\n    colors_vol = ['green' if row['close'] >= row['open'] else 'red' \n                  for _, row in df_pd.iterrows()]\n    ax2.bar(range(len(df_pd)), df_pd['volume'], color=colors_vol, alpha=0.5)\n    ax2.set_ylabel('Volume', fontsize=12)\n    ax2.set_xlabel(f'Last {num_candles} bars', fontsize=12)\n    ax2.grid(True, alpha=0.3, axis='y')\n    \n    plt.tight_layout()\n    plt.show()\n\n\nprint(\"✓ Plotting utility functions defined successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3.5 Plotting Utilities\n\nHelper functions for creating beautiful financial charts.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Technical Indicators to All Timeframes\n",
    "\n",
    "Calculate comprehensive technical indicators for each timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_indicators(df: pl.DataFrame, timeframe: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply all technical indicators to a dataframe.\n",
    "    \"\"\"\n",
    "    if df.is_empty():\n",
    "        return df\n",
    "    \n",
    "    print(f\"Calculating indicators for {timeframe}...\")\n",
    "    \n",
    "    # Determine appropriate periods based on timeframe\n",
    "    if timeframe in ['10min', '15min', '30min']:\n",
    "        ma_periods = [5, 10, 20, 50]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 14\n",
    "    elif timeframe in ['1hour', '4hour']:\n",
    "        ma_periods = [5, 10, 20, 50, 100]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 14\n",
    "    else:  # 1day\n",
    "        ma_periods = [5, 10, 20, 50, 200]\n",
    "        rsi_period = 14\n",
    "        bb_period = 20\n",
    "        vol_period = 20\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df = df.sort('datetime')\n",
    "    \n",
    "    # Apply indicators\n",
    "    df = add_moving_averages(df, ma_periods)\n",
    "    df = add_rsi(df, rsi_period)\n",
    "    df = add_macd(df)\n",
    "    df = add_bollinger_bands(df, bb_period)\n",
    "    df = add_volatility_metrics(df, vol_period)\n",
    "    df = add_volume_indicators(df, vol_period)\n",
    "    df = add_price_action_signals(df)\n",
    "    \n",
    "    # Add timeframe identifier\n",
    "    df = df.with_columns(pl.lit(timeframe).alias('timeframe'))\n",
    "    \n",
    "    print(f\"  ✓ Completed {timeframe}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "# Enrich all timeframes with indicators\n",
    "enriched_data = {}\n",
    "\n",
    "print(\"Enriching all timeframes with technical indicators...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for tf_name, df in timeframe_data.items():\n",
    "    enriched_data[tf_name] = enrich_with_indicators(df, tf_name)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\nIndicator calculation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive 10-minute chart\nprint(\"\\n📊 10-Minute Charts:\")\nplot_comprehensive_chart(df_10min, '10min', PRIMARY_TICKER)\n\n# Candlestick chart for recent bars\nprint(\"\\n📈 Recent Candlestick Pattern:\")\nplot_candlestick(df_10min, '10min', PRIMARY_TICKER, num_candles=50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Timeframe-Specific Analysis\n",
    "\n",
    "### 5.1 - 10 Minute Analysis (Scalping Timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive 15-minute chart\nprint(\"\\n📊 15-Minute Charts:\")\nplot_comprehensive_chart(df_15min, '15min', PRIMARY_TICKER)\n\n# RSI and MACD detailed views\nprint(\"\\n📈 RSI Analysis:\")\nplot_rsi(df_15min, '15min', PRIMARY_TICKER)\n\nprint(\"\\n📈 MACD Analysis:\")\nplot_macd(df_15min, '15min', PRIMARY_TICKER)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10min = enriched_data['10min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"10-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_10min)}\")\n",
    "print(f\"Date range: {df_10min['datetime'].min()} to {df_10min['datetime'].max()}\")\n",
    "\n",
    "# Recent price action\n",
    "print(\"\\n📊 Latest 10 bars:\")\n",
    "print(df_10min.select([\n",
    "    'datetime', 'open', 'high', 'low', 'close', 'volume',\n",
    "    'sma_5', 'sma_10', 'rsi', 'pct_change'\n",
    "]).tail(10))\n",
    "\n",
    "# Key statistics\n",
    "if not df_10min.is_empty():\n",
    "    stats_10min = df_10min.select([\n",
    "        pl.col('close').mean().alias('avg_price'),\n",
    "        pl.col('close').std().alias('price_std'),\n",
    "        pl.col('volume').mean().alias('avg_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi'),\n",
    "        pl.col('atr').mean().alias('avg_atr'),\n",
    "        pl.col('pct_change').mean().alias('avg_pct_change'),\n",
    "        pl.col('pct_change').std().alias('volatility')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n📈 10-Minute Statistics:\")\n",
    "    print(stats_10min)\n",
    "\n",
    "# Identify high volatility periods\n",
    "if 'volatility' in df_10min.columns:\n",
    "    high_vol = df_10min.filter(\n",
    "        pl.col('volatility') > pl.col('volatility').quantile(0.75)\n",
    "    ).select(['datetime', 'close', 'volume', 'volatility', 'pct_change'])\n",
    "    \n",
    "    print(f\"\\n⚡ High Volatility Periods (Top 25%): {len(high_vol)} bars\")\n",
    "    print(high_vol.head(5))\n",
    "\n",
    "# RSI extremes (oversold/overbought)\n",
    "if 'rsi' in df_10min.columns:\n",
    "    oversold = df_10min.filter(pl.col('rsi') < 30).select(\n",
    "        ['datetime', 'close', 'rsi', 'volume']\n",
    "    )\n",
    "    overbought = df_10min.filter(pl.col('rsi') > 70).select(\n",
    "        ['datetime', 'close', 'rsi', 'volume']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🔴 Oversold signals (RSI < 30): {len(oversold)}\")\n",
    "    if len(oversold) > 0:\n",
    "        print(oversold.tail(3))\n",
    "    \n",
    "    print(f\"\\n🟢 Overbought signals (RSI > 70): {len(overbought)}\")\n",
    "    if len(overbought) > 0:\n",
    "        print(overbought.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive 30-minute chart\nprint(\"\\n📊 30-Minute Charts:\")\nplot_comprehensive_chart(df_30min, '30min', PRIMARY_TICKER)\n\n# Bollinger Bands focused view\nprint(\"\\n📈 Bollinger Bands Analysis:\")\nplot_bollinger_bands(df_30min, '30min', PRIMARY_TICKER)\n\n# Candlestick chart\nprint(\"\\n📊 Candlestick Chart:\")\nplot_candlestick(df_30min, '30min', PRIMARY_TICKER, num_candles=60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - 15 Minute Analysis (Intraday Trading)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive 1-hour chart\nprint(\"\\n📊 1-Hour Charts:\")\nplot_comprehensive_chart(df_1hour, '1hour', PRIMARY_TICKER)\n\n# Price with moving averages\nprint(\"\\n📈 Price and Moving Averages:\")\nplot_price_with_ma(df_1hour, '1hour', PRIMARY_TICKER, ma_periods=[10, 20, 50, 100])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15min = enriched_data['15min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"15-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_15min)}\")\n",
    "print(f\"Date range: {df_15min['datetime'].min()} to {df_15min['datetime'].max()}\")\n",
    "\n",
    "# Moving average crossovers\n",
    "if 'sma_5' in df_15min.columns and 'sma_20' in df_15min.columns:\n",
    "    df_15min_signals = df_15min.with_columns([\n",
    "        (pl.col('sma_5') > pl.col('sma_20')).alias('bullish_ma_cross'),\n",
    "        (pl.col('sma_5') < pl.col('sma_20')).alias('bearish_ma_cross')\n",
    "    ])\n",
    "    \n",
    "    # Detect crossover points\n",
    "    df_15min_signals = df_15min_signals.with_columns([\n",
    "        (pl.col('bullish_ma_cross') & ~pl.col('bullish_ma_cross').shift(1)).alias('bullish_cross_signal'),\n",
    "        (pl.col('bearish_ma_cross') & ~pl.col('bearish_ma_cross').shift(1)).alias('bearish_cross_signal')\n",
    "    ])\n",
    "    \n",
    "    bullish_crosses = df_15min_signals.filter(pl.col('bullish_cross_signal'))\n",
    "    bearish_crosses = df_15min_signals.filter(pl.col('bearish_cross_signal'))\n",
    "    \n",
    "    print(f\"\\n🔵 Bullish MA crossovers (5 > 20): {len(bullish_crosses)}\")\n",
    "    if len(bullish_crosses) > 0:\n",
    "        print(bullish_crosses.select(['datetime', 'close', 'sma_5', 'sma_20', 'rsi']).tail(3))\n",
    "    \n",
    "    print(f\"\\n🔴 Bearish MA crossovers (5 < 20): {len(bearish_crosses)}\")\n",
    "    if len(bearish_crosses) > 0:\n",
    "        print(bearish_crosses.select(['datetime', 'close', 'sma_5', 'sma_20', 'rsi']).tail(3))\n",
    "\n",
    "# Volume analysis\n",
    "if 'volume_ratio' in df_15min.columns:\n",
    "    high_volume = df_15min.filter(\n",
    "        pl.col('volume_ratio') > 1.5\n",
    "    ).select(['datetime', 'close', 'volume', 'volume_ratio', 'pct_change'])\n",
    "    \n",
    "    print(f\"\\n📊 High Volume Bars (>1.5x average): {len(high_volume)}\")\n",
    "    if len(high_volume) > 0:\n",
    "        print(high_volume.tail(5))\n",
    "\n",
    "# MACD signals\n",
    "if 'macd' in df_15min.columns and 'macd_signal' in df_15min.columns:\n",
    "    df_15min_macd = df_15min.with_columns([\n",
    "        (pl.col('macd') > pl.col('macd_signal')).alias('macd_bullish'),\n",
    "        (pl.col('macd') < pl.col('macd_signal')).alias('macd_bearish')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n📈 MACD Analysis:\")\n",
    "    print(df_15min_macd.select([\n",
    "        'datetime', 'close', 'macd', 'macd_signal', 'macd_histogram'\n",
    "    ]).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive 4-hour chart\nprint(\"\\n📊 4-Hour Charts:\")\nplot_comprehensive_chart(df_4hour, '4hour', PRIMARY_TICKER)\n\n# Candlestick with swing levels\nprint(\"\\n📈 Candlestick with Swing Analysis:\")\nplot_candlestick(df_4hour, '4hour', PRIMARY_TICKER, num_candles=80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - 30 Minute Analysis (Short-term Trading)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive daily chart\nprint(\"\\n📊 Daily Charts:\")\nplot_comprehensive_chart(df_1day, '1day', PRIMARY_TICKER)\n\n# Price with major moving averages (including 50 and 200-day)\nprint(\"\\n📈 Price with Major Moving Averages (50-day and 200-day):\")\nplot_price_with_ma(df_1day, '1day', PRIMARY_TICKER, ma_periods=[20, 50, 200])\n\n# Long-term candlestick\nprint(\"\\n📊 Long-term Candlestick Pattern:\")\nplot_candlestick(df_1day, '1day', PRIMARY_TICKER, num_candles=100)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30min = enriched_data['30min']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"30-MINUTE TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_30min)}\")\n",
    "print(f\"Date range: {df_30min['datetime'].min()} to {df_30min['datetime'].max()}\")\n",
    "\n",
    "# Bollinger Band analysis\n",
    "if all(col in df_30min.columns for col in ['bb_upper', 'bb_lower', 'close']):\n",
    "    df_30min_bb = df_30min.with_columns([\n",
    "        (pl.col('close') > pl.col('bb_upper')).alias('above_bb_upper'),\n",
    "        (pl.col('close') < pl.col('bb_lower')).alias('below_bb_lower'),\n",
    "        ((pl.col('close') - pl.col('bb_lower')) / (pl.col('bb_upper') - pl.col('bb_lower'))).alias('bb_position')\n",
    "    ])\n",
    "    \n",
    "    upper_touches = df_30min_bb.filter(pl.col('above_bb_upper'))\n",
    "    lower_touches = df_30min_bb.filter(pl.col('below_bb_lower'))\n",
    "    \n",
    "    print(f\"\\n📊 Bollinger Band Analysis:\")\n",
    "    print(f\"  Price above upper band: {len(upper_touches)} times\")\n",
    "    print(f\"  Price below lower band: {len(lower_touches)} times\")\n",
    "    \n",
    "    print(\"\\n Latest BB positions:\")\n",
    "    print(df_30min_bb.select([\n",
    "        'datetime', 'close', 'bb_upper', 'bb_middle', 'bb_lower', 'bb_position'\n",
    "    ]).tail(10))\n",
    "\n",
    "# Trend analysis using multiple moving averages\n",
    "if all(col in df_30min.columns for col in ['sma_5', 'sma_10', 'sma_20']):\n",
    "    df_30min_trend = df_30min.with_columns(\n",
    "        pl.when(\n",
    "            (pl.col('sma_5') > pl.col('sma_10')) & (pl.col('sma_10') > pl.col('sma_20'))\n",
    "        ).then(pl.lit('strong_uptrend'))\n",
    "        .when(\n",
    "            (pl.col('sma_5') < pl.col('sma_10')) & (pl.col('sma_10') < pl.col('sma_20'))\n",
    "        ).then(pl.lit('strong_downtrend'))\n",
    "        .when(\n",
    "            pl.col('sma_5') > pl.col('sma_20')\n",
    "        ).then(pl.lit('uptrend'))\n",
    "        .when(\n",
    "            pl.col('sma_5') < pl.col('sma_20')\n",
    "        ).then(pl.lit('downtrend'))\n",
    "        .otherwise(pl.lit('sideways'))\n",
    "        .alias('trend')\n",
    "    )\n",
    "    \n",
    "    trend_dist = df_30min_trend.group_by('trend').agg(\n",
    "        pl.count().alias('count')\n",
    "    ).sort('count', descending=True)\n",
    "    \n",
    "    print(\"\\n📈 Trend Distribution:\")\n",
    "    print(trend_dist)\n",
    "    \n",
    "    print(\"\\n Current trend:\")\n",
    "    print(df_30min_trend.select(['datetime', 'close', 'trend', 'rsi', 'atr']).tail(5))\n",
    "\n",
    "# Support and resistance levels (using rolling highs/lows)\n",
    "if len(df_30min) > 20:\n",
    "    df_30min_sr = df_30min.with_columns([\n",
    "        pl.col('high').rolling_max(window_size=20).alias('resistance_20'),\n",
    "        pl.col('low').rolling_min(window_size=20).alias('support_20')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n🎯 Support & Resistance Levels (20-period):\")\n",
    "    print(df_30min_sr.select([\n",
    "        'datetime', 'close', 'support_20', 'resistance_20'\n",
    "    ]).tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Cross-timeframe visualizations\nif timeframe_comparison:\n    df_comp_pd = df_comparison.to_pandas()\n    \n    # RSI comparison across timeframes\n    if 'rsi' in df_comp_pd.columns:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        timeframes_order = ['10min', '15min', '30min', '1hour', '4hour', '1day']\n        df_comp_sorted = df_comp_pd.set_index('timeframe').loc[\n            [tf for tf in timeframes_order if tf in df_comp_pd['timeframe'].values]\n        ].reset_index()\n        \n        bars = ax.bar(range(len(df_comp_sorted)), df_comp_sorted['rsi'], \n                     color=['red' if rsi > 70 else 'green' if rsi < 30 else 'gray' \n                           for rsi in df_comp_sorted['rsi']], alpha=0.7)\n        \n        ax.axhline(y=70, color='red', linestyle='--', label='Overbought', alpha=0.5)\n        ax.axhline(y=30, color='green', linestyle='--', label='Oversold', alpha=0.5)\n        ax.axhline(y=50, color='gray', linestyle=':', alpha=0.3)\n        \n        ax.set_xticks(range(len(df_comp_sorted)))\n        ax.set_xticklabels(df_comp_sorted['timeframe'], rotation=0)\n        ax.set_ylabel('RSI Value', fontsize=12)\n        ax.set_xlabel('Timeframe', fontsize=12)\n        ax.set_title(f'{PRIMARY_TICKER} - RSI Across All Timeframes', \n                    fontsize=14, fontweight='bold')\n        ax.set_ylim(0, 100)\n        ax.legend()\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        # Add value labels on bars\n        for i, (idx, row) in enumerate(df_comp_sorted.iterrows()):\n            ax.text(i, row['rsi'] + 2, f\"{row['rsi']:.1f}\", \n                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n        \n        plt.tight_layout()\n        plt.show()\n    \n    # Price comparison across timeframes\n    if 'close' in df_comp_pd.columns:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        # Normalize prices to show relative changes\n        reference_price = df_comp_pd['close'].iloc[0]\n        df_comp_pd['price_pct_from_ref'] = ((df_comp_pd['close'] - reference_price) / reference_price) * 100\n        \n        ax.plot(df_comp_sorted.index, df_comp_sorted['close'], \n               marker='o', linewidth=2, markersize=8, color='blue')\n        \n        ax.set_xticks(range(len(df_comp_sorted)))\n        ax.set_xticklabels(df_comp_sorted['timeframe'], rotation=0)\n        ax.set_ylabel('Price ($)', fontsize=12)\n        ax.set_xlabel('Timeframe', fontsize=12)\n        ax.set_title(f'{PRIMARY_TICKER} - Latest Price Across Timeframes', \n                    fontsize=14, fontweight='bold')\n        ax.grid(True, alpha=0.3)\n        \n        # Add value labels\n        for i, (idx, row) in enumerate(df_comp_sorted.iterrows()):\n            ax.text(i, row['close'], f\"${row['close']:.2f}\", \n                   ha='center', va='bottom', fontsize=9)\n        \n        plt.tight_layout()\n        plt.show()\n    \n    # Trend alignment visualization\n    if 'trend' in df_comp_pd.columns:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        trend_colors = {'bullish': 'green', 'bearish': 'red', 'mixed': 'gray'}\n        colors = [trend_colors.get(trend, 'gray') for trend in df_comp_sorted['trend']]\n        \n        bars = ax.bar(range(len(df_comp_sorted)), [1]*len(df_comp_sorted), \n                     color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n        \n        ax.set_xticks(range(len(df_comp_sorted)))\n        ax.set_xticklabels(df_comp_sorted['timeframe'], rotation=0)\n        ax.set_ylabel('Trend Direction', fontsize=12)\n        ax.set_xlabel('Timeframe', fontsize=12)\n        ax.set_title(f'{PRIMARY_TICKER} - Trend Alignment Across Timeframes', \n                    fontsize=14, fontweight='bold')\n        ax.set_yticks([])\n        ax.set_ylim(0, 1.2)\n        \n        # Add legend\n        from matplotlib.patches import Patch\n        legend_elements = [\n            Patch(facecolor='green', alpha=0.7, label='Bullish'),\n            Patch(facecolor='red', alpha=0.7, label='Bearish'),\n            Patch(facecolor='gray', alpha=0.7, label='Mixed')\n        ]\n        ax.legend(handles=legend_elements, loc='upper right')\n        \n        # Add trend labels\n        for i, (idx, row) in enumerate(df_comp_sorted.iterrows()):\n            ax.text(i, 0.5, row['trend'].upper(), \n                   ha='center', va='center', fontsize=11, fontweight='bold', \n                   color='white', rotation=0)\n        \n        plt.tight_layout()\n        plt.show()\n\nprint(\"\\n✅ Cross-timeframe visualization complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 - 1 Hour Analysis (Swing Trading)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Trading signals visualization\nif all_signals:\n    df_signals_pd = df_signals.to_pandas()\n    \n    # Signal distribution across timeframes\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Left plot: Signals by timeframe\n    timeframes_order = ['10min', '15min', '30min', '1hour', '4hour', '1day']\n    df_signals_sorted = df_signals_pd.set_index('timeframe').loc[\n        [tf for tf in timeframes_order if tf in df_signals_pd['timeframe'].values]\n    ].reset_index()\n    \n    signal_colors = {'BUY': 'green', 'SELL': 'red', 'HOLD': 'gray'}\n    colors = [signal_colors.get(sig, 'gray') for sig in df_signals_sorted['signal']]\n    \n    bars = ax1.bar(range(len(df_signals_sorted)), [1]*len(df_signals_sorted), \n                   color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n    \n    ax1.set_xticks(range(len(df_signals_sorted)))\n    ax1.set_xticklabels(df_signals_sorted['timeframe'], rotation=0)\n    ax1.set_ylabel('Signal Type', fontsize=12)\n    ax1.set_xlabel('Timeframe', fontsize=12)\n    ax1.set_title(f'{PRIMARY_TICKER} - Trading Signals by Timeframe', \n                 fontsize=14, fontweight='bold')\n    ax1.set_yticks([])\n    ax1.set_ylim(0, 1.3)\n    \n    # Add legend\n    from matplotlib.patches import Patch\n    legend_elements = [\n        Patch(facecolor='green', alpha=0.7, label='BUY'),\n        Patch(facecolor='red', alpha=0.7, label='SELL'),\n        Patch(facecolor='gray', alpha=0.7, label='HOLD')\n    ]\n    ax1.legend(handles=legend_elements, loc='upper right')\n    \n    # Add signal labels with strength\n    for i, (idx, row) in enumerate(df_signals_sorted.iterrows()):\n        ax1.text(i, 0.5, f\"{row['signal']}\\\\n({row['strength']})\", \n                ha='center', va='center', fontsize=10, fontweight='bold', \n                color='white')\n    \n    # Right plot: Signal consensus pie chart\n    signal_counts_dict = df_signals_pd['signal'].value_counts().to_dict()\n    \n    if signal_counts_dict:\n        labels = list(signal_counts_dict.keys())\n        sizes = list(signal_counts_dict.values())\n        colors_pie = [signal_colors.get(label, 'gray') for label in labels]\n        \n        wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors_pie, \n                                           autopct='%1.0f%%', startangle=90,\n                                           textprops={'fontsize': 12, 'fontweight': 'bold'},\n                                           explode=[0.05] * len(labels))\n        \n        # Make percentage text white and bold\n        for autotext in autotexts:\n            autotext.set_color('white')\n            autotext.set_fontsize(14)\n            autotext.set_fontweight('bold')\n        \n        ax2.set_title(f'{PRIMARY_TICKER} - Signal Consensus\\\\n({len(all_signals)} Timeframes)', \n                     fontsize=14, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Detailed signal strength visualization\n    fig, ax = plt.subplots(figsize=(14, 6))\n    \n    # Parse strength as numeric value\n    strengths = []\n    for s in df_signals_sorted['strength']:\n        try:\n            num, denom = s.split('/')\n            strength_pct = (int(num) / int(denom)) * 100 if int(denom) > 0 else 0\n            strengths.append(strength_pct)\n        except:\n            strengths.append(0)\n    \n    df_signals_sorted['strength_pct'] = strengths\n    \n    bars = ax.bar(range(len(df_signals_sorted)), df_signals_sorted['strength_pct'], \n                 color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n    \n    ax.set_xticks(range(len(df_signals_sorted)))\n    ax.set_xticklabels(df_signals_sorted['timeframe'], rotation=0)\n    ax.set_ylabel('Signal Strength (%)', fontsize=12)\n    ax.set_xlabel('Timeframe', fontsize=12)\n    ax.set_title(f'{PRIMARY_TICKER} - Signal Strength Across Timeframes', \n                fontsize=14, fontweight='bold')\n    ax.set_ylim(0, 110)\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels\n    for i, (idx, row) in enumerate(df_signals_sorted.iterrows()):\n        ax.text(i, row['strength_pct'] + 3, \n               f\"{row['signal']}\\\\n{row['strength']}\", \n               ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"\\n✅ Trading signals visualization complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1hour = enriched_data['1hour']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1-HOUR TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_1hour)}\")\n",
    "print(f\"Date range: {df_1hour['datetime'].min()} to {df_1hour['datetime'].max()}\")\n",
    "\n",
    "# Multi-timeframe momentum\n",
    "if all(col in df_1hour.columns for col in ['sma_10', 'sma_20', 'sma_50']):\n",
    "    df_1hour_momentum = df_1hour.with_columns([\n",
    "        ((pl.col('close') - pl.col('sma_10')) / pl.col('sma_10') * 100).alias('distance_from_sma10'),\n",
    "        ((pl.col('close') - pl.col('sma_20')) / pl.col('sma_20') * 100).alias('distance_from_sma20'),\n",
    "        ((pl.col('close') - pl.col('sma_50')) / pl.col('sma_50') * 100).alias('distance_from_sma50')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n📊 Distance from Moving Averages:\")\n",
    "    print(df_1hour_momentum.select([\n",
    "        'datetime', 'close', 'distance_from_sma10', 'distance_from_sma20', 'distance_from_sma50'\n",
    "    ]).tail(10))\n",
    "\n",
    "# ATR-based stop loss levels\n",
    "if 'atr' in df_1hour.columns:\n",
    "    df_1hour_stops = df_1hour.with_columns([\n",
    "        (pl.col('close') - 2 * pl.col('atr')).alias('stop_loss_2atr'),\n",
    "        (pl.col('close') + 2 * pl.col('atr')).alias('take_profit_2atr'),\n",
    "        (pl.col('close') - 3 * pl.col('atr')).alias('stop_loss_3atr'),\n",
    "        (pl.col('close') + 3 * pl.col('atr')).alias('take_profit_3atr')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n🎯 ATR-Based Trading Levels:\")\n",
    "    print(df_1hour_stops.select([\n",
    "        'datetime', 'close', 'atr', 'stop_loss_2atr', 'take_profit_2atr'\n",
    "    ]).tail(5))\n",
    "\n",
    "# Divergence analysis (price vs RSI)\n",
    "if 'rsi' in df_1hour.columns and len(df_1hour) > 5:\n",
    "    df_1hour_div = df_1hour.with_columns([\n",
    "        (pl.col('close') > pl.col('close').shift(5)).alias('price_higher'),\n",
    "        (pl.col('rsi') > pl.col('rsi').shift(5)).alias('rsi_higher')\n",
    "    ])\n",
    "    \n",
    "    # Bearish divergence: price makes higher high, RSI makes lower high\n",
    "    bearish_div = df_1hour_div.filter(\n",
    "        pl.col('price_higher') & ~pl.col('rsi_higher')\n",
    "    )\n",
    "    \n",
    "    # Bullish divergence: price makes lower low, RSI makes higher low\n",
    "    bullish_div = df_1hour_div.filter(\n",
    "        ~pl.col('price_higher') & pl.col('rsi_higher')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n⚠️ Divergence Signals:\")\n",
    "    print(f\"  Bearish divergences: {len(bearish_div)}\")\n",
    "    print(f\"  Bullish divergences: {len(bullish_div)}\")\n",
    "\n",
    "# Consolidation vs breakout identification\n",
    "if 'atr' in df_1hour.columns:\n",
    "    df_1hour_volatility = df_1hour.with_columns(\n",
    "        (pl.col('atr') < pl.col('atr').rolling_mean(window_size=20)).alias('consolidation')\n",
    "    )\n",
    "    \n",
    "    consolidating = df_1hour_volatility.filter(pl.col('consolidation'))\n",
    "    \n",
    "    print(f\"\\n📉 Market State:\")\n",
    "    print(f\"  Consolidation periods: {len(consolidating)}\")\n",
    "    print(f\"  Trending periods: {len(df_1hour) - len(consolidating)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrates:\n\n1. **Data Acquisition**: Fetching multi-timeframe stock data using yfinance\n2. **Polars Integration**: Converting and processing data with Polars for high performance\n3. **Technical Indicators**: Implementing various indicators (MA, RSI, MACD, BB, ATR, etc.)\n4. **Multi-Timeframe Analysis**: Analyzing 10min, 15min, 30min, 1hr, 4hr, and daily timeframes\n5. **Cross-Timeframe Comparison**: Identifying trends and signals across different timeframes\n6. **Trading Signals**: Generating actionable signals based on multiple indicators\n7. **Polars Features**: Leveraging expressions, lazy evaluation, window functions, and aggregations\n8. **Professional Visualizations**: Beautiful, informative charts for all analyses\n\n### Key Polars Operations Used:\n- DataFrame transformations with `with_columns`\n- Window functions with `rolling_mean`, `rolling_std`, `rolling_max`, `rolling_min`\n- Conditional expressions with `when`, `then`, `otherwise`\n- Aggregations with `group_by` and `agg`\n- Filtering and sorting\n- DateTime operations\n- Expression chaining for complex calculations\n\n### Visualizations Included:\n- **Comprehensive Multi-Panel Charts**: Price, Volume, RSI, and MACD in synchronized views\n- **Candlestick Charts**: Professional OHLC visualizations with moving averages\n- **Technical Indicator Plots**: Dedicated RSI, MACD, and Bollinger Bands charts\n- **Cross-Timeframe Analysis**: Visual comparison of trends, RSI, and prices across all timeframes\n- **Trading Signal Dashboards**: Signal distribution, consensus pie charts, and strength analysis\n- **Color-Coded Visualizations**: Green/red color schemes for easy interpretation\n\nThis approach provides a comprehensive framework for stock market analysis using modern data tools, combining the performance of Polars with the visual insights of matplotlib."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4hour = enriched_data['4hour']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4-HOUR TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_4hour)}\")\n",
    "print(f\"Date range: {df_4hour['datetime'].min()} to {df_4hour['datetime'].max()}\")\n",
    "\n",
    "# Longer-term trend analysis\n",
    "if all(col in df_4hour.columns for col in ['sma_20', 'sma_50']):\n",
    "    current_price = df_4hour.select(pl.col('close').last()).item()\n",
    "    sma_20 = df_4hour.select(pl.col('sma_20').last()).item()\n",
    "    sma_50 = df_4hour.select(pl.col('sma_50').last()).item()\n",
    "    \n",
    "    print(f\"\\n📊 Current Technical Position:\")\n",
    "    print(f\"  Current Price: ${current_price:.2f}\")\n",
    "    print(f\"  20-period SMA: ${sma_20:.2f}\")\n",
    "    print(f\"  50-period SMA: ${sma_50:.2f}\")\n",
    "    \n",
    "    if current_price > sma_20 > sma_50:\n",
    "        print(\"  Trend: STRONG BULLISH 🟢\")\n",
    "    elif current_price < sma_20 < sma_50:\n",
    "        print(\"  Trend: STRONG BEARISH 🔴\")\n",
    "    elif current_price > sma_50:\n",
    "        print(\"  Trend: BULLISH 🟢\")\n",
    "    else:\n",
    "        print(\"  Trend: BEARISH 🔴\")\n",
    "\n",
    "# Price swings (for swing trading)\n",
    "if len(df_4hour) > 10:\n",
    "    df_4hour_swings = df_4hour.with_columns([\n",
    "        pl.col('high').rolling_max(window_size=5).shift(1).alias('swing_high'),\n",
    "        pl.col('low').rolling_min(window_size=5).shift(1).alias('swing_low')\n",
    "    ])\n",
    "    \n",
    "    # Breakouts above swing highs\n",
    "    breakouts = df_4hour_swings.filter(\n",
    "        pl.col('close') > pl.col('swing_high')\n",
    "    )\n",
    "    \n",
    "    # Breakdowns below swing lows\n",
    "    breakdowns = df_4hour_swings.filter(\n",
    "        pl.col('close') < pl.col('swing_low')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🚀 Swing Analysis:\")\n",
    "    print(f\"  Breakouts (above swing high): {len(breakouts)}\")\n",
    "    print(f\"  Breakdowns (below swing low): {len(breakdowns)}\")\n",
    "    \n",
    "    if len(breakouts) > 0:\n",
    "        print(\"\\n  Recent breakouts:\")\n",
    "        print(breakouts.select(['datetime', 'close', 'swing_high', 'volume']).tail(3))\n",
    "\n",
    "# Weekly statistics\n",
    "if len(df_4hour) > 0:\n",
    "    weekly_stats = df_4hour.select([\n",
    "        pl.col('pct_change').mean().alias('avg_4h_change'),\n",
    "        pl.col('pct_change').std().alias('volatility'),\n",
    "        pl.col('volume').mean().alias('avg_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n📈 4-Hour Statistics:\")\n",
    "    print(weekly_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 - Daily Analysis (Investment/Long-term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1day = enriched_data['1day']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DAILY TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ticker: {PRIMARY_TICKER}\")\n",
    "print(f\"Total candles: {len(df_1day)}\")\n",
    "print(f\"Date range: {df_1day['datetime'].min()} to {df_1day['datetime'].max()}\")\n",
    "\n",
    "# Major moving average analysis\n",
    "if all(col in df_1day.columns for col in ['sma_50', 'sma_200']):\n",
    "    current_price = df_1day.select(pl.col('close').last()).item()\n",
    "    sma_50 = df_1day.select(pl.col('sma_50').last()).item()\n",
    "    sma_200 = df_1day.select(pl.col('sma_200').last()).item()\n",
    "    \n",
    "    print(f\"\\n📊 Major Moving Averages:\")\n",
    "    print(f\"  Current Price: ${current_price:.2f}\")\n",
    "    print(f\"  50-day SMA: ${sma_50:.2f}\")\n",
    "    print(f\"  200-day SMA: ${sma_200:.2f}\")\n",
    "    \n",
    "    if sma_50 > sma_200:\n",
    "        print(\"  Golden Cross: YES ✅ (Bullish)\")\n",
    "    else:\n",
    "        print(\"  Death Cross: YES ❌ (Bearish)\")\n",
    "    \n",
    "    # Detect recent crossovers\n",
    "    df_1day_crosses = df_1day.with_columns([\n",
    "        (pl.col('sma_50') > pl.col('sma_200')).alias('golden_cross_active'),\n",
    "    ])\n",
    "    \n",
    "    df_1day_crosses = df_1day_crosses.with_columns(\n",
    "        (pl.col('golden_cross_active') != pl.col('golden_cross_active').shift(1)).alias('cross_occurred')\n",
    "    )\n",
    "    \n",
    "    recent_crosses = df_1day_crosses.filter(pl.col('cross_occurred')).tail(5)\n",
    "    if len(recent_crosses) > 0:\n",
    "        print(\"\\n  Recent MA Crosses:\")\n",
    "        print(recent_crosses.select(['datetime', 'close', 'sma_50', 'sma_200']))\n",
    "\n",
    "# Year-to-date performance\n",
    "if len(df_1day) > 0:\n",
    "    latest = df_1day.select('datetime', 'close').sort('datetime').tail(1)\n",
    "    latest_date = latest['datetime'].item()\n",
    "    latest_price = latest['close'].item()\n",
    "    \n",
    "    # Find first price of the year\n",
    "    year_start = df_1day.filter(\n",
    "        pl.col('datetime').dt.year() == latest_date.year\n",
    "    ).sort('datetime').head(1)\n",
    "    \n",
    "    if len(year_start) > 0:\n",
    "        year_start_price = year_start['close'].item()\n",
    "        ytd_return = ((latest_price - year_start_price) / year_start_price) * 100\n",
    "        \n",
    "        print(f\"\\n📈 Year-to-Date Performance:\")\n",
    "        print(f\"  Start of year price: ${year_start_price:.2f}\")\n",
    "        print(f\"  Current price: ${latest_price:.2f}\")\n",
    "        print(f\"  YTD Return: {ytd_return:+.2f}%\")\n",
    "\n",
    "# Monthly returns analysis\n",
    "monthly_returns = df_1day.with_columns(\n",
    "    pl.col('datetime').dt.strftime('%Y-%m').alias('month')\n",
    ").group_by('month').agg([\n",
    "    pl.col('close').first().alias('month_open'),\n",
    "    pl.col('close').last().alias('month_close'),\n",
    "    pl.col('high').max().alias('month_high'),\n",
    "    pl.col('low').min().alias('month_low'),\n",
    "    pl.col('volume').sum().alias('month_volume')\n",
    "]).with_columns(\n",
    "    ((pl.col('month_close') - pl.col('month_open')) / pl.col('month_open') * 100).alias('monthly_return')\n",
    ").sort('month')\n",
    "\n",
    "print(\"\\n📅 Monthly Returns (Last 12 months):\")\n",
    "print(monthly_returns.tail(12))\n",
    "\n",
    "# Statistical summary\n",
    "if len(df_1day) > 0:\n",
    "    daily_stats = df_1day.select([\n",
    "        pl.col('close').max().alias('all_time_high'),\n",
    "        pl.col('close').min().alias('all_time_low'),\n",
    "        pl.col('pct_change').mean().alias('avg_daily_change'),\n",
    "        pl.col('pct_change').std().alias('daily_volatility'),\n",
    "        pl.col('volume').mean().alias('avg_daily_volume'),\n",
    "        pl.col('rsi').mean().alias('avg_rsi')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n📊 Daily Statistics Summary:\")\n",
    "    print(daily_stats)\n",
    "\n",
    "# Drawdown analysis\n",
    "if len(df_1day) > 0:\n",
    "    df_1day_dd = df_1day.with_columns(\n",
    "        pl.col('close').cum_max().alias('running_max')\n",
    "    ).with_columns(\n",
    "        ((pl.col('close') - pl.col('running_max')) / pl.col('running_max') * 100).alias('drawdown_pct')\n",
    "    )\n",
    "    \n",
    "    max_drawdown = df_1day_dd.select(pl.col('drawdown_pct').min()).item()\n",
    "    max_dd_row = df_1day_dd.filter(pl.col('drawdown_pct') == max_drawdown)\n",
    "    \n",
    "    print(f\"\\n📉 Drawdown Analysis:\")\n",
    "    print(f\"  Maximum Drawdown: {max_drawdown:.2f}%\")\n",
    "    if len(max_dd_row) > 0:\n",
    "        print(f\"  Occurred on: {max_dd_row['datetime'].item()}\")\n",
    "        print(f\"  Price at max DD: ${max_dd_row['close'].item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Timeframe Analysis\n",
    "\n",
    "Compare signals and trends across multiple timeframes for comprehensive market view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROSS-TIMEFRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get latest values from each timeframe\n",
    "def get_latest_metrics(df: pl.DataFrame, timeframe: str) -> dict:\n",
    "    \"\"\"Extract latest metrics from a timeframe.\"\"\"\n",
    "    if df.is_empty():\n",
    "        return None\n",
    "    \n",
    "    latest = df.sort('datetime').tail(1)\n",
    "    \n",
    "    metrics = {\n",
    "        'timeframe': timeframe,\n",
    "        'datetime': latest['datetime'].item(),\n",
    "        'close': latest['close'].item(),\n",
    "    }\n",
    "    \n",
    "    # Add available indicators\n",
    "    for col in ['rsi', 'macd', 'macd_signal', 'atr', 'bb_width', 'volume_ratio']:\n",
    "        if col in latest.columns:\n",
    "            metrics[col] = latest[col].item()\n",
    "    \n",
    "    # Trend determination\n",
    "    if 'sma_5' in latest.columns and 'sma_20' in latest.columns:\n",
    "        sma_5 = latest['sma_5'].item()\n",
    "        sma_20 = latest['sma_20'].item()\n",
    "        close = latest['close'].item()\n",
    "        \n",
    "        if close > sma_5 > sma_20:\n",
    "            metrics['trend'] = 'bullish'\n",
    "        elif close < sma_5 < sma_20:\n",
    "            metrics['trend'] = 'bearish'\n",
    "        else:\n",
    "            metrics['trend'] = 'mixed'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Collect metrics from all timeframes\n",
    "timeframe_comparison = []\n",
    "for tf_name, df in enriched_data.items():\n",
    "    metrics = get_latest_metrics(df, tf_name)\n",
    "    if metrics:\n",
    "        timeframe_comparison.append(metrics)\n",
    "\n",
    "# Create comparison dataframe\n",
    "if timeframe_comparison:\n",
    "    df_comparison = pl.DataFrame(timeframe_comparison)\n",
    "    \n",
    "    print(\"\\n📊 Latest Metrics Across All Timeframes:\")\n",
    "    print(df_comparison)\n",
    "    \n",
    "    # Trend alignment\n",
    "    if 'trend' in df_comparison.columns:\n",
    "        trend_summary = df_comparison.group_by('trend').agg(\n",
    "            pl.col('timeframe').count().alias('count')\n",
    "        )\n",
    "        \n",
    "        print(\"\\n🎯 Trend Alignment:\")\n",
    "        print(trend_summary)\n",
    "        \n",
    "        bullish_count = trend_summary.filter(pl.col('trend') == 'bullish')['count'].sum()\n",
    "        bearish_count = trend_summary.filter(pl.col('trend') == 'bearish')['count'].sum()\n",
    "        \n",
    "        print(f\"\\n  Overall Market Bias:\")\n",
    "        if bullish_count > bearish_count:\n",
    "            print(f\"  BULLISH ({bullish_count}/{len(timeframe_comparison)} timeframes) 🟢\")\n",
    "        elif bearish_count > bullish_count:\n",
    "            print(f\"  BEARISH ({bearish_count}/{len(timeframe_comparison)} timeframes) 🔴\")\n",
    "        else:\n",
    "            print(f\"  NEUTRAL (Mixed signals) ⚪\")\n",
    "    \n",
    "    # RSI comparison\n",
    "    if 'rsi' in df_comparison.columns:\n",
    "        print(\"\\n📊 RSI Across Timeframes:\")\n",
    "        rsi_data = df_comparison.select(['timeframe', 'rsi']).sort('timeframe')\n",
    "        print(rsi_data)\n",
    "        \n",
    "        avg_rsi = df_comparison['rsi'].mean()\n",
    "        print(f\"\\n  Average RSI across all timeframes: {avg_rsi:.2f}\")\n",
    "        \n",
    "        if avg_rsi < 30:\n",
    "            print(\"  ⚠️ Overall OVERSOLD condition\")\n",
    "        elif avg_rsi > 70:\n",
    "            print(\"  ⚠️ Overall OVERBOUGHT condition\")\n",
    "        else:\n",
    "            print(\"  ✅ Neutral RSI conditions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading Signals Summary\n",
    "\n",
    "Consolidated view of trading signals across all timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trading_signals(df: pl.DataFrame, timeframe: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on multiple indicators.\n",
    "    \"\"\"\n",
    "    if df.is_empty() or len(df) < 5:\n",
    "        return None\n",
    "    \n",
    "    latest = df.sort('datetime').tail(1)\n",
    "    \n",
    "    signals = {\n",
    "        'timeframe': timeframe,\n",
    "        'datetime': latest['datetime'].item(),\n",
    "        'price': latest['close'].item()\n",
    "    }\n",
    "    \n",
    "    bullish_signals = 0\n",
    "    bearish_signals = 0\n",
    "    signal_details = []\n",
    "    \n",
    "    # RSI signals\n",
    "    if 'rsi' in latest.columns:\n",
    "        rsi = latest['rsi'].item()\n",
    "        if rsi is not None:\n",
    "            if rsi < 30:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(f\"RSI oversold ({rsi:.1f})\")\n",
    "            elif rsi > 70:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(f\"RSI overbought ({rsi:.1f})\")\n",
    "    \n",
    "    # MACD signals\n",
    "    if 'macd' in latest.columns and 'macd_signal' in latest.columns:\n",
    "        macd = latest['macd'].item()\n",
    "        macd_signal = latest['macd_signal'].item()\n",
    "        if macd is not None and macd_signal is not None:\n",
    "            if macd > macd_signal:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"MACD bullish\")\n",
    "            else:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"MACD bearish\")\n",
    "    \n",
    "    # Moving average signals\n",
    "    if 'sma_5' in latest.columns and 'sma_20' in latest.columns:\n",
    "        close = latest['close'].item()\n",
    "        sma_5 = latest['sma_5'].item()\n",
    "        sma_20 = latest['sma_20'].item()\n",
    "        \n",
    "        if sma_5 is not None and sma_20 is not None:\n",
    "            if close > sma_5 > sma_20:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"MA alignment bullish\")\n",
    "            elif close < sma_5 < sma_20:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"MA alignment bearish\")\n",
    "    \n",
    "    # Bollinger Band signals\n",
    "    if all(col in latest.columns for col in ['close', 'bb_upper', 'bb_lower']):\n",
    "        close = latest['close'].item()\n",
    "        bb_upper = latest['bb_upper'].item()\n",
    "        bb_lower = latest['bb_lower'].item()\n",
    "        \n",
    "        if all(v is not None for v in [close, bb_upper, bb_lower]):\n",
    "            if close < bb_lower:\n",
    "                bullish_signals += 1\n",
    "                signal_details.append(\"Below BB lower band\")\n",
    "            elif close > bb_upper:\n",
    "                bearish_signals += 1\n",
    "                signal_details.append(\"Above BB upper band\")\n",
    "    \n",
    "    # Determine overall signal\n",
    "    total_signals = bullish_signals + bearish_signals\n",
    "    if total_signals > 0:\n",
    "        if bullish_signals > bearish_signals:\n",
    "            signals['signal'] = 'BUY'\n",
    "            signals['strength'] = f\"{bullish_signals}/{total_signals}\"\n",
    "        elif bearish_signals > bullish_signals:\n",
    "            signals['signal'] = 'SELL'\n",
    "            signals['strength'] = f\"{bearish_signals}/{total_signals}\"\n",
    "        else:\n",
    "            signals['signal'] = 'HOLD'\n",
    "            signals['strength'] = f\"{max(bullish_signals, bearish_signals)}/{total_signals}\"\n",
    "    else:\n",
    "        signals['signal'] = 'HOLD'\n",
    "        signals['strength'] = '0/0'\n",
    "    \n",
    "    signals['details'] = ', '.join(signal_details) if signal_details else 'No clear signals'\n",
    "    \n",
    "    return signals\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRADING SIGNALS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate signals for all timeframes\n",
    "all_signals = []\n",
    "for tf_name, df in enriched_data.items():\n",
    "    signals = generate_trading_signals(df, tf_name)\n",
    "    if signals:\n",
    "        all_signals.append(signals)\n",
    "\n",
    "if all_signals:\n",
    "    df_signals = pl.DataFrame(all_signals)\n",
    "    \n",
    "    print(\"\\n🎯 Trading Signals Across All Timeframes:\")\n",
    "    print(df_signals.select(['timeframe', 'signal', 'strength', 'details']))\n",
    "    \n",
    "    # Signal consensus\n",
    "    signal_counts = df_signals.group_by('signal').agg(\n",
    "        pl.col('timeframe').count().alias('count')\n",
    "    ).sort('count', descending=True)\n",
    "    \n",
    "    print(\"\\n📊 Signal Consensus:\")\n",
    "    print(signal_counts)\n",
    "    \n",
    "    # Overall recommendation\n",
    "    buy_count = signal_counts.filter(pl.col('signal') == 'BUY')['count'].sum()\n",
    "    sell_count = signal_counts.filter(pl.col('signal') == 'SELL')['count'].sum()\n",
    "    hold_count = signal_counts.filter(pl.col('signal') == 'HOLD')['count'].sum()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OVERALL RECOMMENDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if buy_count > sell_count and buy_count > hold_count:\n",
    "        print(f\"\\n🟢 BULLISH BIAS: {buy_count}/{len(all_signals)} timeframes suggest BUY\")\n",
    "    elif sell_count > buy_count and sell_count > hold_count:\n",
    "        print(f\"\\n🔴 BEARISH BIAS: {sell_count}/{len(all_signals)} timeframes suggest SELL\")\n",
    "    else:\n",
    "        print(f\"\\n⚪ NEUTRAL: Mixed signals across timeframes (Hold recommended)\")\n",
    "    \n",
    "    print(\"\\n⚠️ Disclaimer: This is for educational purposes only.\")\n",
    "    print(\"   Not financial advice. Always do your own research.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Data for Further Analysis\n",
    "\n",
    "Save processed data to CSV files for external analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export data\n",
    "\n",
    "# for tf_name, df in enriched_data.items():\n",
    "#     if not df.is_empty():\n",
    "#         filename = f\"{PRIMARY_TICKER}_{tf_name}_analysis.csv\"\n",
    "#         df.write_csv(filename)\n",
    "#         print(f\"Exported {filename}\")\n",
    "\n",
    "print(\"\\n✅ Analysis Complete!\")\n",
    "print(\"\\nTo export data, uncomment the code block above and run the cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Acquisition**: Fetching multi-timeframe stock data using yfinance\n",
    "2. **Polars Integration**: Converting and processing data with Polars for high performance\n",
    "3. **Technical Indicators**: Implementing various indicators (MA, RSI, MACD, BB, ATR, etc.)\n",
    "4. **Multi-Timeframe Analysis**: Analyzing 10min, 15min, 30min, 1hr, 4hr, and daily timeframes\n",
    "5. **Cross-Timeframe Comparison**: Identifying trends and signals across different timeframes\n",
    "6. **Trading Signals**: Generating actionable signals based on multiple indicators\n",
    "7. **Polars Features**: Leveraging expressions, lazy evaluation, window functions, and aggregations\n",
    "\n",
    "### Key Polars Operations Used:\n",
    "- DataFrame transformations with `with_columns`\n",
    "- Window functions with `rolling_mean`, `rolling_std`, `rolling_max`, `rolling_min`\n",
    "- Conditional expressions with `when`, `then`, `otherwise`\n",
    "- Aggregations with `group_by` and `agg`\n",
    "- Filtering and sorting\n",
    "- DateTime operations\n",
    "- Expression chaining for complex calculations\n",
    "\n",
    "This approach provides a comprehensive framework for stock market analysis using modern data tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}