{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Window Functions - Comprehensive Guide\n",
    "\n",
    "Window functions perform calculations across rows related to the current row.\n",
    "\n",
    "## Topics Covered:\n",
    "- What are window functions?\n",
    "- over() clause syntax\n",
    "- Ranking functions (rank, dense_rank, row_number)\n",
    "- Lag and Lead\n",
    "- Cumulative operations\n",
    "- Rolling windows\n",
    "- Partition by multiple columns\n",
    "- Practical examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What are Window Functions?\n",
    "\n",
    "Window functions compute values **over** a \"window\" of rows, without collapsing rows like group_by does.\n",
    "\n",
    "**Key difference from group_by:**\n",
    "- `group_by`: Returns 1 row per group\n",
    "- `over`: Returns same number of rows as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sales data\n",
    "df = pl.DataFrame({\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n",
    "    'product': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'sales': [100, 150, 120, 200, 180, 220],\n",
    "    'region': ['North', 'North', 'South', 'North', 'South', 'North']\n",
    "})\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_by: Returns 2 rows (one per product)\n",
    "grouped = df.group_by('product').agg(pl.col('sales').mean().alias('avg_sales'))\n",
    "print(\"group_by (2 rows):\")\n",
    "print(grouped)\n",
    "\n",
    "# over: Returns 6 rows (same as input)\n",
    "windowed = df.with_columns(\n",
    "    pl.col('sales').mean().over('product').alias('avg_sales')\n",
    ")\n",
    "print(\"\\nover (6 rows):\")\n",
    "print(windowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Window Functions with over()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical aggregations over partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stats per product\n",
    "result = df.with_columns([\n",
    "    pl.col('sales').mean().over('product').alias('product_avg'),\n",
    "    pl.col('sales').sum().over('product').alias('product_total'),\n",
    "    pl.col('sales').min().over('product').alias('product_min'),\n",
    "    pl.col('sales').max().over('product').alias('product_max'),\n",
    "    pl.len().over('product').alias('product_count')\n",
    "])\n",
    "\n",
    "print(\"Stats per product (repeated for each row):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference from group mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much each sale deviates from product average\n",
    "result = df.with_columns([\n",
    "    pl.col('sales').mean().over('product').alias('product_avg'),\n",
    "    (pl.col('sales') - pl.col('sales').mean().over('product')).alias('deviation_from_avg'),\n",
    "    ((pl.col('sales') - pl.col('sales').mean().over('product')) / pl.col('sales').mean().over('product') * 100)\n",
    "      .alias('pct_deviation')\n",
    "])\n",
    "\n",
    "print(\"Deviation from product average:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of group total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What % of product's total sales does each transaction represent?\n",
    "result = df.with_columns([\n",
    "    pl.col('sales').sum().over('product').alias('product_total'),\n",
    "    (pl.col('sales') / pl.col('sales').sum().over('product') * 100).alias('pct_of_product_total')\n",
    "])\n",
    "\n",
    "print(\"Percentage of product total:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Ranking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with ties\n",
    "rank_df = pl.DataFrame({\n",
    "    'student': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],\n",
    "    'class': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'score': [95, 87, 87, 92, 88, 92]  # Note: ties at 87 and 92\n",
    "})\n",
    "\n",
    "print(\"Student scores with ties:\")\n",
    "print(rank_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank() - Standard ranking (1, 2, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank(): Ties get same rank, next rank is skipped\n",
    "result = rank_df.with_columns([\n",
    "    pl.col('score').rank(descending=True).over('class').alias('rank')\n",
    "]).sort(['class', 'rank'])\n",
    "\n",
    "print(\"rank() - Standard ranking:\")\n",
    "print(result)\n",
    "print(\"\\nNote: In class A, both 87s get rank 2, next is rank 4 (not 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense_rank() - Dense ranking (1, 2, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_rank(): Ties get same rank, next rank is NOT skipped\n",
    "result = rank_df.with_columns([\n",
    "    pl.col('score').rank('dense', descending=True).over('class').alias('dense_rank')\n",
    "]).sort(['class', 'dense_rank'])\n",
    "\n",
    "print(\"dense_rank() - Dense ranking:\")\n",
    "print(result)\n",
    "print(\"\\nNote: In class A, both 87s get rank 2, next is rank 3 (not skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### row_number() - Sequential numbers (1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_number(): No ties, arbitrary order for equal values\n",
    "result = rank_df.with_columns([\n",
    "    pl.col('score').rank('ordinal', descending=True).over('class').alias('row_number')\n",
    "]).sort(['class', 'row_number'])\n",
    "\n",
    "print(\"row_number() - Sequential:\")\n",
    "print(result)\n",
    "print(\"\\nNote: Tied values get different numbers (order is arbitrary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of all three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three together\n",
    "result = rank_df.with_columns([\n",
    "    pl.col('score').rank(descending=True).over('class').alias('rank'),\n",
    "    pl.col('score').rank('dense', descending=True).over('class').alias('dense_rank'),\n",
    "    pl.col('score').rank('ordinal', descending=True).over('class').alias('row_number')\n",
    "]).sort(['class', 'score'], descending=[False, True])\n",
    "\n",
    "print(\"Comparison of ranking methods:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Lag and Lead (Compare with Previous/Next Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data\n",
    "ts_df = pl.DataFrame({\n",
    "    'date': pl.date_range(pl.date(2023, 1, 1), pl.date(2023, 1, 10), '1d', eager=True),\n",
    "    'product': ['A'] * 5 + ['B'] * 5,\n",
    "    'sales': [100, 110, 105, 115, 120, 200, 210, 205, 220, 215]\n",
    "})\n",
    "\n",
    "print(\"Time series data:\")\n",
    "print(ts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shift() - Lag (previous value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get previous day's sales\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').shift(1).over('product').alias('prev_day_sales'),\n",
    "    (pl.col('sales') - pl.col('sales').shift(1).over('product')).alias('daily_change')\n",
    "])\n",
    "\n",
    "print(\"Lag - Compare with previous day:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shift(-n) - Lead (next value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get next day's sales\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').shift(-1).over('product').alias('next_day_sales'),\n",
    "    pl.when(pl.col('sales').shift(-1).over('product') > pl.col('sales'))\n",
    "      .then(pl.lit('Increasing'))\n",
    "      .when(pl.col('sales').shift(-1).over('product') < pl.col('sales'))\n",
    "      .then(pl.lit('Decreasing'))\n",
    "      .otherwise(pl.lit('Stable'))\n",
    "      .alias('trend')\n",
    "])\n",
    "\n",
    "print(\"Lead - Compare with next day:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with multiple previous days\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').shift(1).over('product').alias('lag_1'),\n",
    "    pl.col('sales').shift(2).over('product').alias('lag_2'),\n",
    "    pl.col('sales').shift(3).over('product').alias('lag_3')\n",
    "])\n",
    "\n",
    "print(\"Multiple lags:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Cumulative Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running total per product\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').cum_sum().over('product').alias('cumulative_sales'),\n",
    "    (pl.col('sales').cum_sum().over('product') / pl.col('sales').sum().over('product') * 100)\n",
    "      .alias('pct_of_total')\n",
    "])\n",
    "\n",
    "print(\"Cumulative sum:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other cumulative operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple cumulative operations\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').cum_sum().over('product').alias('cum_sum'),\n",
    "    pl.col('sales').cum_min().over('product').alias('cum_min'),\n",
    "    pl.col('sales').cum_max().over('product').alias('cum_max'),\n",
    "    pl.col('sales').cum_count().over('product').alias('cum_count')\n",
    "])\n",
    "\n",
    "print(\"Multiple cumulative operations:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Rolling Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling mean (moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-day moving average\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').rolling_mean(window_size=3).over('product').alias('ma_3day'),\n",
    "    pl.col('sales').rolling_mean(window_size=5).over('product').alias('ma_5day')\n",
    "])\n",
    "\n",
    "print(\"Rolling mean (moving average):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other rolling operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rolling operations with 3-day window\n",
    "result = ts_df.with_columns([\n",
    "    pl.col('sales').rolling_mean(window_size=3).over('product').alias('rolling_mean'),\n",
    "    pl.col('sales').rolling_sum(window_size=3).over('product').alias('rolling_sum'),\n",
    "    pl.col('sales').rolling_min(window_size=3).over('product').alias('rolling_min'),\n",
    "    pl.col('sales').rolling_max(window_size=3).over('product').alias('rolling_max'),\n",
    "    pl.col('sales').rolling_std(window_size=3).over('product').alias('rolling_std')\n",
    "])\n",
    "\n",
    "print(\"Multiple rolling operations (3-day window):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Partitioning by Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with multiple grouping columns\n",
    "multi_df = pl.DataFrame({\n",
    "    'region': ['North', 'North', 'North', 'South', 'South', 'South'],\n",
    "    'product': ['A', 'A', 'B', 'A', 'A', 'B'],\n",
    "    'month': [1, 2, 1, 1, 2, 1],\n",
    "    'sales': [100, 110, 150, 120, 130, 140]\n",
    "})\n",
    "\n",
    "print(\"Multi-level data:\")\n",
    "print(multi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition by multiple columns\n",
    "result = multi_df.with_columns([\n",
    "    pl.col('sales').mean().over(['region', 'product']).alias('region_product_avg'),\n",
    "    pl.col('sales').mean().over('region').alias('region_avg'),\n",
    "    pl.col('sales').mean().over('product').alias('product_avg'),\n",
    "    pl.col('sales').mean().alias('overall_avg')\n",
    "])\n",
    "\n",
    "print(\"Multiple partition levels:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Practical Real-World Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic e-commerce data\n",
    "np.random.seed(42)\n",
    "dates = pl.date_range(pl.date(2023, 1, 1), pl.date(2023, 3, 31), '1d', eager=True)\n",
    "\n",
    "sales_data = pl.DataFrame({\n",
    "    'date': dates,\n",
    "    'product': np.random.choice(['Laptop', 'Mouse', 'Keyboard'], len(dates)),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], len(dates)),\n",
    "    'revenue': np.random.uniform(1000, 5000, len(dates))\n",
    "}).sort('date')\n",
    "\n",
    "print(f\"E-commerce data: {len(sales_data)} days\")\n",
    "print(sales_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Sales trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trends with moving averages and growth rates\n",
    "trend_analysis = sales_data.with_columns([\n",
    "    # 7-day moving average\n",
    "    pl.col('revenue').rolling_mean(window_size=7).over('product').alias('ma_7day'),\n",
    "    \n",
    "    # Day-over-day change\n",
    "    (pl.col('revenue') - pl.col('revenue').shift(1).over('product')).alias('daily_change'),\n",
    "    \n",
    "    # Day-over-day % change\n",
    "    ((pl.col('revenue') - pl.col('revenue').shift(1).over('product')) / \n",
    "     pl.col('revenue').shift(1).over('product') * 100).alias('daily_pct_change'),\n",
    "    \n",
    "    # Running total\n",
    "    pl.col('revenue').cum_sum().over('product').alias('ytd_revenue')\n",
    "])\n",
    "\n",
    "print(\"Sales trend analysis:\")\n",
    "print(trend_analysis.filter(pl.col('product') == 'Laptop').head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Product performance ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank products by revenue within each region\n",
    "product_ranking = (\n",
    "    sales_data\n",
    "    .group_by(['region', 'product'])\n",
    "    .agg(pl.col('revenue').sum().alias('total_revenue'))\n",
    "    .with_columns([\n",
    "        pl.col('total_revenue').rank(descending=True).over('region').alias('rank_in_region'),\n",
    "        (pl.col('total_revenue') / pl.col('total_revenue').sum().over('region') * 100)\n",
    "          .alias('pct_of_region')\n",
    "    ])\n",
    "    .sort(['region', 'rank_in_region'])\n",
    ")\n",
    "\n",
    "print(\"Product ranking by region:\")\n",
    "print(product_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Quartile analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each day's performance into quartiles\n",
    "quartile_analysis = sales_data.with_columns([\n",
    "    pl.col('revenue').quantile(0.25).over('product').alias('q1'),\n",
    "    pl.col('revenue').quantile(0.50).over('product').alias('q2_median'),\n",
    "    pl.col('revenue').quantile(0.75).over('product').alias('q3'),\n",
    "]).with_columns([\n",
    "    pl.when(pl.col('revenue') <= pl.col('q1'))\n",
    "      .then(pl.lit('Q1 (Bottom 25%)'))\n",
    "      .when(pl.col('revenue') <= pl.col('q2_median'))\n",
    "      .then(pl.lit('Q2'))\n",
    "      .when(pl.col('revenue') <= pl.col('q3'))\n",
    "      .then(pl.lit('Q3'))\n",
    "      .otherwise(pl.lit('Q4 (Top 25%)'))\n",
    "      .alias('quartile')\n",
    "])\n",
    "\n",
    "print(\"Quartile analysis:\")\n",
    "print(quartile_analysis.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Top N within each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 3 revenue days for each product\n",
    "top_days = (\n",
    "    sales_data\n",
    "    .with_columns([\n",
    "        pl.col('revenue').rank(descending=True).over('product').alias('rank')\n",
    "    ])\n",
    "    .filter(pl.col('rank') <= 3)\n",
    "    .sort(['product', 'rank'])\n",
    ")\n",
    "\n",
    "print(\"Top 3 revenue days per product:\")\n",
    "print(top_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Complex Window Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 1: Z-score (standardization within group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-score per product\n",
    "zscore = sales_data.with_columns([\n",
    "    ((pl.col('revenue') - pl.col('revenue').mean().over('product')) / \n",
    "     pl.col('revenue').std().over('product')).alias('z_score')\n",
    "]).with_columns([\n",
    "    pl.when(pl.col('z_score').abs() > 2)\n",
    "      .then(pl.lit('Outlier'))\n",
    "      .otherwise(pl.lit('Normal'))\n",
    "      .alias('outlier_status')\n",
    "])\n",
    "\n",
    "print(\"Z-score analysis (outlier detection):\")\n",
    "print(zscore.filter(pl.col('outlier_status') == 'Outlier').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: First and last comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare current value with first and last in group\n",
    "comparison = sales_data.with_columns([\n",
    "    pl.col('revenue').first().over('product').alias('first_revenue'),\n",
    "    pl.col('revenue').last().over('product').alias('last_revenue'),\n",
    "]).with_columns([\n",
    "    (pl.col('revenue') - pl.col('first_revenue')).alias('change_from_first'),\n",
    "    ((pl.col('revenue') - pl.col('first_revenue')) / pl.col('first_revenue') * 100)\n",
    "      .alias('pct_change_from_first')\n",
    "])\n",
    "\n",
    "print(\"Comparison with first value:\")\n",
    "print(comparison.filter(pl.col('product') == 'Laptop').head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Performance Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create large dataset\n",
    "large_df = pl.DataFrame({\n",
    "    'group': np.random.choice(['A', 'B', 'C', 'D', 'E'], 100000),\n",
    "    'value': np.random.randn(100000)\n",
    "})\n",
    "\n",
    "print(f\"Large dataset: {len(large_df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine window functions when possible\n",
    "start = time.time()\n",
    "result = large_df.with_columns([\n",
    "    pl.col('value').mean().over('group').alias('mean'),\n",
    "    pl.col('value').std().over('group').alias('std'),\n",
    "    pl.col('value').min().over('group').alias('min')\n",
    "])\n",
    "time1 = time.time() - start\n",
    "\n",
    "print(f\"Combined window functions: {time1:.4f}s\")\n",
    "print(\"Tip: Combine multiple window operations in single with_columns for efficiency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts:\n",
    "1. **over()** applies operations across a window without collapsing rows\n",
    "2. **Ranking**: rank, dense_rank, row_number for ordering within groups\n",
    "3. **shift()**: Access previous (lag) or next (lead) values\n",
    "4. **Cumulative**: cum_sum, cum_min, cum_max for running totals\n",
    "5. **Rolling**: rolling_mean, rolling_sum for moving windows\n",
    "6. **Partition**: Use multiple columns to define windows\n",
    "\n",
    "### When to Use:\n",
    "- **Ranking**: Leaderboards, top N per group\n",
    "- **Lag/Lead**: Time series comparisons, trends\n",
    "- **Cumulative**: Running totals, YTD calculations\n",
    "- **Rolling**: Moving averages, smoothing\n",
    "- **Stats over window**: Deviations, z-scores, percentages\n",
    "\n",
    "### vs group_by:\n",
    "- Use **group_by** when you want aggregated results (fewer rows)\n",
    "- Use **over** when you want to keep all rows and add aggregated values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
