{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-World Financial Time-Series Analysis with Polars & yfinance\n",
    "\n",
    "Practical examples using real stock market data to demonstrate Polars' powerful time-series capabilities.\n",
    "\n",
    "## Topics:\n",
    "- Fetching real stock data with yfinance\n",
    "- Converting to Polars DataFrames\n",
    "- Multi-stock analysis with group_by_dynamic\n",
    "- Technical analysis indicators\n",
    "- Portfolio analysis\n",
    "- Correlation and covariance analysis\n",
    "- Risk metrics (volatility, Sharpe ratio, drawdowns)\n",
    "- Market regime detection\n",
    "- Trading signals and backtesting basics\n",
    "\n",
    "## Installation\n",
    "```bash\n",
    "pip install yfinance polars\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Set display options\n",
    "pl.Config.set_tbl_rows(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Fetching Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Apple stock data for the last year\n",
    "ticker = 'AAPL'\n",
    "stock = yf.Ticker(ticker)\n",
    "\n",
    "# Get historical data\n",
    "hist = stock.history(period='1y')\n",
    "\n",
    "print(f\"Downloaded {len(hist)} days of data for {ticker}\")\n",
    "print(hist.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Polars DataFrame\n",
    "aapl_df = pl.DataFrame({\n",
    "    'date': hist.index,\n",
    "    'open': hist['Open'].values,\n",
    "    'high': hist['High'].values,\n",
    "    'low': hist['Low'].values,\n",
    "    'close': hist['Close'].values,\n",
    "    'volume': hist['Volume'].values,\n",
    "}).with_columns([\n",
    "    pl.lit(ticker).alias('symbol')\n",
    "])\n",
    "\n",
    "print(\"\\nPolars DataFrame:\")\n",
    "print(aapl_df.head())\n",
    "print(f\"\\nSchema: {aapl_df.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Stocks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for multiple stocks\n",
    "symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "\n",
    "# Download all at once (faster)\n",
    "data = yf.download(symbols, period='2y', group_by='ticker', progress=False)\n",
    "\n",
    "print(f\"Downloaded data for {len(symbols)} stocks\")\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to long format Polars DataFrame\n",
    "stocks_list = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    df = pl.DataFrame({\n",
    "        'date': data[symbol].index,\n",
    "        'open': data[symbol]['Open'].values,\n",
    "        'high': data[symbol]['High'].values,\n",
    "        'low': data[symbol]['Low'].values,\n",
    "        'close': data[symbol]['Close'].values,\n",
    "        'volume': data[symbol]['Volume'].values,\n",
    "    }).with_columns([\n",
    "        pl.lit(symbol).alias('symbol')\n",
    "    ])\n",
    "    stocks_list.append(df)\n",
    "\n",
    "# Concatenate all stocks\n",
    "stocks_df = pl.concat(stocks_list)\n",
    "\n",
    "print(f\"\\nCombined DataFrame: {len(stocks_df)} records\")\n",
    "print(stocks_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Technical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns for each stock\n",
    "stocks_with_returns = stocks_df.sort(['symbol', 'date']).with_columns([\n",
    "    # Simple returns\n",
    "    (pl.col('close') / pl.col('close').shift(1).over('symbol') - 1).alias('daily_return'),\n",
    "    \n",
    "    # Log returns (better for analysis)\n",
    "    (pl.col('close') / pl.col('close').shift(1).over('symbol')).log().alias('log_return'),\n",
    "    \n",
    "    # Intraday range\n",
    "    ((pl.col('high') - pl.col('low')) / pl.col('close')).alias('daily_range_pct')\n",
    "])\n",
    "\n",
    "print(\"Stocks with returns:\")\n",
    "print(stocks_with_returns.filter(pl.col('symbol') == 'AAPL').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages and Crossovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multiple moving averages\n",
    "stocks_with_ma = stocks_with_returns.with_columns([\n",
    "    # Simple Moving Averages\n",
    "    pl.col('close').rolling_mean(window_size=20).over('symbol').alias('sma_20'),\n",
    "    pl.col('close').rolling_mean(window_size=50).over('symbol').alias('sma_50'),\n",
    "    pl.col('close').rolling_mean(window_size=200).over('symbol').alias('sma_200'),\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    pl.col('close').ewm_mean(span=12).over('symbol').alias('ema_12'),\n",
    "    pl.col('close').ewm_mean(span=26).over('symbol').alias('ema_26'),\n",
    "]).with_columns([\n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    (pl.col('ema_12') - pl.col('ema_26')).alias('macd'),\n",
    "]).with_columns([\n",
    "    # MACD Signal line\n",
    "    pl.col('macd').ewm_mean(span=9).over('symbol').alias('macd_signal'),\n",
    "]).with_columns([\n",
    "    # MACD Histogram\n",
    "    (pl.col('macd') - pl.col('macd_signal')).alias('macd_hist')\n",
    "])\n",
    "\n",
    "# Detect golden cross (SMA 50 crosses above SMA 200)\n",
    "stocks_with_signals = stocks_with_ma.with_columns([\n",
    "    # Previous values\n",
    "    pl.col('sma_50').shift(1).over('symbol').alias('sma_50_prev'),\n",
    "    pl.col('sma_200').shift(1).over('symbol').alias('sma_200_prev'),\n",
    "]).with_columns([\n",
    "    # Golden cross: SMA50 crosses above SMA200\n",
    "    ((pl.col('sma_50') > pl.col('sma_200')) & \n",
    "     (pl.col('sma_50_prev') <= pl.col('sma_200_prev'))).alias('golden_cross'),\n",
    "    \n",
    "    # Death cross: SMA50 crosses below SMA200\n",
    "    ((pl.col('sma_50') < pl.col('sma_200')) & \n",
    "     (pl.col('sma_50_prev') >= pl.col('sma_200_prev'))).alias('death_cross'),\n",
    "])\n",
    "\n",
    "print(\"\\nStocks with moving averages and signals:\")\n",
    "print(stocks_with_signals.filter(pl.col('symbol') == 'AAPL').tail(10).select([\n",
    "    'date', 'symbol', 'close', 'sma_20', 'sma_50', 'sma_200', 'macd', 'macd_signal'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all golden crosses in the dataset\n",
    "golden_crosses = stocks_with_signals.filter(pl.col('golden_cross'))\n",
    "\n",
    "print(f\"\\nFound {len(golden_crosses)} golden cross signals:\")\n",
    "print(golden_crosses.select(['date', 'symbol', 'close', 'sma_50', 'sma_200']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bollinger Bands\n",
    "stocks_with_bb = stocks_with_ma.with_columns([\n",
    "    pl.col('close').rolling_std(window_size=20).over('symbol').alias('bb_std')\n",
    "]).with_columns([\n",
    "    (pl.col('sma_20') + 2 * pl.col('bb_std')).alias('bb_upper'),\n",
    "    (pl.col('sma_20') - 2 * pl.col('bb_std')).alias('bb_lower'),\n",
    "    \n",
    "    # Bollinger Band Width (volatility indicator)\n",
    "    ((pl.col('bb_std') * 4) / pl.col('sma_20')).alias('bb_width'),\n",
    "    \n",
    "    # %B (position within bands)\n",
    "    ((pl.col('close') - (pl.col('sma_20') - 2 * pl.col('bb_std'))) / \n",
    "     (4 * pl.col('bb_std'))).alias('bb_percent')\n",
    "])\n",
    "\n",
    "# Identify when price touches or breaks bands\n",
    "bb_signals = stocks_with_bb.with_columns([\n",
    "    (pl.col('close') > pl.col('bb_upper')).alias('above_upper_band'),\n",
    "    (pl.col('close') < pl.col('bb_lower')).alias('below_lower_band')\n",
    "])\n",
    "\n",
    "print(\"\\nBollinger Bands for AAPL:\")\n",
    "print(bb_signals.filter(pl.col('symbol') == 'AAPL').tail(10).select([\n",
    "    'date', 'close', 'sma_20', 'bb_upper', 'bb_lower', 'bb_width', 'bb_percent'\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSI (Relative Strength Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RSI (14-period)\n",
    "def calculate_rsi(df, period=14):\n",
    "    return df.with_columns([\n",
    "        # Price changes\n",
    "        (pl.col('close') - pl.col('close').shift(1)).alias('price_change')\n",
    "    ]).with_columns([\n",
    "        # Separate gains and losses\n",
    "        pl.when(pl.col('price_change') > 0)\n",
    "          .then(pl.col('price_change'))\n",
    "          .otherwise(0)\n",
    "          .alias('gain'),\n",
    "        pl.when(pl.col('price_change') < 0)\n",
    "          .then(-pl.col('price_change'))\n",
    "          .otherwise(0)\n",
    "          .alias('loss')\n",
    "    ]).with_columns([\n",
    "        # Average gains and losses using EWM\n",
    "        pl.col('gain').ewm_mean(span=period).over('symbol').alias('avg_gain'),\n",
    "        pl.col('loss').ewm_mean(span=period).over('symbol').alias('avg_loss')\n",
    "    ]).with_columns([\n",
    "        # RS and RSI\n",
    "        (pl.col('avg_gain') / pl.col('avg_loss')).alias('rs')\n",
    "    ]).with_columns([\n",
    "        (100 - (100 / (1 + pl.col('rs')))).alias('rsi')\n",
    "    ])\n",
    "\n",
    "stocks_with_rsi = calculate_rsi(stocks_with_returns.sort(['symbol', 'date']))\n",
    "\n",
    "# Identify overbought/oversold conditions\n",
    "rsi_signals = stocks_with_rsi.with_columns([\n",
    "    (pl.col('rsi') > 70).alias('overbought'),\n",
    "    (pl.col('rsi') < 30).alias('oversold')\n",
    "])\n",
    "\n",
    "print(\"\\nRSI for AAPL:\")\n",
    "print(rsi_signals.filter(pl.col('symbol') == 'AAPL').tail(10).select([\n",
    "    'date', 'close', 'rsi', 'overbought', 'oversold'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find recent oversold conditions (potential buy signals)\n",
    "recent_oversold = rsi_signals.filter(\n",
    "    (pl.col('oversold')) & \n",
    "    (pl.col('date') >= (datetime.now() - timedelta(days=30)))\n",
    ")\n",
    "\n",
    "print(f\"\\nOversold signals in the last 30 days:\")\n",
    "print(recent_oversold.select(['date', 'symbol', 'close', 'rsi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Volatility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical volatility at different timeframes\n",
    "volatility_df = stocks_with_returns.with_columns([\n",
    "    # 20-day volatility (annualized)\n",
    "    (pl.col('daily_return').rolling_std(window_size=20).over('symbol') * np.sqrt(252)).alias('volatility_20d'),\n",
    "    \n",
    "    # 50-day volatility\n",
    "    (pl.col('daily_return').rolling_std(window_size=50).over('symbol') * np.sqrt(252)).alias('volatility_50d'),\n",
    "    \n",
    "    # ATR (Average True Range) - 14 periods\n",
    "]).with_columns([\n",
    "    # True Range components\n",
    "    (pl.col('high') - pl.col('low')).alias('hl'),\n",
    "    (pl.col('high') - pl.col('close').shift(1).over('symbol')).abs().alias('hc'),\n",
    "    (pl.col('low') - pl.col('close').shift(1).over('symbol')).abs().alias('lc')\n",
    "]).with_columns([\n",
    "    # True Range is the maximum of the three\n",
    "    pl.max_horizontal(['hl', 'hc', 'lc']).alias('true_range')\n",
    "]).with_columns([\n",
    "    # ATR is the moving average of True Range\n",
    "    pl.col('true_range').rolling_mean(window_size=14).over('symbol').alias('atr')\n",
    "])\n",
    "\n",
    "print(\"\\nVolatility metrics:\")\n",
    "print(volatility_df.filter(pl.col('symbol') == 'TSLA').tail(10).select([\n",
    "    'date', 'symbol', 'close', 'daily_return', 'volatility_20d', 'volatility_50d', 'atr'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare current volatility across stocks\n",
    "latest_volatility = volatility_df.group_by('symbol').agg([\n",
    "    pl.col('date').max().alias('latest_date'),\n",
    "    pl.col('volatility_20d').last().alias('current_vol_20d'),\n",
    "    pl.col('volatility_50d').last().alias('current_vol_50d')\n",
    "]).sort('current_vol_20d', descending=True)\n",
    "\n",
    "print(\"\\nCurrent volatility ranking:\")\n",
    "print(latest_volatility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Using group_by_dynamic for Time-Based Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly and Monthly Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weekly OHLC for each stock\n",
    "weekly_ohlc = stocks_df.sort(['symbol', 'date']).group_by_dynamic(\n",
    "    'date',\n",
    "    every='1w',\n",
    "    by='symbol'\n",
    ").agg([\n",
    "    pl.col('open').first().alias('open'),\n",
    "    pl.col('high').max().alias('high'),\n",
    "    pl.col('low').min().alias('low'),\n",
    "    pl.col('close').last().alias('close'),\n",
    "    pl.col('volume').sum().alias('volume'),\n",
    "]).with_columns([\n",
    "    # Weekly return\n",
    "    ((pl.col('close') - pl.col('open')) / pl.col('open')).alias('weekly_return')\n",
    "])\n",
    "\n",
    "print(\"\\nWeekly OHLC:\")\n",
    "print(weekly_ohlc.filter(pl.col('symbol') == 'AAPL').tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly aggregations\n",
    "monthly_stats = stocks_df.sort(['symbol', 'date']).group_by_dynamic(\n",
    "    'date',\n",
    "    every='1mo',\n",
    "    by='symbol'\n",
    ").agg([\n",
    "    pl.col('close').first().alias('month_open'),\n",
    "    pl.col('close').last().alias('month_close'),\n",
    "    pl.col('high').max().alias('month_high'),\n",
    "    pl.col('low').min().alias('month_low'),\n",
    "    pl.col('volume').mean().alias('avg_daily_volume'),\n",
    "    pl.len().alias('trading_days')\n",
    "]).with_columns([\n",
    "    ((pl.col('month_close') - pl.col('month_open')) / pl.col('month_open')).alias('monthly_return')\n",
    "])\n",
    "\n",
    "print(\"\\nMonthly statistics:\")\n",
    "print(monthly_stats.filter(pl.col('symbol') == 'AAPL').tail(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarterly Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarterly performance comparison\n",
    "quarterly_perf = stocks_df.sort(['symbol', 'date']).group_by_dynamic(\n",
    "    'date',\n",
    "    every='1q',  # Quarterly\n",
    "    by='symbol'\n",
    ").agg([\n",
    "    pl.col('close').first().alias('q_open'),\n",
    "    pl.col('close').last().alias('q_close'),\n",
    "    pl.col('high').max().alias('q_high'),\n",
    "    pl.col('low').min().alias('q_low'),\n",
    "]).with_columns([\n",
    "    ((pl.col('q_close') - pl.col('q_open')) / pl.col('q_open') * 100).alias('q_return_pct')\n",
    "])\n",
    "\n",
    "# Pivot to compare stocks side by side\n",
    "quarterly_comparison = quarterly_perf.pivot(\n",
    "    values='q_return_pct',\n",
    "    index='date',\n",
    "    columns='symbol'\n",
    ").sort('date')\n",
    "\n",
    "print(\"\\nQuarterly returns comparison (%):\")\n",
    "print(quarterly_comparison.tail(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an equal-weighted portfolio\n",
    "portfolio_weights = {symbol: 1.0 / len(symbols) for symbol in symbols}\n",
    "\n",
    "print(\"Portfolio weights:\")\n",
    "for symbol, weight in portfolio_weights.items():\n",
    "    print(f\"{symbol}: {weight:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio daily returns\n",
    "portfolio_df = stocks_with_returns.select([\n",
    "    'date', 'symbol', 'close', 'daily_return'\n",
    "]).with_columns([\n",
    "    pl.col('symbol').replace_strict(\n",
    "        old=list(portfolio_weights.keys()),\n",
    "        new=list(portfolio_weights.values())\n",
    "    ).alias('weight')\n",
    "]).with_columns([\n",
    "    (pl.col('daily_return') * pl.col('weight')).alias('weighted_return')\n",
    "])\n",
    "\n",
    "# Aggregate to get portfolio returns\n",
    "portfolio_returns = portfolio_df.group_by('date').agg([\n",
    "    pl.col('weighted_return').sum().alias('portfolio_return')\n",
    "]).sort('date')\n",
    "\n",
    "print(\"\\nPortfolio daily returns:\")\n",
    "print(portfolio_returns.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative portfolio value (starting with $10,000)\n",
    "portfolio_value = portfolio_returns.with_columns([\n",
    "    (pl.col('portfolio_return') + 1).alias('growth_factor')\n",
    "]).with_columns([\n",
    "    (pl.col('growth_factor').cum_prod() * 10000).alias('portfolio_value')\n",
    "])\n",
    "\n",
    "# Portfolio statistics\n",
    "total_return = (portfolio_value['portfolio_value'][-1] / 10000 - 1) * 100\n",
    "avg_daily_return = portfolio_returns['portfolio_return'].mean() * 100\n",
    "volatility = portfolio_returns['portfolio_return'].std() * np.sqrt(252) * 100\n",
    "\n",
    "print(f\"\\nPortfolio Performance:\")\n",
    "print(f\"Initial Investment: $10,000\")\n",
    "print(f\"Final Value: ${portfolio_value['portfolio_value'][-1]:,.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Average Daily Return: {avg_daily_return:.4f}%\")\n",
    "print(f\"Annualized Volatility: {volatility:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Ratio Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe Ratio (assuming 4% risk-free rate)\n",
    "risk_free_rate = 0.04\n",
    "daily_rf_rate = risk_free_rate / 252\n",
    "\n",
    "portfolio_metrics = portfolio_returns.with_columns([\n",
    "    (pl.col('portfolio_return') - daily_rf_rate).alias('excess_return')\n",
    "])\n",
    "\n",
    "# Calculate Sharpe Ratio\n",
    "avg_excess_return = portfolio_metrics['excess_return'].mean()\n",
    "std_excess_return = portfolio_metrics['excess_return'].std()\n",
    "sharpe_ratio = (avg_excess_return / std_excess_return) * np.sqrt(252)\n",
    "\n",
    "print(f\"\\nSharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "print(f\"Annualized Excess Return: {avg_excess_return * 252 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdown\n",
    "drawdown_df = portfolio_value.with_columns([\n",
    "    pl.col('portfolio_value').cum_max().alias('running_max')\n",
    "]).with_columns([\n",
    "    ((pl.col('portfolio_value') - pl.col('running_max')) / pl.col('running_max')).alias('drawdown')\n",
    "])\n",
    "\n",
    "# Find maximum drawdown\n",
    "max_drawdown = drawdown_df['drawdown'].min() * 100\n",
    "max_dd_date = drawdown_df.filter(\n",
    "    pl.col('drawdown') == drawdown_df['drawdown'].min()\n",
    ")['date'][0]\n",
    "\n",
    "print(f\"\\nMaximum Drawdown: {max_drawdown:.2f}%\")\n",
    "print(f\"Occurred on: {max_dd_date}\")\n",
    "\n",
    "# Show worst drawdown periods\n",
    "print(\"\\nWorst 5 drawdown periods:\")\n",
    "print(drawdown_df.sort('drawdown').head(5).select(['date', 'portfolio_value', 'running_max', 'drawdown']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot returns to wide format for correlation calculation\n",
    "returns_wide = stocks_with_returns.select([\n",
    "    'date', 'symbol', 'daily_return'\n",
    "]).filter(\n",
    "    pl.col('daily_return').is_not_null()\n",
    ").pivot(\n",
    "    values='daily_return',\n",
    "    index='date',\n",
    "    columns='symbol'\n",
    ").sort('date')\n",
    "\n",
    "print(\"Returns in wide format:\")\n",
    "print(returns_wide.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "# Note: Polars doesn't have built-in correlation matrix, so we'll use select with corr\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "\n",
    "for i, symbol1 in enumerate(symbols):\n",
    "    for symbol2 in symbols[i+1:]:\n",
    "        corr = returns_wide.select(\n",
    "            pl.corr(symbol1, symbol2).alias('correlation')\n",
    "        )['correlation'][0]\n",
    "        print(f\"{symbol1} vs {symbol2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 60-day rolling correlation between AAPL and MSFT\n",
    "aapl_msft_corr = returns_wide.with_columns([\n",
    "    pl.rolling_corr('AAPL', 'MSFT', window_size=60).alias('aapl_msft_corr_60d')\n",
    "])\n",
    "\n",
    "print(\"\\n60-day rolling correlation between AAPL and MSFT:\")\n",
    "print(aapl_msft_corr.select(['date', 'AAPL', 'MSFT', 'aapl_msft_corr_60d']).tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Advanced Analysis - Intraday Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 1-minute intraday data (last 7 days)\n",
    "ticker_intraday = 'AAPL'\n",
    "intraday_data = yf.download(\n",
    "    ticker_intraday, \n",
    "    period='7d', \n",
    "    interval='1m',\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "print(f\"Downloaded {len(intraday_data)} minutes of intraday data for {ticker_intraday}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Polars\n",
    "intraday_df = pl.DataFrame({\n",
    "    'timestamp': intraday_data.index,\n",
    "    'open': intraday_data['Open'].values,\n",
    "    'high': intraday_data['High'].values,\n",
    "    'low': intraday_data['Low'].values,\n",
    "    'close': intraday_data['Close'].values,\n",
    "    'volume': intraday_data['Volume'].values,\n",
    "})\n",
    "\n",
    "print(\"\\nIntraday data:\")\n",
    "print(intraday_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate to 5-minute and 15-minute Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-minute OHLC bars\n",
    "bars_5m = intraday_df.group_by_dynamic(\n",
    "    'timestamp',\n",
    "    every='5m'\n",
    ").agg([\n",
    "    pl.col('open').first().alias('open'),\n",
    "    pl.col('high').max().alias('high'),\n",
    "    pl.col('low').min().alias('low'),\n",
    "    pl.col('close').last().alias('close'),\n",
    "    pl.col('volume').sum().alias('volume'),\n",
    "    pl.len().alias('num_ticks')\n",
    "])\n",
    "\n",
    "print(\"\\n5-minute OHLC bars:\")\n",
    "print(bars_5m.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 15-minute bars with VWAP\n",
    "bars_15m = intraday_df.group_by_dynamic(\n",
    "    'timestamp',\n",
    "    every='15m'\n",
    ").agg([\n",
    "    pl.col('open').first().alias('open'),\n",
    "    pl.col('high').max().alias('high'),\n",
    "    pl.col('low').min().alias('low'),\n",
    "    pl.col('close').last().alias('close'),\n",
    "    pl.col('volume').sum().alias('volume'),\n",
    "    # VWAP calculation\n",
    "    ((pl.col('close') * pl.col('volume')).sum() / pl.col('volume').sum()).alias('vwap')\n",
    "])\n",
    "\n",
    "print(\"\\n15-minute bars with VWAP:\")\n",
    "print(bars_15m.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intraday Volume Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze volume by hour of day\n",
    "intraday_with_time = intraday_df.with_columns([\n",
    "    pl.col('timestamp').dt.hour().alias('hour'),\n",
    "    pl.col('timestamp').dt.date().alias('date')\n",
    "])\n",
    "\n",
    "hourly_volume = intraday_with_time.group_by('hour').agg([\n",
    "    pl.col('volume').mean().alias('avg_volume'),\n",
    "    pl.col('volume').sum().alias('total_volume'),\n",
    "    pl.len().alias('num_minutes')\n",
    "]).sort('hour')\n",
    "\n",
    "print(\"\\nAverage volume by hour of day:\")\n",
    "print(hourly_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and Closing Price Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze first and last 30 minutes of trading\n",
    "daily_open_close = intraday_with_time.group_by_dynamic(\n",
    "    'timestamp',\n",
    "    every='1d'\n",
    ").agg([\n",
    "    pl.col('open').first().alias('day_open'),\n",
    "    pl.col('close').last().alias('day_close'),\n",
    "]).with_columns([\n",
    "    ((pl.col('day_close') - pl.col('day_open')) / pl.col('day_open') * 100).alias('daily_change_pct')\n",
    "])\n",
    "\n",
    "print(\"\\nDaily open to close changes:\")\n",
    "print(daily_open_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Market Regime Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect market regimes based on volatility and trend\n",
    "regime_df = stocks_with_returns.filter(\n",
    "    pl.col('symbol') == 'AAPL'\n",
    ").with_columns([\n",
    "    # Calculate rolling metrics\n",
    "    pl.col('daily_return').rolling_mean(window_size=20).alias('trend_20d'),\n",
    "    pl.col('daily_return').rolling_std(window_size=20).alias('vol_20d'),\n",
    "    pl.col('close').rolling_mean(window_size=50).alias('sma_50'),\n",
    "    pl.col('close').rolling_mean(window_size=200).alias('sma_200'),\n",
    "]).with_columns([\n",
    "    # Classify regime\n",
    "    pl.when((pl.col('close') > pl.col('sma_200')) & (pl.col('vol_20d') < pl.col('vol_20d').median()))\n",
    "      .then(pl.lit('Bull - Low Vol'))\n",
    "      .when((pl.col('close') > pl.col('sma_200')) & (pl.col('vol_20d') >= pl.col('vol_20d').median()))\n",
    "      .then(pl.lit('Bull - High Vol'))\n",
    "      .when((pl.col('close') <= pl.col('sma_200')) & (pl.col('vol_20d') < pl.col('vol_20d').median()))\n",
    "      .then(pl.lit('Bear - Low Vol'))\n",
    "      .otherwise(pl.lit('Bear - High Vol'))\n",
    "      .alias('regime')\n",
    "])\n",
    "\n",
    "# Count days in each regime\n",
    "regime_counts = regime_df.group_by('regime').agg([\n",
    "    pl.len().alias('num_days'),\n",
    "    pl.col('daily_return').mean().alias('avg_daily_return')\n",
    "])\n",
    "\n",
    "print(\"\\nMarket regime distribution for AAPL:\")\n",
    "print(regime_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show recent regime\n",
    "print(\"\\nRecent market regime:\")\n",
    "print(regime_df.tail(10).select(['date', 'close', 'sma_200', 'vol_20d', 'regime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Simple Trading Signal Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple SMA crossover strategy\n",
    "backtest_df = stocks_with_ma.filter(\n",
    "    pl.col('symbol') == 'AAPL'\n",
    ").with_columns([\n",
    "    # Generate signals\n",
    "    pl.when(pl.col('sma_20') > pl.col('sma_50'))\n",
    "      .then(pl.lit(1))  # Long signal\n",
    "      .otherwise(pl.lit(0))  # No position\n",
    "      .alias('signal')\n",
    "]).with_columns([\n",
    "    # Strategy returns\n",
    "    (pl.col('signal').shift(1) * pl.col('daily_return')).alias('strategy_return')\n",
    "])\n",
    "\n",
    "# Calculate cumulative returns\n",
    "backtest_results = backtest_df.with_columns([\n",
    "    ((pl.col('daily_return') + 1).cum_prod() * 100).alias('buy_hold_value'),\n",
    "    ((pl.col('strategy_return').fill_null(0) + 1).cum_prod() * 100).alias('strategy_value')\n",
    "])\n",
    "\n",
    "# Performance metrics\n",
    "final_bh = backtest_results['buy_hold_value'][-1]\n",
    "final_strategy = backtest_results['strategy_value'][-1]\n",
    "\n",
    "strategy_returns = backtest_results['strategy_return'].fill_null(0)\n",
    "strategy_sharpe = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252)\n",
    "\n",
    "print(\"\\nBacktest Results (SMA 20/50 Crossover):\")\n",
    "print(f\"Buy & Hold Return: {final_bh - 100:.2f}%\")\n",
    "print(f\"Strategy Return: {final_strategy - 100:.2f}%\")\n",
    "print(f\"Strategy Sharpe Ratio: {strategy_sharpe:.3f}\")\n",
    "\n",
    "# Show recent signals\n",
    "print(\"\\nRecent signals:\")\n",
    "print(backtest_results.tail(10).select([\n",
    "    'date', 'close', 'sma_20', 'sma_50', 'signal', 'daily_return', 'strategy_return'\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Comparative Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance summary for all stocks\n",
    "performance_summary = stocks_with_returns.group_by('symbol').agg([\n",
    "    # Return metrics\n",
    "    pl.col('close').first().alias('start_price'),\n",
    "    pl.col('close').last().alias('end_price'),\n",
    "    ((pl.col('close').last() / pl.col('close').first()) - 1).alias('total_return'),\n",
    "    pl.col('daily_return').mean().alias('avg_daily_return'),\n",
    "    \n",
    "    # Risk metrics\n",
    "    pl.col('daily_return').std().alias('daily_volatility'),\n",
    "    pl.col('daily_return').min().alias('worst_day'),\n",
    "    pl.col('daily_return').max().alias('best_day'),\n",
    "    \n",
    "    # Volume\n",
    "    pl.col('volume').mean().alias('avg_volume'),\n",
    "]).with_columns([\n",
    "    # Annualized metrics\n",
    "    (pl.col('avg_daily_return') * 252).alias('annualized_return'),\n",
    "    (pl.col('daily_volatility') * np.sqrt(252)).alias('annualized_volatility'),\n",
    "]).with_columns([\n",
    "    # Sharpe Ratio (assuming 4% risk-free rate)\n",
    "    ((pl.col('annualized_return') - 0.04) / pl.col('annualized_volatility')).alias('sharpe_ratio')\n",
    "]).sort('total_return', descending=True)\n",
    "\n",
    "print(\"\\nComprehensive Performance Summary:\")\n",
    "print(performance_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-adjusted performance comparison\n",
    "print(\"\\nRisk-Adjusted Performance (Sharpe Ratio):\")\n",
    "print(performance_summary.select([\n",
    "    'symbol', 'total_return', 'annualized_volatility', 'sharpe_ratio'\n",
    "]).sort('sharpe_ratio', descending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Polars Time-Series Techniques Demonstrated:\n",
    "\n",
    "1. **Data Integration**: Converting yfinance data to Polars DataFrames\n",
    "2. **group_by_dynamic**: Weekly, monthly, quarterly aggregations\n",
    "3. **Rolling Windows**: Moving averages, RSI, Bollinger Bands, volatility\n",
    "4. **Window Functions**: Over() for grouped calculations\n",
    "5. **Time Components**: Extracting hour, date for intraday analysis\n",
    "6. **Pivoting**: Creating correlation matrices\n",
    "7. **Complex Aggregations**: VWAP, OHLC bars, cumulative metrics\n",
    "8. **Conditional Logic**: Signal generation, regime detection\n",
    "\n",
    "### Financial Concepts Covered:\n",
    "\n",
    "- **Technical Indicators**: SMA, EMA, MACD, RSI, Bollinger Bands, ATR\n",
    "- **Risk Metrics**: Volatility, Sharpe Ratio, Maximum Drawdown\n",
    "- **Portfolio Analysis**: Returns, diversification, correlation\n",
    "- **Market Analysis**: Volume profiles, regime detection\n",
    "- **Trading Strategies**: Crossover signals, backtesting\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. Always sort by date/timestamp before time-series operations\n",
    "2. Use `over()` for grouped rolling calculations\n",
    "3. Handle null values appropriately (especially for returns)\n",
    "4. Annualize metrics for proper comparison (252 trading days)\n",
    "5. Use `group_by_dynamic` for flexible time-based aggregations\n",
    "6. Leverage lazy evaluation for large datasets\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Add more sophisticated indicators (Ichimoku, Fibonacci, etc.)\n",
    "- Implement advanced strategies (mean reversion, momentum)\n",
    "- Add transaction costs and slippage to backtests\n",
    "- Create visualization layers with plotly or matplotlib\n",
    "- Implement portfolio optimization (Markowitz, Black-Litterman)\n",
    "- Add options and derivatives analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
