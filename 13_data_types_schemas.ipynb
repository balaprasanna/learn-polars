{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Data Types and Schema Management - Comprehensive Guide\n",
    "\n",
    "This notebook covers Polars' type system, from basic types to advanced schema management.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Complete overview of Polars data types\n",
    "- Categorical vs Enum types (memory optimization)\n",
    "- Decimal types for financial data\n",
    "- Schema definition and validation\n",
    "- Type casting and coercion\n",
    "- Schema evolution and compatibility\n",
    "- Performance implications of data types\n",
    "- Best practices for type selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Polars Data Types Overview\n",
    "\n",
    "Polars has a rich type system designed for performance and correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Numeric Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer types (signed and unsigned)\n",
    "df_integers = pl.DataFrame({\n",
    "    'int8': pl.Series([1, 2, 3], dtype=pl.Int8),      # -128 to 127\n",
    "    'int16': pl.Series([1, 2, 3], dtype=pl.Int16),    # -32,768 to 32,767\n",
    "    'int32': pl.Series([1, 2, 3], dtype=pl.Int32),    # -2.1B to 2.1B\n",
    "    'int64': pl.Series([1, 2, 3], dtype=pl.Int64),    # -9.2E18 to 9.2E18\n",
    "    'uint8': pl.Series([1, 2, 3], dtype=pl.UInt8),    # 0 to 255\n",
    "    'uint16': pl.Series([1, 2, 3], dtype=pl.UInt16),  # 0 to 65,535\n",
    "    'uint32': pl.Series([1, 2, 3], dtype=pl.UInt32),  # 0 to 4.3B\n",
    "    'uint64': pl.Series([1, 2, 3], dtype=pl.UInt64),  # 0 to 1.8E19\n",
    "})\n",
    "\n",
    "print(\"Integer types:\")\n",
    "print(df_integers.schema)\n",
    "print(f\"\\nMemory usage: {df_integers.estimated_size('mb'):.6f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floating point types\n",
    "df_floats = pl.DataFrame({\n",
    "    'float32': pl.Series([1.5, 2.5, 3.5], dtype=pl.Float32),  # 32-bit float\n",
    "    'float64': pl.Series([1.5, 2.5, 3.5], dtype=pl.Float64),  # 64-bit float (double)\n",
    "})\n",
    "\n",
    "print(\"Float types:\")\n",
    "print(df_floats.schema)\n",
    "print(df_floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the right size (memory efficiency)\n",
    "# Example: Age column\n",
    "ages_int64 = pl.Series('age_int64', [25, 30, 35], dtype=pl.Int64)\n",
    "ages_uint8 = pl.Series('age_uint8', [25, 30, 35], dtype=pl.UInt8)\n",
    "\n",
    "print(f\"Int64 memory: {ages_int64.estimated_size('b')} bytes\")\n",
    "print(f\"UInt8 memory: {ages_uint8.estimated_size('b')} bytes\")\n",
    "print(f\"Memory saved: {(1 - ages_uint8.estimated_size('b') / ages_int64.estimated_size('b')) * 100:.1f}%\")\n",
    "print(\"\\nüí° Use smallest type that fits your data range!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Temporal Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date and time types\n",
    "df_temporal = pl.DataFrame({\n",
    "    'date': pl.Series([date(2024, 1, 1), date(2024, 1, 2)], dtype=pl.Date),\n",
    "    'datetime': pl.Series([datetime(2024, 1, 1, 10, 30), datetime(2024, 1, 2, 14, 45)], dtype=pl.Datetime),\n",
    "    'time': pl.Series([time(10, 30), time(14, 45)], dtype=pl.Time),\n",
    "    'duration': pl.Series([timedelta(days=1), timedelta(hours=2)], dtype=pl.Duration),\n",
    "})\n",
    "\n",
    "print(\"Temporal types:\")\n",
    "print(df_temporal)\n",
    "print(f\"\\nSchema: {df_temporal.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime with timezone\n",
    "df_tz = pl.DataFrame({\n",
    "    'dt_utc': pl.datetime_range(\n",
    "        datetime(2024, 1, 1),\n",
    "        datetime(2024, 1, 3),\n",
    "        interval='1d',\n",
    "        time_zone='UTC',\n",
    "        eager=True\n",
    "    )\n",
    "})\n",
    "\n",
    "print(\"Datetime with timezone:\")\n",
    "print(df_tz)\n",
    "print(f\"Type: {df_tz['dt_utc'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 String and Boolean Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String and Boolean\n",
    "df_basic = pl.DataFrame({\n",
    "    'text': pl.Series(['hello', 'world'], dtype=pl.Utf8),  # UTF-8 encoded strings\n",
    "    'flag': pl.Series([True, False], dtype=pl.Boolean),\n",
    "})\n",
    "\n",
    "print(\"String and Boolean:\")\n",
    "print(df_basic)\n",
    "print(f\"Schema: {df_basic.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Categorical and Enum Types\n",
    "\n",
    "These types are crucial for memory optimization and performance with repetitive string data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Categorical Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with repetitive strings\n",
    "countries = ['USA', 'Canada', 'Mexico'] * 1000\n",
    "\n",
    "# As String (Utf8)\n",
    "df_string = pl.DataFrame({\n",
    "    'country': countries\n",
    "})\n",
    "\n",
    "# As Categorical\n",
    "df_categorical = pl.DataFrame({\n",
    "    'country': pl.Series(countries, dtype=pl.Categorical)\n",
    "})\n",
    "\n",
    "print(\"Memory comparison:\")\n",
    "print(f\"String (Utf8):     {df_string.estimated_size('kb'):.2f} KB\")\n",
    "print(f\"Categorical:       {df_categorical.estimated_size('kb'):.2f} KB\")\n",
    "print(f\"Memory saved:      {(1 - df_categorical.estimated_size('kb') / df_string.estimated_size('kb')) * 100:.1f}%\")\n",
    "print(\"\\nüí° Categorical stores strings once and uses integer indices!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Categorical\n",
    "df = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "# Convert to categorical\n",
    "df_cat = df.with_columns(\n",
    "    pl.col('category').cast(pl.Categorical)\n",
    ")\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df.schema)\n",
    "\n",
    "print(\"\\nAfter casting to Categorical:\")\n",
    "print(df_cat.schema)\n",
    "print(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical operations\n",
    "result = df_cat.group_by('category').agg([\n",
    "    pl.count().alias('count')\n",
    "]).sort('category')\n",
    "\n",
    "print(\"GroupBy on Categorical (fast):\")\n",
    "print(result)\n",
    "\n",
    "# Get categories\n",
    "print(f\"\\nUnique categories: {df_cat['category'].unique().to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Enum Type (Preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum: When categories are known in advance\n",
    "# Enum is FASTER and SAFER than Categorical\n",
    "\n",
    "# Define enum with fixed categories\n",
    "status_enum = pl.Enum(['pending', 'processing', 'completed', 'failed'])\n",
    "\n",
    "df_enum = pl.DataFrame({\n",
    "    'order_id': [1, 2, 3, 4, 5],\n",
    "    'status': pl.Series(['pending', 'completed', 'processing', 'completed', 'failed'], dtype=status_enum)\n",
    "})\n",
    "\n",
    "print(\"DataFrame with Enum:\")\n",
    "print(df_enum)\n",
    "print(f\"\\nSchema: {df_enum.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum validation (rejects invalid values)\n",
    "try:\n",
    "    invalid_df = pl.DataFrame({\n",
    "        'status': pl.Series(['pending', 'invalid_status'], dtype=status_enum)\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error (expected): {type(e).__name__}\")\n",
    "    print(\"Enum enforces valid categories!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum vs Categorical: When to use which?\n",
    "comparison = pl.DataFrame({\n",
    "    'Aspect': [\n",
    "        'Categories known upfront?',\n",
    "        'Performance',\n",
    "        'Memory efficiency',\n",
    "        'Type safety',\n",
    "        'Multiple DataFrames',\n",
    "        'Use case'\n",
    "    ],\n",
    "    'Enum': [\n",
    "        '‚úÖ Yes (required)',\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Fastest',\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best',\n",
    "        '‚úÖ Strict validation',\n",
    "        '‚úÖ Same encoding across DFs',\n",
    "        'Status codes, fixed categories'\n",
    "    ],\n",
    "    'Categorical': [\n",
    "        '‚ùå No (dynamic)',\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê Fast',\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê Good',\n",
    "        '‚ùå No validation',\n",
    "        '‚ö†Ô∏è Different encodings',\n",
    "        'Unknown categories, user input'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Enum vs Categorical:\")\n",
    "print(comparison)\n",
    "print(\"\\nüèÜ Prefer Enum whenever possible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Decimal Type\n",
    "\n",
    "For exact decimal arithmetic (financial calculations, currencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimal type for precise financial calculations\n",
    "# Decimal(precision, scale) where precision=total digits, scale=decimal places\n",
    "\n",
    "df_decimal = pl.DataFrame({\n",
    "    'product': ['A', 'B', 'C'],\n",
    "    'price': pl.Series([19.99, 29.95, 9.99], dtype=pl.Decimal(precision=10, scale=2)),\n",
    "    'tax_rate': pl.Series([0.08, 0.08, 0.08], dtype=pl.Decimal(precision=5, scale=4)),\n",
    "})\n",
    "\n",
    "print(\"Decimal types:\")\n",
    "print(df_decimal)\n",
    "print(f\"\\nSchema: {df_decimal.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimal arithmetic (exact calculations)\n",
    "df_calculated = df_decimal.with_columns([\n",
    "    (pl.col('price') * pl.col('tax_rate')).alias('tax_amount'),\n",
    "    (pl.col('price') * (1 + pl.col('tax_rate'))).alias('total_price')\n",
    "])\n",
    "\n",
    "print(\"Decimal calculations:\")\n",
    "print(df_calculated)\n",
    "print(\"\\nüí° Decimals avoid floating point precision errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float vs Decimal precision\n",
    "# Classic floating point problem\n",
    "float_sum = 0.1 + 0.2\n",
    "print(f\"Float: 0.1 + 0.2 = {float_sum}\")\n",
    "print(f\"Expected: 0.3\")\n",
    "print(f\"Accurate? {float_sum == 0.3}\")\n",
    "\n",
    "# With Decimal\n",
    "df_precision = pl.DataFrame({\n",
    "    'a': pl.Series([Decimal('0.1')], dtype=pl.Decimal(precision=10, scale=2)),\n",
    "    'b': pl.Series([Decimal('0.2')], dtype=pl.Decimal(precision=10, scale=2))\n",
    "}).with_columns(\n",
    "    (pl.col('a') + pl.col('b')).alias('sum')\n",
    ")\n",
    "\n",
    "print(\"\\nWith Decimal:\")\n",
    "print(df_precision)\n",
    "print(\"‚úÖ Exact arithmetic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Schema Definition and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Explicit Schema Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema explicitly for better control\n",
    "schema = {\n",
    "    'user_id': pl.UInt32,\n",
    "    'username': pl.Utf8,\n",
    "    'age': pl.UInt8,\n",
    "    'is_active': pl.Boolean,\n",
    "    'signup_date': pl.Date,\n",
    "    'balance': pl.Decimal(precision=15, scale=2),\n",
    "    'status': pl.Enum(['active', 'inactive', 'pending'])\n",
    "}\n",
    "\n",
    "# Create DataFrame with schema\n",
    "df_schema = pl.DataFrame(\n",
    "    {\n",
    "        'user_id': [1, 2, 3],\n",
    "        'username': ['alice', 'bob', 'charlie'],\n",
    "        'age': [25, 30, 35],\n",
    "        'is_active': [True, True, False],\n",
    "        'signup_date': [date(2024, 1, 1), date(2024, 1, 2), date(2024, 1, 3)],\n",
    "        'balance': [1000.50, 2500.75, 500.00],\n",
    "        'status': ['active', 'active', 'inactive']\n",
    "    },\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "print(\"DataFrame with explicit schema:\")\n",
    "print(df_schema)\n",
    "print(f\"\\nSchema: {df_schema.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV with explicit schema (faster + type safety)\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create sample CSV\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "csv_path = os.path.join(temp_dir, 'users.csv')\n",
    "\n",
    "with open(csv_path, 'w') as f:\n",
    "    f.write('user_id,username,age,is_active,signup_date,balance\\n')\n",
    "    f.write('1,alice,25,true,2024-01-01,1000.50\\n')\n",
    "    f.write('2,bob,30,true,2024-01-02,2500.75\\n')\n",
    "    f.write('3,charlie,35,false,2024-01-03,500.00\\n')\n",
    "\n",
    "# Read with schema\n",
    "csv_schema = {\n",
    "    'user_id': pl.UInt32,\n",
    "    'username': pl.Utf8,\n",
    "    'age': pl.UInt8,\n",
    "    'is_active': pl.Boolean,\n",
    "    'signup_date': pl.Date,\n",
    "    'balance': pl.Float64  # Will be exact in Decimal if needed\n",
    "}\n",
    "\n",
    "df_from_csv = pl.read_csv(csv_path, schema=csv_schema)\n",
    "\n",
    "print(\"Read CSV with schema:\")\n",
    "print(df_from_csv)\n",
    "print(f\"\\nSchema: {df_from_csv.schema}\")\n",
    "print(\"\\nüí° Explicit schema = faster parsing + type safety\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate DataFrame against expected schema\n",
    "def validate_schema(df: pl.DataFrame, expected_schema: dict) -> bool:\n",
    "    \"\"\"Validate DataFrame schema matches expected schema.\"\"\"\n",
    "    actual_schema = df.schema\n",
    "    \n",
    "    # Check all expected columns exist\n",
    "    for col_name, expected_type in expected_schema.items():\n",
    "        if col_name not in actual_schema:\n",
    "            print(f\"‚ùå Missing column: {col_name}\")\n",
    "            return False\n",
    "        \n",
    "        actual_type = actual_schema[col_name]\n",
    "        if actual_type != expected_type:\n",
    "            print(f\"‚ùå Type mismatch for '{col_name}': expected {expected_type}, got {actual_type}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"‚úÖ Schema validation passed!\")\n",
    "    return True\n",
    "\n",
    "# Test validation\n",
    "expected_schema = {\n",
    "    'user_id': pl.UInt32,\n",
    "    'username': pl.Utf8,\n",
    "    'age': pl.UInt8\n",
    "}\n",
    "\n",
    "test_df = pl.DataFrame({\n",
    "    'user_id': pl.Series([1, 2], dtype=pl.UInt32),\n",
    "    'username': ['alice', 'bob'],\n",
    "    'age': pl.Series([25, 30], dtype=pl.UInt8)\n",
    "})\n",
    "\n",
    "validate_schema(test_df, expected_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema enforcement on write/read\n",
    "# Write with schema preserved (Parquet is best)\n",
    "parquet_path = os.path.join(temp_dir, 'data.parquet')\n",
    "df_schema.write_parquet(parquet_path)\n",
    "\n",
    "# Read back - schema is preserved!\n",
    "df_read = pl.read_parquet(parquet_path)\n",
    "\n",
    "print(\"Original schema:\")\n",
    "print(df_schema.schema)\n",
    "\n",
    "print(\"\\nRead schema (from Parquet):\")\n",
    "print(df_read.schema)\n",
    "\n",
    "print(\"\\n‚úÖ Parquet preserves exact schema (including Enum, Decimal)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Type Casting and Coercion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe type casting\n",
    "df_cast = pl.DataFrame({\n",
    "    'int_col': [1, 2, 3, 4, 5],\n",
    "    'str_num': ['10', '20', '30', '40', '50'],\n",
    "    'float_col': [1.1, 2.2, 3.3, 4.4, 5.5]\n",
    "})\n",
    "\n",
    "df_casted = df_cast.select([\n",
    "    pl.col('int_col').cast(pl.Float64).alias('int_to_float'),\n",
    "    pl.col('str_num').cast(pl.Int64).alias('str_to_int'),\n",
    "    pl.col('float_col').cast(pl.Int64).alias('float_to_int'),  # Truncates\n",
    "    pl.col('int_col').cast(pl.Utf8).alias('int_to_str')\n",
    "])\n",
    "\n",
    "print(\"Type casting:\")\n",
    "print(df_casted)\n",
    "print(f\"\\nSchema: {df_casted.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling cast failures\n",
    "df_invalid = pl.DataFrame({\n",
    "    'values': ['1', '2', 'invalid', '4']\n",
    "})\n",
    "\n",
    "# Strict cast (fails on invalid)\n",
    "try:\n",
    "    df_invalid.select(pl.col('values').cast(pl.Int64, strict=True))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Strict cast failed: {type(e).__name__}\")\n",
    "\n",
    "# Non-strict cast (invalid -> null)\n",
    "df_with_nulls = df_invalid.select(\n",
    "    pl.col('values').cast(pl.Int64, strict=False).alias('values_int')\n",
    ")\n",
    "\n",
    "print(\"\\nNon-strict cast (invalid -> null):\")\n",
    "print(df_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcasting for memory efficiency\n",
    "df_large = pl.DataFrame({\n",
    "    'id': range(1000),\n",
    "    'value': range(1000)\n",
    "})\n",
    "\n",
    "print(f\"Original (Int64): {df_large.estimated_size('kb'):.2f} KB\")\n",
    "\n",
    "# Downcast to smaller types\n",
    "df_optimized = df_large.select([\n",
    "    pl.col('id').cast(pl.UInt16).alias('id'),\n",
    "    pl.col('value').cast(pl.UInt16).alias('value')\n",
    "])\n",
    "\n",
    "print(f\"Optimized (UInt16): {df_optimized.estimated_size('kb'):.2f} KB\")\n",
    "print(f\"Memory saved: {(1 - df_optimized.estimated_size('kb') / df_large.estimated_size('kb')) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Schema Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema evolution scenario\n",
    "# Version 1: Original schema\n",
    "df_v1 = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35]\n",
    "})\n",
    "\n",
    "# Version 2: Added column\n",
    "df_v2 = pl.DataFrame({\n",
    "    'id': [4, 5, 6],\n",
    "    'name': ['Diana', 'Eve', 'Frank'],\n",
    "    'age': [28, 32, 40],\n",
    "    'email': ['diana@example.com', 'eve@example.com', 'frank@example.com']  # New!\n",
    "})\n",
    "\n",
    "# Version 3: Changed type\n",
    "df_v3 = pl.DataFrame({\n",
    "    'id': [7, 8, 9],\n",
    "    'name': ['Grace', 'Henry', 'Iris'],\n",
    "    'age': [26.5, 31.5, 38.5],  # Float instead of int!\n",
    "})\n",
    "\n",
    "print(\"V1 schema:\", df_v1.schema)\n",
    "print(\"V2 schema:\", df_v2.schema)\n",
    "print(\"V3 schema:\", df_v3.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining DataFrames with different schemas\n",
    "# align_columns will add missing columns with nulls\n",
    "\n",
    "combined = pl.concat(\n",
    "    [df_v1, df_v2, df_v3],\n",
    "    how='diagonal'  # Handles different schemas\n",
    ")\n",
    "\n",
    "print(\"Combined with schema evolution:\")\n",
    "print(combined)\n",
    "print(f\"\\nFinal schema: {combined.schema}\")\n",
    "print(\"Note: Missing 'email' is null, 'age' cast to Float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Binary and Object Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Binary Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary data (bytes)\n",
    "df_binary = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'data': [b'hello', b'world', b'polars']\n",
    "})\n",
    "\n",
    "print(\"Binary data:\")\n",
    "print(df_binary)\n",
    "print(f\"Schema: {df_binary.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary operations\n",
    "import base64\n",
    "\n",
    "# Encode string to binary\n",
    "df_encode = pl.DataFrame({\n",
    "    'text': ['hello', 'world']\n",
    "}).with_columns(\n",
    "    pl.col('text').str.encode('utf-8').alias('binary')\n",
    ")\n",
    "\n",
    "print(\"Encode to binary:\")\n",
    "print(df_encode)\n",
    "\n",
    "# Decode binary to string\n",
    "df_decode = df_encode.with_columns(\n",
    "    pl.col('binary').str.decode('utf-8').alias('decoded')\n",
    ")\n",
    "\n",
    "print(\"\\nDecode from binary:\")\n",
    "print(df_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Object Type (Use Sparingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object type for arbitrary Python objects (SLOW - avoid if possible)\n",
    "class CustomObject:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def __repr__(self):\n",
    "        return f\"CustomObject({self.value})\"\n",
    "\n",
    "df_object = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'obj': [CustomObject(10), CustomObject(20), CustomObject(30)]\n",
    "})\n",
    "\n",
    "print(\"Object type (slow - avoid):\")\n",
    "print(df_object)\n",
    "print(f\"Schema: {df_object.schema}\")\n",
    "print(\"\\n‚ö†Ô∏è Object types are slow - use native types when possible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 7: Type Selection Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices guide\n",
    "best_practices = pl.DataFrame({\n",
    "    'Data Type': [\n",
    "        'Age (0-120)',\n",
    "        'IDs (positive, < 4B)',\n",
    "        'Prices/Money',\n",
    "        'Status codes (fixed)',\n",
    "        'Categories (unknown)',\n",
    "        'Text/Names',\n",
    "        'Dates',\n",
    "        'Timestamps',\n",
    "        'True/False flags',\n",
    "        'Percentages (0-1)'\n",
    "    ],\n",
    "    'Recommended Type': [\n",
    "        'UInt8',\n",
    "        'UInt32',\n",
    "        'Decimal(15, 2)',\n",
    "        'Enum',\n",
    "        'Categorical',\n",
    "        'Utf8',\n",
    "        'Date',\n",
    "        'Datetime',\n",
    "        'Boolean',\n",
    "        'Float32'\n",
    "    ],\n",
    "    'Why': [\n",
    "        'Smallest type that fits range',\n",
    "        'Efficient, no negatives needed',\n",
    "        'Exact arithmetic, no float errors',\n",
    "        'Fastest, type-safe, consistent',\n",
    "        'Memory efficient, flexible',\n",
    "        'Standard string type',\n",
    "        'Date-only operations',\n",
    "        'Full precision timestamps',\n",
    "        'Single bit storage',\n",
    "        'Half precision sufficient'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Type Selection Best Practices:\")\n",
    "print(best_practices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example with optimized types\n",
    "df_optimized_schema = pl.DataFrame(\n",
    "    {\n",
    "        'customer_id': [1, 2, 3, 4, 5],\n",
    "        'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "        'age': [25, 30, 35, 28, 42],\n",
    "        'is_premium': [True, False, True, False, True],\n",
    "        'status': ['active', 'active', 'inactive', 'pending', 'active'],\n",
    "        'balance': [1234.56, 5678.90, 910.11, 1213.14, 1516.17],\n",
    "        'signup_date': [date(2024, 1, 1), date(2024, 1, 2), date(2024, 1, 3), \n",
    "                       date(2024, 1, 4), date(2024, 1, 5)]\n",
    "    },\n",
    "    schema={\n",
    "        'customer_id': pl.UInt32,\n",
    "        'name': pl.Utf8,\n",
    "        'age': pl.UInt8,\n",
    "        'is_premium': pl.Boolean,\n",
    "        'status': pl.Enum(['active', 'inactive', 'pending']),\n",
    "        'balance': pl.Decimal(precision=10, scale=2),\n",
    "        'signup_date': pl.Date\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Optimized customer DataFrame:\")\n",
    "print(df_optimized_schema)\n",
    "print(f\"\\nSchema: {df_optimized_schema.schema}\")\n",
    "print(f\"Memory: {df_optimized_schema.estimated_size('kb'):.4f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "### **Type Categories:**\n",
    "1. **Numeric**: Int8-Int64, UInt8-UInt64, Float32, Float64, Decimal\n",
    "2. **Temporal**: Date, Datetime, Time, Duration\n",
    "3. **Text**: Utf8, Categorical, Enum\n",
    "4. **Other**: Boolean, Binary, Object\n",
    "\n",
    "### **Memory Optimization:**\n",
    "- ‚úÖ Use smallest numeric type that fits your range\n",
    "- ‚úÖ Use UInt for positive-only values\n",
    "- ‚úÖ Use Enum/Categorical for repetitive strings\n",
    "- ‚úÖ Use Decimal for financial data\n",
    "- ‚ùå Avoid Object type (very slow)\n",
    "\n",
    "### **Enum vs Categorical:**\n",
    "| Feature | Enum | Categorical |\n",
    "|---------|------|-------------|\n",
    "| Performance | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| Type Safety | ‚úÖ Strict | ‚ùå None |\n",
    "| Use Case | Known categories | Dynamic categories |\n",
    "| **Recommendation** | **Prefer Enum** | Only if dynamic |\n",
    "\n",
    "### **Schema Best Practices:**\n",
    "1. Define schemas explicitly for production code\n",
    "2. Use Parquet to preserve exact schemas\n",
    "3. Validate schemas before processing\n",
    "4. Handle schema evolution with `how='diagonal'`\n",
    "5. Use strict=False for graceful cast failures\n",
    "\n",
    "### **Common Patterns:**\n",
    "```python\n",
    "# Define schema\n",
    "schema = {\n",
    "    'id': pl.UInt32,\n",
    "    'status': pl.Enum(['active', 'inactive']),\n",
    "    'price': pl.Decimal(10, 2)\n",
    "}\n",
    "\n",
    "# Create with schema\n",
    "df = pl.DataFrame(data, schema=schema)\n",
    "\n",
    "# Read with schema\n",
    "df = pl.read_csv('data.csv', schema=schema)\n",
    "\n",
    "# Cast safely\n",
    "df = df.with_columns(pl.col('col').cast(pl.Int32, strict=False))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Optimize this DataFrame's memory usage\n",
    "df_exercise = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],  # All positive, < 1000\n",
    "    'age': [25, 30, 35, 40, 45],  # 0-120 range\n",
    "    'score': [85.5, 92.3, 78.1, 88.9, 95.2],  # Percentages\n",
    "})\n",
    "\n",
    "# TODO: Cast columns to smallest appropriate types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Convert repetitive strings to Enum\n",
    "df_status = pl.DataFrame({\n",
    "    'order_id': range(1000),\n",
    "    'status': ['pending', 'shipped', 'delivered'] * 333 + ['pending']\n",
    "})\n",
    "\n",
    "# TODO: Convert status to Enum, measure memory savings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Define and validate a schema for user data\n",
    "# TODO: Create schema with: user_id (UInt32), email (Utf8), \n",
    "#       is_verified (Boolean), created_at (Datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Handle schema evolution\n",
    "# TODO: Combine 3 DataFrames with different schemas using diagonal concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Use Decimal for financial calculations\n",
    "# TODO: Calculate total price with tax using Decimal to avoid float errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"Cleaned up: {temp_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
