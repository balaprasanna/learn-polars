{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Nested Data Structures - Comprehensive Guide\n",
    "\n",
    "This notebook covers Polars' powerful nested data types: **Struct**, **List**, and **Array**.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Creating and manipulating Struct columns (nested key-value pairs)\n",
    "- Advanced List operations (dynamic-length sequences)\n",
    "- Array operations (fixed-length sequences)\n",
    "- Unnesting and exploding nested structures\n",
    "- Real-world JSON normalization patterns\n",
    "- When to use each nested type\n",
    "\n",
    "## Polars Nested Types Overview:\n",
    "\n",
    "| Type | Description | Length | Use Case |\n",
    "|------|-------------|--------|----------|\n",
    "| **Struct** | Nested named fields (like a mini-DataFrame) | Fixed fields | JSON objects, nested records |\n",
    "| **List** | Dynamic-length sequences | Variable per row | Arrays of items, tags, transactions |\n",
    "| **Array** | Fixed-length sequences | Same for all rows | Embeddings, coordinates, fixed features |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set display options\n",
    "pl.Config.set_tbl_rows(10)\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Struct Data Type\n",
    "\n",
    "Structs are like having a mini-DataFrame within each cell. They store named fields with potentially different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating Struct Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Create from dictionary (automatically becomes Struct)\n",
    "df_struct = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'address': [\n",
    "        {'street': '123 Main St', 'city': 'NYC', 'zip': '10001'},\n",
    "        {'street': '456 Oak Ave', 'city': 'LA', 'zip': '90001'},\n",
    "        {'street': '789 Pine Rd', 'city': 'Chicago', 'zip': '60601'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with Struct column:\")\n",
    "print(df_struct)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_struct.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Create Struct from existing columns using pl.struct()\n",
    "df = pl.DataFrame({\n",
    "    'user_id': [1, 2, 3],\n",
    "    'first_name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'last_name': ['Smith', 'Jones', 'Brown'],\n",
    "    'age': [25, 30, 35],\n",
    "    'city': ['NYC', 'LA', 'Chicago']\n",
    "})\n",
    "\n",
    "# Combine columns into a struct\n",
    "df_with_struct = df.select([\n",
    "    pl.col('user_id'),\n",
    "    pl.struct(['first_name', 'last_name', 'age']).alias('user_info'),\n",
    "    pl.col('city')\n",
    "])\n",
    "\n",
    "print(\"Created Struct from columns:\")\n",
    "print(df_with_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Create Struct using expressions\n",
    "result = df.select([\n",
    "    pl.col('user_id'),\n",
    "    pl.struct([\n",
    "        pl.col('first_name'),\n",
    "        pl.col('last_name'),\n",
    "        (pl.col('age') + 1).alias('age_next_year')\n",
    "    ]).alias('person')\n",
    "])\n",
    "\n",
    "print(\"Struct with computed fields:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Accessing Struct Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access struct fields using .struct.field()\n",
    "result = df_struct.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('address').struct.field('city').alias('city'),\n",
    "    pl.col('address').struct.field('zip').alias('zip_code')\n",
    "])\n",
    "\n",
    "print(\"Extract specific fields from Struct:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all struct fields at once using unnest()\n",
    "result = df_struct.unnest('address')\n",
    "\n",
    "print(\"Unnest struct (flatten all fields):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract multiple fields in one operation\n",
    "result = df_struct.with_columns([\n",
    "    pl.col('address').struct.field('city').alias('city'),\n",
    "    pl.col('address').struct.field('street').alias('street')\n",
    "])\n",
    "\n",
    "print(\"Keep original struct and extract fields:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Renaming Struct Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename struct fields using .struct.rename_fields()\n",
    "result = df_struct.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('address').struct.rename_fields(['street_address', 'city_name', 'postal_code'])\n",
    "])\n",
    "\n",
    "print(\"Renamed struct fields:\")\n",
    "print(result)\n",
    "print(\"\\nSchema:\")\n",
    "print(result.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Complex Nested Structs (Structs within Structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deeply nested structure\n",
    "df_nested = pl.DataFrame({\n",
    "    'user_id': [1, 2, 3],\n",
    "    'profile': [\n",
    "        {\n",
    "            'name': {'first': 'Alice', 'last': 'Smith'},\n",
    "            'contact': {'email': 'alice@example.com', 'phone': '555-0001'},\n",
    "            'age': 25\n",
    "        },\n",
    "        {\n",
    "            'name': {'first': 'Bob', 'last': 'Jones'},\n",
    "            'contact': {'email': 'bob@example.com', 'phone': '555-0002'},\n",
    "            'age': 30\n",
    "        },\n",
    "        {\n",
    "            'name': {'first': 'Charlie', 'last': 'Brown'},\n",
    "            'contact': {'email': 'charlie@example.com', 'phone': '555-0003'},\n",
    "            'age': 35\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Deeply nested structs:\")\n",
    "print(df_nested)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_nested.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access nested struct fields (chaining)\n",
    "result = df_nested.select([\n",
    "    pl.col('user_id'),\n",
    "    pl.col('profile').struct.field('name').struct.field('first').alias('first_name'),\n",
    "    pl.col('profile').struct.field('name').struct.field('last').alias('last_name'),\n",
    "    pl.col('profile').struct.field('contact').struct.field('email').alias('email'),\n",
    "    pl.col('profile').struct.field('age').alias('age')\n",
    "])\n",
    "\n",
    "print(\"Extract deeply nested fields:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnest nested structs level by level\n",
    "result = (\n",
    "    df_nested\n",
    "    .unnest('profile')  # First level\n",
    "    .unnest(['name', 'contact'])  # Second level (multiple structs)\n",
    ")\n",
    "\n",
    "print(\"Fully flattened nested structs:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Filtering and Operations on Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on struct field values\n",
    "result = df_struct.filter(\n",
    "    pl.col('address').struct.field('city') == 'NYC'\n",
    ")\n",
    "\n",
    "print(\"Filter by struct field:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update struct field values\n",
    "result = df_struct.with_columns(\n",
    "    pl.struct([\n",
    "        pl.col('address').struct.field('street').alias('street'),\n",
    "        pl.col('address').struct.field('city').str.to_uppercase().alias('city'),\n",
    "        pl.col('address').struct.field('zip').alias('zip')\n",
    "    ]).alias('address')\n",
    ")\n",
    "\n",
    "print(\"Modified struct field (city to uppercase):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: List Data Type\n",
    "\n",
    "Lists store variable-length sequences. Each row can have different number of elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating List Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with lists\n",
    "df_lists = pl.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'purchase_amounts': [[100, 200, 150], [50, 75], [300, 250, 400, 100], [500]],\n",
    "    'product_ids': [[1, 2, 3], [4, 5], [6, 7, 8, 9], [10]],\n",
    "    'tags': [['vip', 'frequent'], ['new'], ['vip', 'enterprise', 'gold'], ['standard']]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with lists:\")\n",
    "print(df_lists)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_lists.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Basic List Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List aggregations\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts').list.len().alias('num_purchases'),\n",
    "    pl.col('purchase_amounts').list.sum().alias('total_spent'),\n",
    "    pl.col('purchase_amounts').list.mean().alias('avg_purchase'),\n",
    "    pl.col('purchase_amounts').list.max().alias('max_purchase'),\n",
    "    pl.col('purchase_amounts').list.min().alias('min_purchase')\n",
    "])\n",
    "\n",
    "print(\"List aggregations:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access list elements by index\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts').list.first().alias('first_purchase'),\n",
    "    pl.col('purchase_amounts').list.last().alias('last_purchase'),\n",
    "    pl.col('purchase_amounts').list.get(1).alias('second_purchase'),  # 0-indexed\n",
    "    pl.col('purchase_amounts').list.get(-1).alias('last_purchase_negative_idx')\n",
    "])\n",
    "\n",
    "print(\"Access list elements:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List slicing\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts'),\n",
    "    pl.col('purchase_amounts').list.head(2).alias('first_2_purchases'),\n",
    "    pl.col('purchase_amounts').list.tail(2).alias('last_2_purchases'),\n",
    "    pl.col('purchase_amounts').list.slice(1, 2).alias('middle_slice')  # offset=1, length=2\n",
    "])\n",
    "\n",
    "print(\"List slicing:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Advanced List Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List sorting and reversing\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts'),\n",
    "    pl.col('purchase_amounts').list.sort().alias('sorted_purchases'),\n",
    "    pl.col('purchase_amounts').list.sort(descending=True).alias('sorted_desc'),\n",
    "    pl.col('purchase_amounts').list.reverse().alias('reversed')\n",
    "])\n",
    "\n",
    "print(\"List sorting and reversing:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check list membership\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('tags'),\n",
    "    pl.col('tags').list.contains('vip').alias('is_vip'),\n",
    "    pl.col('tags').list.contains('enterprise').alias('is_enterprise')\n",
    "])\n",
    "\n",
    "print(\"Check list membership:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique and counts\n",
    "df_with_duplicates = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'values': [[1, 2, 2, 3, 3, 3], [5, 5, 6], [7, 8, 8, 9, 9, 9, 9]]\n",
    "})\n",
    "\n",
    "result = df_with_duplicates.select([\n",
    "    pl.col('values'),\n",
    "    pl.col('values').list.unique().alias('unique_values'),\n",
    "    pl.col('values').list.n_unique().alias('n_unique'),\n",
    "    pl.col('values').list.len().alias('original_length')\n",
    "])\n",
    "\n",
    "print(\"List unique values:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 List Transformations with list.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list.eval() allows applying expressions to each element in a list\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts'),\n",
    "    # Apply discount: multiply each element by 0.9\n",
    "    pl.col('purchase_amounts').list.eval(pl.element() * 0.9).alias('discounted_10pct'),\n",
    "    # Filter elements: keep only purchases > 100\n",
    "    pl.col('purchase_amounts').list.eval(\n",
    "        pl.element().filter(pl.element() > 100)\n",
    "    ).alias('large_purchases_only')\n",
    "])\n",
    "\n",
    "print(\"List transformations with eval():\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex list.eval() examples\n",
    "result = df_lists.select([\n",
    "    pl.col('name'),\n",
    "    pl.col('purchase_amounts'),\n",
    "    # Categorize each purchase\n",
    "    pl.col('purchase_amounts').list.eval(\n",
    "        pl.when(pl.element() >= 200)\n",
    "          .then(pl.lit('high'))\n",
    "          .when(pl.element() >= 100)\n",
    "          .then(pl.lit('medium'))\n",
    "          .otherwise(pl.lit('low'))\n",
    "    ).alias('purchase_categories'),\n",
    "    # Round to nearest 50\n",
    "    pl.col('purchase_amounts').list.eval(\n",
    "        (pl.element() / 50).round(0) * 50\n",
    "    ).alias('rounded_to_50')\n",
    "])\n",
    "\n",
    "print(\"Complex list transformations:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 List Concatenation and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lists from multiple columns\n",
    "df_multi_lists = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'list_a': [[1, 2], [3, 4], [5, 6]],\n",
    "    'list_b': [[7, 8], [9], [10, 11, 12]]\n",
    "})\n",
    "\n",
    "result = df_multi_lists.select([\n",
    "    pl.col('id'),\n",
    "    pl.col('list_a'),\n",
    "    pl.col('list_b'),\n",
    "    pl.concat_list(['list_a', 'list_b']).alias('combined')\n",
    "])\n",
    "\n",
    "print(\"Concatenate lists:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list from scalar values\n",
    "df_scalars = pl.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'value_a': [10, 20, 30],\n",
    "    'value_b': [40, 50, 60],\n",
    "    'value_c': [70, 80, 90]\n",
    "})\n",
    "\n",
    "result = df_scalars.select([\n",
    "    pl.col('id'),\n",
    "    pl.concat_list(['value_a', 'value_b', 'value_c']).alias('values_list')\n",
    "])\n",
    "\n",
    "print(\"Create list from scalar columns:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten nested lists (lists of lists)\n",
    "df_nested_lists = pl.DataFrame({\n",
    "    'id': [1, 2],\n",
    "    'nested': [[[1, 2], [3, 4]], [[5, 6], [7, 8, 9]]]\n",
    "})\n",
    "\n",
    "result = df_nested_lists.select([\n",
    "    pl.col('id'),\n",
    "    pl.col('nested'),\n",
    "    pl.col('nested').list.flatten().alias('flattened')\n",
    "])\n",
    "\n",
    "print(\"Flatten nested lists:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Array Data Type\n",
    "\n",
    "Arrays are fixed-length sequences where all rows have the same number of elements. Useful for embeddings, coordinates, and fixed-size features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Creating Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array by casting from list\n",
    "df_arrays = pl.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'coordinates': [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]\n",
    "})\n",
    "\n",
    "# Cast to Array with fixed width\n",
    "df_arrays = df_arrays.with_columns(\n",
    "    pl.col('coordinates').cast(pl.Array(pl.Float64, 3)).alias('coordinates_array')\n",
    ")\n",
    "\n",
    "print(\"DataFrame with Array column:\")\n",
    "print(df_arrays)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_arrays.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays vs Lists - Type enforcement\n",
    "try:\n",
    "    # This will fail - arrays must have same length for all rows\n",
    "    df_invalid = pl.DataFrame({\n",
    "        'values': [[1, 2, 3], [4, 5], [6, 7, 8]]  # Different lengths!\n",
    "    }).with_columns(\n",
    "        pl.col('values').cast(pl.Array(pl.Int64, 3))\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error (expected): {type(e).__name__}\")\n",
    "    print(\"Arrays require all rows to have the same length!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 When to Use Array vs List\n",
    "\n",
    "| Use Case | Array | List |\n",
    "|----------|-------|------|\n",
    "| Fixed-size vectors (embeddings, RGB colors) | ✅ | ❌ |\n",
    "| Variable-length sequences (tags, items) | ❌ | ✅ |\n",
    "| Coordinates (x, y, z) | ✅ | ❌ |\n",
    "| Time series windows (fixed size) | ✅ | ❌ |\n",
    "| Transaction history (variable) | ❌ | ✅ |\n",
    "| Machine learning features (fixed) | ✅ | ❌ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: RGB color values\n",
    "df_colors = pl.DataFrame({\n",
    "    'color_name': ['red', 'green', 'blue', 'yellow'],\n",
    "    'rgb': [[255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0]]\n",
    "}).with_columns(\n",
    "    pl.col('rgb').cast(pl.Array(pl.UInt8, 3)).alias('rgb_array')\n",
    ")\n",
    "\n",
    "print(\"RGB colors as Arrays:\")\n",
    "print(df_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Geographic coordinates (lat, lon)\n",
    "df_locations = pl.DataFrame({\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago'],\n",
    "    'coords': [[40.7128, -74.0060], [34.0522, -118.2437], [41.8781, -87.6298]]\n",
    "}).with_columns(\n",
    "    pl.col('coords').cast(pl.Array(pl.Float64, 2)).alias('coordinates')\n",
    ")\n",
    "\n",
    "# Extract lat and lon\n",
    "result = df_locations.with_columns([\n",
    "    pl.col('coordinates').arr.get(0).alias('latitude'),\n",
    "    pl.col('coordinates').arr.get(1).alias('longitude')\n",
    "])\n",
    "\n",
    "print(\"Geographic coordinates:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Array Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array operations are similar to List operations\n",
    "result = df_arrays.select([\n",
    "    pl.col('id'),\n",
    "    pl.col('coordinates_array'),\n",
    "    pl.col('coordinates_array').arr.sum().alias('sum'),\n",
    "    pl.col('coordinates_array').arr.mean().alias('mean'),\n",
    "    pl.col('coordinates_array').arr.get(0).alias('x'),\n",
    "    pl.col('coordinates_array').arr.get(1).alias('y'),\n",
    "    pl.col('coordinates_array').arr.get(2).alias('z')\n",
    "])\n",
    "\n",
    "print(\"Array operations:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Unnesting and Exploding\n",
    "\n",
    "Converting nested structures to flat tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Explode vs Unnest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with both structs and lists\n",
    "df_mixed = pl.DataFrame({\n",
    "    'customer_id': [1, 2],\n",
    "    'name': ['Alice', 'Bob'],\n",
    "    'purchases': [[100, 200, 150], [50, 75]],\n",
    "    'address': [\n",
    "        {'city': 'NYC', 'state': 'NY'},\n",
    "        {'city': 'LA', 'state': 'CA'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLODE: Expands lists into multiple rows (one row per list element)\n",
    "exploded = df_mixed.explode('purchases')\n",
    "\n",
    "print(\"After explode('purchases'):\")\n",
    "print(exploded)\n",
    "print(f\"\\nRows: {len(df_mixed)} -> {len(exploded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNNEST: Expands structs into separate columns (flattens struct fields)\n",
    "unnested = df_mixed.unnest('address')\n",
    "\n",
    "print(\"After unnest('address'):\")\n",
    "print(unnested)\n",
    "print(f\"\\nColumns: {df_mixed.columns} -> {unnested.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine explode and unnest\n",
    "result = (\n",
    "    df_mixed\n",
    "    .explode('purchases')  # Expand list to rows\n",
    "    .unnest('address')     # Expand struct to columns\n",
    ")\n",
    "\n",
    "print(\"After both explode and unnest:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Exploding Multiple Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode multiple list columns simultaneously\n",
    "df_multi = pl.DataFrame({\n",
    "    'id': [1, 2],\n",
    "    'products': [['A', 'B', 'C'], ['D', 'E']],\n",
    "    'prices': [[10, 20, 30], [40, 50]],\n",
    "    'quantities': [[1, 2, 3], [4, 5]]\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df_multi)\n",
    "\n",
    "# Explode multiple columns (must have same length per row)\n",
    "exploded = df_multi.explode(['products', 'prices', 'quantities'])\n",
    "\n",
    "print(\"\\nExploded multiple lists:\")\n",
    "print(exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Working with Lists of Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common pattern: List of structs (like JSON arrays of objects)\n",
    "df_list_struct = pl.DataFrame({\n",
    "    'order_id': [1, 2],\n",
    "    'items': [\n",
    "        [\n",
    "            {'product': 'Laptop', 'price': 1000, 'qty': 1},\n",
    "            {'product': 'Mouse', 'price': 25, 'qty': 2}\n",
    "        ],\n",
    "        [\n",
    "            {'product': 'Keyboard', 'price': 75, 'qty': 1},\n",
    "            {'product': 'Monitor', 'price': 300, 'qty': 2}\n",
    "        ]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"List of structs:\")\n",
    "print(df_list_struct)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_list_struct.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten list of structs: explode then unnest\n",
    "flattened = (\n",
    "    df_list_struct\n",
    "    .explode('items')      # One row per item\n",
    "    .unnest('items')       # Struct fields become columns\n",
    ")\n",
    "\n",
    "print(\"Flattened list of structs:\")\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add computed column\n",
    "result = flattened.with_columns(\n",
    "    (pl.col('price') * pl.col('qty')).alias('total')\n",
    ")\n",
    "\n",
    "print(\"With computed total:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Real-World JSON Normalization\n",
    "\n",
    "Working with real-world nested JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: API response with nested user data\n",
    "json_data = [\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"username\": \"alice_smith\",\n",
    "        \"profile\": {\n",
    "            \"age\": 25,\n",
    "            \"location\": {\"city\": \"NYC\", \"country\": \"USA\"},\n",
    "            \"verified\": True\n",
    "        },\n",
    "        \"posts\": [\n",
    "            {\"post_id\": 101, \"likes\": 50, \"comments\": 5},\n",
    "            {\"post_id\": 102, \"likes\": 75, \"comments\": 10}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"username\": \"bob_jones\",\n",
    "        \"profile\": {\n",
    "            \"age\": 30,\n",
    "            \"location\": {\"city\": \"LA\", \"country\": \"USA\"},\n",
    "            \"verified\": False\n",
    "        },\n",
    "        \"posts\": [\n",
    "            {\"post_id\": 201, \"likes\": 100, \"comments\": 20}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Read JSON into Polars\n",
    "df_json = pl.DataFrame(json_data)\n",
    "\n",
    "print(\"Raw JSON data:\")\n",
    "print(df_json)\n",
    "print(\"\\nSchema:\")\n",
    "print(df_json.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Unnest the profile struct\n",
    "df_step1 = df_json.unnest('profile')\n",
    "\n",
    "print(\"Step 1 - Unnest profile:\")\n",
    "print(df_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Unnest the nested location struct\n",
    "df_step2 = df_step1.unnest('location')\n",
    "\n",
    "print(\"Step 2 - Unnest location:\")\n",
    "print(df_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Explode the posts list\n",
    "df_step3 = df_step2.explode('posts')\n",
    "\n",
    "print(\"Step 3 - Explode posts:\")\n",
    "print(df_step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Unnest the posts struct\n",
    "df_normalized = df_step3.unnest('posts')\n",
    "\n",
    "print(\"Fully normalized (flattened) data:\")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All steps in one chain\n",
    "df_normalized_chain = (\n",
    "    pl.DataFrame(json_data)\n",
    "    .unnest('profile')\n",
    "    .unnest('location')\n",
    "    .explode('posts')\n",
    "    .unnest('posts')\n",
    ")\n",
    "\n",
    "print(\"Normalized in one chain:\")\n",
    "print(df_normalized_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Advanced JSON Normalization Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex e-commerce order data\n",
    "orders_json = [\n",
    "    {\n",
    "        \"order_id\": \"ORD-001\",\n",
    "        \"date\": \"2024-01-15\",\n",
    "        \"customer\": {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Alice Smith\",\n",
    "            \"tier\": \"gold\"\n",
    "        },\n",
    "        \"items\": [\n",
    "            {\n",
    "                \"sku\": \"LAPTOP-001\",\n",
    "                \"name\": \"Dell Laptop\",\n",
    "                \"price\": 1200,\n",
    "                \"quantity\": 1,\n",
    "                \"discount\": 0.1\n",
    "            },\n",
    "            {\n",
    "                \"sku\": \"MOUSE-001\",\n",
    "                \"name\": \"Wireless Mouse\",\n",
    "                \"price\": 25,\n",
    "                \"quantity\": 2,\n",
    "                \"discount\": 0.0\n",
    "            }\n",
    "        ],\n",
    "        \"shipping\": {\n",
    "            \"address\": {\n",
    "                \"street\": \"123 Main St\",\n",
    "                \"city\": \"NYC\",\n",
    "                \"zip\": \"10001\"\n",
    "            },\n",
    "            \"method\": \"express\",\n",
    "            \"cost\": 15.99\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"order_id\": \"ORD-002\",\n",
    "        \"date\": \"2024-01-16\",\n",
    "        \"customer\": {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Bob Jones\",\n",
    "            \"tier\": \"silver\"\n",
    "        },\n",
    "        \"items\": [\n",
    "            {\n",
    "                \"sku\": \"KEYBOARD-001\",\n",
    "                \"name\": \"Mechanical Keyboard\",\n",
    "                \"price\": 150,\n",
    "                \"quantity\": 1,\n",
    "                \"discount\": 0.05\n",
    "            }\n",
    "        ],\n",
    "        \"shipping\": {\n",
    "            \"address\": {\n",
    "                \"street\": \"456 Oak Ave\",\n",
    "                \"city\": \"LA\",\n",
    "                \"zip\": \"90001\"\n",
    "            },\n",
    "            \"method\": \"standard\",\n",
    "            \"cost\": 5.99\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Normalize the complex structure\n",
    "df_orders = (\n",
    "    pl.DataFrame(orders_json)\n",
    "    .unnest('customer')                    # Flatten customer\n",
    "    .rename({'id': 'customer_id', 'name': 'customer_name'})  # Avoid column conflicts\n",
    "    .unnest('shipping')                    # Flatten shipping\n",
    "    .unnest('address')                     # Flatten nested address\n",
    "    .rename({'cost': 'shipping_cost'})     # Avoid conflicts\n",
    "    .explode('items')                      # Expand items list\n",
    "    .unnest('items')                       # Flatten items struct\n",
    "    # Add computed columns\n",
    "    .with_columns([\n",
    "        (pl.col('price') * pl.col('quantity')).alias('subtotal'),\n",
    "        (pl.col('price') * pl.col('quantity') * (1 - pl.col('discount'))).alias('total_after_discount')\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(\"Normalized e-commerce orders:\")\n",
    "print(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation on normalized data\n",
    "order_summary = (\n",
    "    df_orders\n",
    "    .group_by('order_id')\n",
    "    .agg([\n",
    "        pl.col('customer_name').first(),\n",
    "        pl.col('date').first(),\n",
    "        pl.col('total_after_discount').sum().alias('order_total'),\n",
    "        pl.col('sku').count().alias('num_items'),\n",
    "        pl.col('shipping_cost').first(),\n",
    "    ])\n",
    "    .with_columns(\n",
    "        (pl.col('order_total') + pl.col('shipping_cost')).alias('grand_total')\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Order summary:\")\n",
    "print(order_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Performance Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays are more memory-efficient than Lists (when appropriate)\n",
    "import time\n",
    "\n",
    "# Create large dataset\n",
    "n_rows = 100_000\n",
    "data_list = [[1.0, 2.0, 3.0] for _ in range(n_rows)]\n",
    "\n",
    "# As List\n",
    "df_list = pl.DataFrame({'values': data_list})\n",
    "list_size = df_list.estimated_size('mb')\n",
    "\n",
    "# As Array\n",
    "df_array = df_list.with_columns(\n",
    "    pl.col('values').cast(pl.Array(pl.Float64, 3)).alias('values_array')\n",
    ")\n",
    "array_size = df_array.select('values_array').estimated_size('mb')\n",
    "\n",
    "print(f\"List column size: {list_size:.4f} MB\")\n",
    "print(f\"Array column size: {array_size:.4f} MB\")\n",
    "print(f\"\\nArray is {list_size/array_size:.2f}x more memory efficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance tip: Use list.eval() instead of explode when possible\n",
    "df_perf = pl.DataFrame({\n",
    "    'id': range(1000),\n",
    "    'values': [[i, i+1, i+2, i+3, i+4] for i in range(1000)]\n",
    "})\n",
    "\n",
    "# Method 1: explode (creates many rows)\n",
    "start = time.time()\n",
    "result1 = df_perf.explode('values').with_columns(\n",
    "    (pl.col('values') * 2).alias('doubled')\n",
    ")\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Method 2: list.eval (keeps rows same)\n",
    "start = time.time()\n",
    "result2 = df_perf.with_columns(\n",
    "    pl.col('values').list.eval(pl.element() * 2).alias('doubled')\n",
    ")\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(f\"Explode method: {time1:.4f}s, {len(result1)} rows\")\n",
    "print(f\"list.eval method: {time2:.4f}s, {len(result2)} rows\")\n",
    "print(f\"\\nlist.eval is {time1/time2:.2f}x faster (avoids row explosion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary & Best Practices\n",
    "\n",
    "## When to Use Each Type:\n",
    "\n",
    "### **Struct**\n",
    "- ✅ Nested objects with named fields (JSON objects)\n",
    "- ✅ Grouping related columns together\n",
    "- ✅ Hierarchical data (address, contact info)\n",
    "- ✅ Keeping related data together for better organization\n",
    "\n",
    "### **List**\n",
    "- ✅ Variable-length sequences (tags, transaction history)\n",
    "- ✅ Arrays of unknown/changing size\n",
    "- ✅ Collecting values in group_by aggregations\n",
    "- ✅ JSON arrays with different lengths per row\n",
    "\n",
    "### **Array**\n",
    "- ✅ Fixed-size vectors (embeddings, coordinates)\n",
    "- ✅ RGB/RGBA colors\n",
    "- ✅ Time series windows (always N points)\n",
    "- ✅ Machine learning features with fixed dimensions\n",
    "- ✅ Better memory efficiency for fixed-size data\n",
    "\n",
    "## Key Operations:\n",
    "\n",
    "| Operation | Struct | List | Array |\n",
    "|-----------|--------|------|-------|\n",
    "| Access elements | `.struct.field()` | `.list.get()` | `.arr.get()` |\n",
    "| Flatten to columns | `unnest()` | N/A | N/A |\n",
    "| Expand to rows | N/A | `explode()` | `explode()` |\n",
    "| Transform elements | N/A | `.list.eval()` | `.arr.eval()` |\n",
    "| Aggregations | N/A | `.list.sum()`, etc. | `.arr.sum()`, etc. |\n",
    "\n",
    "## Performance Tips:\n",
    "1. Use **Array** instead of **List** when all rows have same length (more efficient)\n",
    "2. Use **list.eval()** instead of explode+operation when possible\n",
    "3. Unnest structs early in query pipeline for better optimization\n",
    "4. Avoid deeply nested structures if possible (harder to query)\n",
    "\n",
    "## Common Patterns:\n",
    "```python\n",
    "# JSON normalization\n",
    "df.unnest('struct_col').explode('list_col').unnest('nested_struct')\n",
    "\n",
    "# Creating list from columns\n",
    "pl.concat_list(['col1', 'col2', 'col3'])\n",
    "\n",
    "# Creating struct from columns\n",
    "pl.struct(['col1', 'col2', 'col3'])\n",
    "\n",
    "# Transforming list elements\n",
    "pl.col('list_col').list.eval(pl.element() * 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Practice Exercises\n",
    "\n",
    "Try these on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise data\n",
    "exercise_data = [\n",
    "    {\n",
    "        \"movie_id\": 1,\n",
    "        \"title\": \"The Matrix\",\n",
    "        \"year\": 1999,\n",
    "        \"genres\": [\"Action\", \"Sci-Fi\"],\n",
    "        \"ratings\": {\"imdb\": 8.7, \"rotten_tomatoes\": 88, \"metacritic\": 73},\n",
    "        \"cast\": [\n",
    "            {\"actor\": \"Keanu Reeves\", \"role\": \"Neo\"},\n",
    "            {\"actor\": \"Laurence Fishburne\", \"role\": \"Morpheus\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"movie_id\": 2,\n",
    "        \"title\": \"Inception\",\n",
    "        \"year\": 2010,\n",
    "        \"genres\": [\"Action\", \"Sci-Fi\", \"Thriller\"],\n",
    "        \"ratings\": {\"imdb\": 8.8, \"rotten_tomatoes\": 87, \"metacritic\": 74},\n",
    "        \"cast\": [\n",
    "            {\"actor\": \"Leonardo DiCaprio\", \"role\": \"Cobb\"},\n",
    "            {\"actor\": \"Tom Hardy\", \"role\": \"Eames\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "df_movies = pl.DataFrame(exercise_data)\n",
    "print(\"Exercise data:\")\n",
    "print(df_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Extract the IMDB rating from the ratings struct\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Find the average of all three rating scores for each movie\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create a table with one row per actor (flatten the cast list)\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Count how many genres each movie has\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Find movies that have \"Sci-Fi\" in their genres list\n",
    "# Your code here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
